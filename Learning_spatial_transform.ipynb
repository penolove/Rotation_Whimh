{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4afcf73d-dced-4549-a33d-ec46c749e8cd"
    }
   },
   "source": [
    "# Spatial TransFormer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2bfd530f-5521-4368-a9c0-c0466b9415a9"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from spatial_transformer import transformer\n",
    "import numpy as np\n",
    "from tf_utils import weight_variable, bias_variable, dense_to_one_hot\n",
    "\n",
    "# %% Load data\n",
    "mnist_cluttered = np.load('./data/mnist_sequence1_sample_5distortions5x5.npz')\n",
    "\n",
    "X_train = mnist_cluttered['X_train']\n",
    "y_train = mnist_cluttered['y_train']\n",
    "X_valid = mnist_cluttered['X_valid']\n",
    "y_valid = mnist_cluttered['y_valid']\n",
    "X_test = mnist_cluttered['X_test']\n",
    "y_test = mnist_cluttered['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b7f57f07-7f52-44f1-980e-47abef9f3161"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1600)\n",
      "(10000, 1)\n",
      "(1000, 1600)\n",
      "(1000, 1600)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_valid.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "30d60729-9d00-4baf-91dd-ce4f00598766"
    }
   },
   "source": [
    "# [sec0] Give a clutter plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "aa206c74-bc21-40a9-9c42-294fcea4d184"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niDhQEBURcaAgKiLiQEFURMTB/wDYPbzrf/MsgAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31ab1693d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the image is more with noise\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt_idx = i * 3 + j + 1\n",
    "        plt.subplot(3, 3, plt_idx)\n",
    "        first_train_img = np.reshape(X_train[i*3+j, :], (40, 40))\n",
    "        plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "print \"the image is more with noise\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d92963d9-7336-4aa3-a3d4-35984719d593"
    }
   },
   "source": [
    "# [sec0-1] create rotation image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3aa148d8-2725-4b17-9306-38366f326e54"
    }
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5654d2aa-4689-48fa-b243-6c31ff14b666"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f319ff68c90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31a8954c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_train_img = np.reshape(X_train[1, :], (40, 40))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "#M = np.float32([[1,0,0],[0,1,0]])\n",
    "rows,cols = first_train_img.shape\n",
    "\n",
    "M = cv2.getRotationMatrix2D((cols/2,rows/2),15,1)\n",
    "dst = cv2.warpAffine(first_train_img,M,(cols,rows))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(dst, cmap = plt.get_cmap('gray'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "a5639ef4-76fd-4d23-b5fb-994a62a3f6f7"
    }
   },
   "outputs": [],
   "source": [
    "# make it as function\n",
    "def getrotation_img(image,angel):\n",
    "    image = np.reshape(image, (40, 40))\n",
    "    rows,cols = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angel,1)\n",
    "    dst = cv2.warpAffine(image,M,(cols,rows))\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5bb23a59-7218-4ff8-9721-9f6ee94bc3a7"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f319c637990>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f319c6a5850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a check\n",
    "dst=getrotation_img(X_train[50, :],50)\n",
    "plt.imshow(dst, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "02a44f30-566f-48c1-82b8-d0f6ebd5eec2"
    }
   },
   "source": [
    "## let's begin rotation!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0d66c53c-ed54-40fe-9272-b9c4492514cc"
    }
   },
   "outputs": [],
   "source": [
    "import random \n",
    "def rotation_all(X_train,angle):\n",
    "    for i in xrange(X_train.shape[0]):\n",
    "        angle+=random.randint(-20 ,20)\n",
    "        if i==0:\n",
    "            X_train_temp=np.reshape(getrotation_img(X_train[i, :],angle), (-1, 1600))\n",
    "        else:\n",
    "            temp=np.reshape(getrotation_img(X_train[i, :],angle), (-1, 1600))\n",
    "            X_train_temp=np.concatenate((X_train_temp, temp), axis=0)\n",
    "    print \"the rotation output : \"+str(X_train_temp.shape)\n",
    "    return X_train_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1cf9dc86-e396-4246-a4de-864176704ebd"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "the rotation output : (10000, 1600)\n",
      "(100000, 1600)\n",
      "(100000, 1)\n"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "X_train_0=rotation_all(X_train,0)\n",
    "X_train_0_1=rotation_all(X_train,0)\n",
    "X_train_45=rotation_all(X_train,45)\n",
    "X_train_90=rotation_all(X_train,90)\n",
    "X_train_135=rotation_all(X_train,135)\n",
    "X_train_180=rotation_all(X_train,180)\n",
    "X_train_225=rotation_all(X_train,225)\n",
    "X_train_270=rotation_all(X_train,270)\n",
    "X_train_315=rotation_all(X_train,315)\n",
    "X_train=np.concatenate((X_train,X_train_0,X_train_0_1,X_train_45,X_train_90,\\\n",
    "                       X_train_135,X_train_180,X_train_225,\\\n",
    "                       X_train_270,X_train_315),axis=0)\n",
    "print X_train.shape\n",
    "\n",
    "y_train=np.concatenate((y_train,y_train,y_train,y_train,y_train,y_train,\\\n",
    "                        y_train,y_train,y_train,y_train),axis=0)\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "dff924ff-09ed-4cbc-a1f6-fba30429e291"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "the rotation output : (1000, 1600)\n",
      "(10000, 1600)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "X_valid_0=rotation_all(X_valid,0)\n",
    "X_valid_0_1=rotation_all(X_valid,0)\n",
    "X_valid_45=rotation_all(X_valid,45)\n",
    "X_valid_90=rotation_all(X_valid,90)\n",
    "X_valid_135=rotation_all(X_valid,135)\n",
    "X_valid_180=rotation_all(X_valid,180)\n",
    "X_valid_225=rotation_all(X_valid,225)\n",
    "X_valid_270=rotation_all(X_valid,270)\n",
    "X_valid_315=rotation_all(X_valid,315)\n",
    "X_valid=np.concatenate((X_valid,X_valid_0,X_valid_0_1,X_valid_45,X_valid_90,\\\n",
    "                       X_valid_135,X_valid_180,X_valid_225,\\\n",
    "                       X_valid_270,X_valid_315),axis=0)\n",
    "print X_valid.shape\n",
    "y_valid=np.concatenate((y_valid,y_valid,y_valid,y_valid,y_valid,y_valid,\\\n",
    "                        y_valid,y_valid,y_valid,y_valid),axis=0)\n",
    "print y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1da06f6a-c8ea-4335-ada7-22fae7a334dc"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9][9]\n",
      "[1][1]\n",
      "[6][6]\n",
      "[0][0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f319c5a9ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take a look of image\n",
    "## training set~~~~~~~\n",
    "first_train_img = np.reshape(X_train[1, :], (40, 40))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "dst = np.reshape(X_train[10001, :], (40, 40))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.imshow(dst, cmap = plt.get_cmap('gray'))\n",
    "plt.axis('off')\n",
    "\n",
    "print str(y_train[10001])+str( y_train[1])\n",
    "\n",
    "first_train_img = np.reshape(X_train[5000, :], (40, 40))\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "dst = np.reshape(X_train[15000, :], (40, 40))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.imshow(dst, cmap = plt.get_cmap('gray'))\n",
    "plt.axis('off')\n",
    "print str(y_train[15000])+str( y_train[5000])\n",
    "\n",
    "## validation set~~~~\n",
    "\n",
    "first_train_img = np.reshape(X_valid[500, :], (40, 40))\n",
    "plt.subplot(4, 2, 5)\n",
    "plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "dst = np.reshape(X_valid[1500, :], (40, 40))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 6)\n",
    "plt.imshow(dst, cmap = plt.get_cmap('gray'))\n",
    "plt.axis('off')\n",
    "print str(y_valid[1500])+str( y_valid[500])\n",
    "\n",
    "\n",
    "first_train_img = np.reshape(X_valid[700, :], (40, 40))\n",
    "plt.subplot(4, 2, 7)\n",
    "plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "dst = np.reshape(X_valid[1700, :], (40, 40))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(4, 2, 8)\n",
    "plt.imshow(dst, cmap = plt.get_cmap('gray'))\n",
    "plt.axis('off')\n",
    "print str(y_valid[1700])+str( y_valid[700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "43cfe518-9c9d-4a2c-875b-3caba8ed7b2c"
    }
   },
   "outputs": [],
   "source": [
    "# before training , shuffle it\n",
    "arr = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(arr)\n",
    "X_train=X_train[arr]\n",
    "y_train=y_train[arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sec[0-3] FCN without STN :  accuracy~30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# % turn from dense to one hot representation\n",
    "Y_train = dense_to_one_hot(y_train, n_classes=10)\n",
    "Y_valid = dense_to_one_hot(y_valid, n_classes=10)\n",
    "Y_test = dense_to_one_hot(y_test, n_classes=10)\n",
    "\n",
    "\n",
    "# %% We can add dropout for regularizing and to reduce overfitting like so:\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "regular_lambda = tf.placeholder(tf.float32)\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "# %% Graph representation of our network\n",
    "\n",
    "# %% Placeholders for 40x40 resolution\n",
    "x = tf.placeholder(tf.float32, [None, 1600])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "W_FCN = weight_variable([1600,10])\n",
    "B_FCN = weight_variable([10])\n",
    "\n",
    "y_logits = tf.matmul(x, W_FCN) + B_FCN\n",
    "\n",
    "# loss function\n",
    "regu = tf.nn.l2_loss(W_FCN)+tf.nn.l2_loss(B_FCN)\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=y_logits, labels=y))+regu*regular_lambda\n",
    "\n",
    "#optimizer\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer = opt.minimize(cross_entropy)\n",
    "\n",
    "# monitor accuracy\n",
    "tf_predictions=tf.argmax(y_logits, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(y_logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: 2.32151 acc :0.0996016\n",
      "Iteration: 100 Loss: 2.17635 acc :0.252485\n",
      "validation Accuracy (0): 0.2597\n",
      "Iteration: 0 Loss: 2.13712 acc :0.24502\n",
      "Iteration: 100 Loss: 2.15248 acc :0.264414\n",
      "validation Accuracy (1): 0.2731\n",
      "Iteration: 0 Loss: 2.12928 acc :0.25498\n",
      "Iteration: 100 Loss: 2.13972 acc :0.274354\n",
      "validation Accuracy (2): 0.2771\n",
      "Iteration: 0 Loss: 2.12306 acc :0.272908\n",
      "Iteration: 100 Loss: 2.13048 acc :0.286282\n",
      "validation Accuracy (3): 0.2869\n",
      "Iteration: 0 Loss: 2.11826 acc :0.270916\n",
      "Iteration: 100 Loss: 2.12341 acc :0.290258\n",
      "validation Accuracy (4): 0.2932\n",
      "Iteration: 0 Loss: 2.11461 acc :0.2749\n",
      "Iteration: 100 Loss: 2.11786 acc :0.298211\n",
      "validation Accuracy (5): 0.2968\n",
      "Iteration: 0 Loss: 2.11188 acc :0.268924\n",
      "Iteration: 100 Loss: 2.11347 acc :0.292247\n",
      "validation Accuracy (6): 0.2998\n",
      "Iteration: 0 Loss: 2.10988 acc :0.268924\n",
      "Iteration: 100 Loss: 2.10997 acc :0.294235\n",
      "validation Accuracy (7): 0.3029\n",
      "Iteration: 0 Loss: 2.10846 acc :0.272908\n",
      "Iteration: 100 Loss: 2.10718 acc :0.302187\n",
      "validation Accuracy (8): 0.3049\n",
      "Iteration: 0 Loss: 2.10749 acc :0.2749\n",
      "Iteration: 100 Loss: 2.10495 acc :0.306163\n",
      "validation Accuracy (9): 0.3058\n",
      "Iteration: 0 Loss: 2.10686 acc :0.280877\n",
      "Iteration: 100 Loss: 2.10318 acc :0.306163\n",
      "validation Accuracy (10): 0.3076\n",
      "Iteration: 0 Loss: 2.1065 acc :0.282869\n",
      "Iteration: 100 Loss: 2.10177 acc :0.306163\n",
      "validation Accuracy (11): 0.3093\n",
      "Iteration: 0 Loss: 2.10632 acc :0.282869\n",
      "Iteration: 100 Loss: 2.10066 acc :0.308151\n",
      "validation Accuracy (12): 0.3097\n",
      "Iteration: 0 Loss: 2.10627 acc :0.278884\n",
      "Iteration: 100 Loss: 2.09978 acc :0.308151\n",
      "validation Accuracy (13): 0.3106\n",
      "Iteration: 0 Loss: 2.10631 acc :0.280877\n",
      "Iteration: 100 Loss: 2.0991 acc :0.310139\n",
      "validation Accuracy (14): 0.311\n",
      "Iteration: 0 Loss: 2.10641 acc :0.276892\n",
      "Iteration: 100 Loss: 2.09856 acc :0.314115\n",
      "validation Accuracy (15): 0.3113\n",
      "Iteration: 0 Loss: 2.10654 acc :0.276892\n",
      "Iteration: 100 Loss: 2.09815 acc :0.316103\n",
      "validation Accuracy (16): 0.3116\n",
      "Iteration: 0 Loss: 2.10668 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09783 acc :0.32008\n",
      "validation Accuracy (17): 0.3119\n",
      "Iteration: 0 Loss: 2.10682 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09758 acc :0.322068\n",
      "validation Accuracy (18): 0.3122\n",
      "Iteration: 0 Loss: 2.10695 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09738 acc :0.322068\n",
      "validation Accuracy (19): 0.3122\n",
      "Iteration: 0 Loss: 2.10707 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09723 acc :0.322068\n",
      "validation Accuracy (20): 0.3122\n",
      "Iteration: 0 Loss: 2.10717 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09712 acc :0.322068\n",
      "validation Accuracy (21): 0.3126\n",
      "Iteration: 0 Loss: 2.10726 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09703 acc :0.322068\n",
      "validation Accuracy (22): 0.3126\n",
      "Iteration: 0 Loss: 2.10733 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09696 acc :0.322068\n",
      "validation Accuracy (23): 0.3127\n",
      "Iteration: 0 Loss: 2.10738 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09691 acc :0.322068\n",
      "validation Accuracy (24): 0.3126\n",
      "Iteration: 0 Loss: 2.10743 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09687 acc :0.322068\n",
      "validation Accuracy (25): 0.3126\n",
      "Iteration: 0 Loss: 2.10747 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09684 acc :0.322068\n",
      "validation Accuracy (26): 0.3128\n",
      "Iteration: 0 Loss: 2.1075 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09681 acc :0.322068\n",
      "validation Accuracy (27): 0.3126\n",
      "Iteration: 0 Loss: 2.10752 acc :0.280876\n",
      "Iteration: 100 Loss: 2.0968 acc :0.322068\n",
      "validation Accuracy (28): 0.3127\n",
      "Iteration: 0 Loss: 2.10754 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09678 acc :0.322068\n",
      "validation Accuracy (29): 0.3127\n",
      "Iteration: 0 Loss: 2.10755 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09677 acc :0.322068\n",
      "validation Accuracy (30): 0.3127\n",
      "Iteration: 0 Loss: 2.10756 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09676 acc :0.322068\n",
      "validation Accuracy (31): 0.3127\n",
      "Iteration: 0 Loss: 2.10757 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09676 acc :0.322068\n",
      "validation Accuracy (32): 0.3127\n",
      "Iteration: 0 Loss: 2.10758 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09675 acc :0.322068\n",
      "validation Accuracy (33): 0.3126\n",
      "Iteration: 0 Loss: 2.10758 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09675 acc :0.322068\n",
      "validation Accuracy (34): 0.3126\n",
      "Iteration: 0 Loss: 2.10758 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09675 acc :0.322068\n",
      "validation Accuracy (35): 0.3126\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (36): 0.3125\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (37): 0.3125\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (38): 0.3125\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (39): 0.3125\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (40): 0.3125\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (41): 0.3125\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (42): 0.3125\n",
      "Iteration: 0 Loss: 2.10759 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (43): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (44): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (45): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (46): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (47): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (48): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (49): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (50): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (51): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (52): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (53): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (54): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (55): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (56): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (57): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (58): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (59): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (60): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (61): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (62): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (63): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (64): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (65): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (66): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (67): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (68): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (69): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (70): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (71): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (72): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (73): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (74): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (75): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (76): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (77): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (78): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (79): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (80): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (81): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (82): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (83): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (84): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (85): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (86): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (87): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (88): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (89): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (90): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (91): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (92): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (93): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (94): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (95): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (96): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (97): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (98): 0.3125\n",
      "Iteration: 0 Loss: 2.1076 acc :0.280876\n",
      "Iteration: 100 Loss: 2.09674 acc :0.322068\n",
      "validation Accuracy (99): 0.3125\n"
     ]
    }
   ],
   "source": [
    "# %% We'll now train in minibatches and report accuracy, loss:\n",
    "iter_per_epoch = 200\n",
    "n_epochs = 100\n",
    "train_size = 100000\n",
    "regular_lambda_=0.01\n",
    "\n",
    "indices = np.linspace(0, 100000 - 1, iter_per_epoch)\n",
    "indices = indices.astype('int')\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    for iter_i in range(iter_per_epoch - 1):\n",
    "        batch_xs = X_train[indices[iter_i]:indices[iter_i+1]]\n",
    "        batch_ys = Y_train[indices[iter_i]:indices[iter_i+1]]\n",
    "        \n",
    "        if iter_i % 100 == 0:\n",
    "            loss,accuracy_ = sess.run([cross_entropy,accuracy],\n",
    "                            feed_dict={\n",
    "                                x: batch_xs,\n",
    "                                y: batch_ys,\n",
    "                                regular_lambda: regular_lambda_\n",
    "                            })\n",
    "            print('Iteration: ' + str(iter_i) + ' Loss: ' + str(loss) +' acc :' +str(accuracy_))\n",
    "\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            x: batch_xs, y: batch_ys, learning_rate:0.001, regular_lambda:regular_lambda_})\n",
    "\n",
    "\n",
    "    print('validation Accuracy (%d): ' % epoch_i + str(sess.run(accuracy,\n",
    "                                                     feed_dict={\n",
    "                                                         x: X_valid,\n",
    "                                                         y: Y_valid,\n",
    "                                                     })))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sec[0-4] CNN without STN :accuracy~90.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: 0.541042 acc :0.974104\n",
      "Iteration: 100 Loss: 0.491824 acc :0.986084\n",
      "validation Accuracy (0): 0.9059\n",
      "Iteration: 0 Loss: 0.48206 acc :0.982072\n",
      "Iteration: 100 Loss: 0.460997 acc :0.982107\n",
      "validation Accuracy (1): 0.9053\n",
      "Iteration: 0 Loss: 0.463597 acc :0.982072\n",
      "Iteration: 100 Loss: 0.453664 acc :0.988072\n",
      "validation Accuracy (2): 0.906\n",
      "Iteration: 0 Loss: 0.451181 acc :0.992032\n",
      "Iteration: 100 Loss: 0.43715 acc :0.982107\n",
      "validation Accuracy (3): 0.9075\n",
      "Iteration: 0 Loss: 0.435151 acc :0.992032\n",
      "Iteration: 100 Loss: 0.426697 acc :0.99006\n",
      "validation Accuracy (4): 0.9027\n",
      "Iteration: 0 Loss: 0.438487 acc :0.984064\n",
      "Iteration: 100 Loss: 0.43001 acc :0.980119\n",
      "validation Accuracy (5): 0.9071\n",
      "Iteration: 0 Loss: 0.435587 acc :0.988048\n",
      "Iteration: 100 Loss: 0.423083 acc :0.99006\n",
      "validation Accuracy (6): 0.9055\n",
      "Iteration: 0 Loss: 0.430603 acc :0.986056\n",
      "Iteration: 100 Loss: 0.419878 acc :0.988071\n",
      "validation Accuracy (7): 0.9069\n",
      "Iteration: 0 Loss: 0.431415 acc :0.99004\n",
      "Iteration: 100 Loss: 0.414777 acc :0.994036\n",
      "validation Accuracy (8): 0.9023\n",
      "Iteration: 0 Loss: 0.421329 acc :0.992032\n",
      "Iteration: 100 Loss: 0.41727 acc :0.99006\n",
      "validation Accuracy (9): 0.9043\n",
      "Iteration: 0 Loss: 0.42828 acc :0.99004\n",
      "Iteration: 100 Loss: 0.41838 acc :0.988071\n",
      "validation Accuracy (10): 0.9038\n",
      "Iteration: 0 Loss: 0.425889 acc :0.992032\n",
      "Iteration: 100 Loss: 0.408512 acc :0.992048\n",
      "validation Accuracy (11): 0.9057\n",
      "Iteration: 0 Loss: 0.4201 acc :0.99004\n",
      "Iteration: 100 Loss: 0.416787 acc :0.986083\n",
      "validation Accuracy (12): 0.9068\n",
      "Iteration: 0 Loss: 0.426689 acc :0.992032\n",
      "Iteration: 100 Loss: 0.418364 acc :0.99006\n",
      "validation Accuracy (13): 0.904\n",
      "Iteration: 0 Loss: 0.428635 acc :0.988048\n",
      "Iteration: 100 Loss: 0.418929 acc :0.982107\n",
      "validation Accuracy (14): 0.9054\n",
      "Iteration: 0 Loss: 0.424735 acc :0.986056\n",
      "Iteration: 100 Loss: 0.413002 acc :0.986083\n",
      "validation Accuracy (15): 0.9057\n",
      "Iteration: 0 Loss: 0.430684 acc :0.988048\n",
      "Iteration: 100 Loss: 0.412892 acc :0.988072\n",
      "validation Accuracy (16): 0.9053\n",
      "Iteration: 0 Loss: 0.418626 acc :0.988048\n",
      "Iteration: 100 Loss: 0.410898 acc :0.992048\n",
      "validation Accuracy (17): 0.9047\n",
      "Iteration: 0 Loss: 0.416377 acc :0.992032\n",
      "Iteration: 100 Loss: 0.41299 acc :0.992048\n",
      "validation Accuracy (18): 0.9035\n",
      "Iteration: 0 Loss: 0.418935 acc :0.99004\n",
      "Iteration: 100 Loss: 0.41371 acc :0.99006\n",
      "validation Accuracy (19): 0.9078\n",
      "Iteration: 0 Loss: 0.418869 acc :0.988048\n",
      "Iteration: 100 Loss: 0.412338 acc :0.99006\n",
      "validation Accuracy (20): 0.9038\n",
      "Iteration: 0 Loss: 0.416344 acc :0.994024\n",
      "Iteration: 100 Loss: 0.40361 acc :0.992048\n",
      "validation Accuracy (21): 0.9039\n",
      "Iteration: 0 Loss: 0.425672 acc :0.98008\n",
      "Iteration: 100 Loss: 0.406765 acc :0.988071\n",
      "validation Accuracy (22): 0.9051\n",
      "Iteration: 0 Loss: 0.426556 acc :0.982072\n",
      "Iteration: 100 Loss: 0.412361 acc :0.988072\n",
      "validation Accuracy (23): 0.9016\n",
      "Iteration: 0 Loss: 0.41895 acc :0.988048\n",
      "Iteration: 100 Loss: 0.411676 acc :0.988072\n",
      "validation Accuracy (24): 0.9045\n",
      "Iteration: 0 Loss: 0.418719 acc :0.99004\n",
      "Iteration: 100 Loss: 0.411541 acc :0.99006\n",
      "validation Accuracy (25): 0.9051\n",
      "Iteration: 0 Loss: 0.411782 acc :0.994024\n",
      "Iteration: 100 Loss: 0.409034 acc :0.988072\n",
      "validation Accuracy (26): 0.9016\n",
      "Iteration: 0 Loss: 0.420907 acc :0.986056\n",
      "Iteration: 100 Loss: 0.406181 acc :0.992048\n",
      "validation Accuracy (27): 0.9013\n",
      "Iteration: 0 Loss: 0.423967 acc :0.982072\n",
      "Iteration: 100 Loss: 0.406363 acc :0.99006\n",
      "validation Accuracy (28): 0.9057\n",
      "Iteration: 0 Loss: 0.417981 acc :0.992032\n",
      "Iteration: 100 Loss: 0.403069 acc :0.988072\n",
      "validation Accuracy (29): 0.9014\n",
      "Iteration: 0 Loss: 0.41158 acc :0.992032\n",
      "Iteration: 100 Loss: 0.408011 acc :0.992048\n",
      "validation Accuracy (30): 0.9041\n",
      "Iteration: 0 Loss: 0.417013 acc :0.992032\n",
      "Iteration: 100 Loss: 0.411468 acc :0.992048\n",
      "validation Accuracy (31): 0.9013\n",
      "Iteration: 0 Loss: 0.418406 acc :0.988048\n",
      "Iteration: 100 Loss: 0.405465 acc :0.992048\n",
      "validation Accuracy (32): 0.9037\n",
      "Iteration: 0 Loss: 0.41199 acc :0.99004\n",
      "Iteration: 100 Loss: 0.404254 acc :0.992048\n",
      "validation Accuracy (33): 0.9024\n",
      "Iteration: 0 Loss: 0.417773 acc :0.99004\n",
      "Iteration: 100 Loss: 0.407024 acc :0.994036\n",
      "validation Accuracy (34): 0.904\n",
      "Iteration: 0 Loss: 0.415088 acc :0.992032\n",
      "Iteration: 100 Loss: 0.402422 acc :0.994036\n",
      "validation Accuracy (35): 0.9066\n",
      "Iteration: 0 Loss: 0.417627 acc :0.994024\n",
      "Iteration: 100 Loss: 0.405374 acc :0.99006\n",
      "validation Accuracy (36): 0.9052\n",
      "Iteration: 0 Loss: 0.420459 acc :0.986056\n",
      "Iteration: 100 Loss: 0.407835 acc :0.992048\n",
      "validation Accuracy (37): 0.9034\n",
      "Iteration: 0 Loss: 0.414884 acc :0.994024\n",
      "Iteration: 100 Loss: 0.403431 acc :0.994036\n",
      "validation Accuracy (38): 0.902\n",
      "Iteration: 0 Loss: 0.418791 acc :0.992032\n",
      "Iteration: 100 Loss: 0.405355 acc :0.996024\n",
      "validation Accuracy (39): 0.9063\n",
      "Iteration: 0 Loss: 0.412027 acc :0.992032\n",
      "Iteration: 100 Loss: 0.406532 acc :0.988071\n",
      "validation Accuracy (40): 0.9066\n",
      "Iteration: 0 Loss: 0.411665 acc :0.994024\n",
      "Iteration: 100 Loss: 0.40756 acc :0.994036\n",
      "validation Accuracy (41): 0.9025\n",
      "Iteration: 0 Loss: 0.41268 acc :0.996016\n",
      "Iteration: 100 Loss: 0.400035 acc :0.994036\n",
      "validation Accuracy (42): 0.9055\n",
      "Iteration: 0 Loss: 0.410676 acc :0.994024\n",
      "Iteration: 100 Loss: 0.408527 acc :0.99006\n",
      "validation Accuracy (43): 0.9059\n",
      "Iteration: 0 Loss: 0.409946 acc :0.994024\n",
      "Iteration: 100 Loss: 0.408467 acc :0.99006\n",
      "validation Accuracy (44): 0.9061\n",
      "Iteration: 0 Loss: 0.413965 acc :0.994024\n",
      "Iteration: 100 Loss: 0.402192 acc :0.992048\n",
      "validation Accuracy (45): 0.9054\n",
      "Iteration: 0 Loss: 0.41773 acc :0.988048\n",
      "Iteration: 100 Loss: 0.407534 acc :0.992048\n",
      "validation Accuracy (46): 0.9049\n",
      "Iteration: 0 Loss: 0.408937 acc :0.992032\n",
      "Iteration: 100 Loss: 0.402843 acc :0.994036\n",
      "validation Accuracy (47): 0.9002\n",
      "Iteration: 0 Loss: 0.413334 acc :0.99004\n",
      "Iteration: 100 Loss: 0.408155 acc :0.992048\n",
      "validation Accuracy (48): 0.9021\n",
      "Iteration: 0 Loss: 0.415026 acc :0.994024\n",
      "Iteration: 100 Loss: 0.403349 acc :0.99006\n",
      "validation Accuracy (49): 0.9027\n",
      "Iteration: 0 Loss: 0.414223 acc :0.994024\n",
      "Iteration: 100 Loss: 0.40348 acc :0.992048\n",
      "validation Accuracy (50): 0.9026\n",
      "Iteration: 0 Loss: 0.41259 acc :0.994024\n",
      "Iteration: 100 Loss: 0.403806 acc :0.996024\n",
      "validation Accuracy (51): 0.9039\n",
      "Iteration: 0 Loss: 0.41149 acc :0.996016\n",
      "Iteration: 100 Loss: 0.408753 acc :0.988072\n",
      "validation Accuracy (52): 0.9034\n",
      "Iteration: 0 Loss: 0.410891 acc :0.99004\n",
      "Iteration: 100 Loss: 0.402627 acc :0.994036\n",
      "validation Accuracy (53): 0.9018\n",
      "Iteration: 0 Loss: 0.404485 acc :0.994024\n",
      "Iteration: 100 Loss: 0.400565 acc :0.994036\n",
      "validation Accuracy (54): 0.9018\n",
      "Iteration: 0 Loss: 0.408184 acc :0.994024\n",
      "Iteration: 100 Loss: 0.398547 acc :0.996024\n",
      "validation Accuracy (55): 0.9032\n",
      "Iteration: 0 Loss: 0.412568 acc :0.994024\n",
      "Iteration: 100 Loss: 0.402873 acc :0.992048\n",
      "validation Accuracy (56): 0.9028\n",
      "Iteration: 0 Loss: 0.411543 acc :0.992032\n",
      "Iteration: 100 Loss: 0.405935 acc :0.994036\n",
      "validation Accuracy (57): 0.902\n",
      "Iteration: 0 Loss: 0.411175 acc :0.992032\n",
      "Iteration: 100 Loss: 0.399336 acc :0.994036\n",
      "validation Accuracy (58): 0.9023\n",
      "Iteration: 0 Loss: 0.40823 acc :0.992032\n",
      "Iteration: 100 Loss: 0.401306 acc :0.992048\n",
      "validation Accuracy (59): 0.9016\n",
      "Iteration: 0 Loss: 0.409105 acc :0.988048\n",
      "Iteration: 100 Loss: 0.407592 acc :0.988071\n",
      "validation Accuracy (60): 0.9052\n",
      "Iteration: 0 Loss: 0.407595 acc :0.994024\n",
      "Iteration: 100 Loss: 0.408082 acc :0.992048\n",
      "validation Accuracy (61): 0.9055\n",
      "Iteration: 0 Loss: 0.414901 acc :0.992032\n",
      "Iteration: 100 Loss: 0.397064 acc :0.996024\n",
      "validation Accuracy (62): 0.9046\n",
      "Iteration: 0 Loss: 0.407194 acc :0.998008\n",
      "Iteration: 100 Loss: 0.400144 acc :0.994036\n",
      "validation Accuracy (63): 0.9079\n",
      "Iteration: 0 Loss: 0.417685 acc :0.986056\n",
      "Iteration: 100 Loss: 0.407024 acc :0.992048\n",
      "validation Accuracy (64): 0.9031\n",
      "Iteration: 0 Loss: 0.415614 acc :0.992032\n",
      "Iteration: 100 Loss: 0.41072 acc :0.99006\n",
      "validation Accuracy (65): 0.9026\n",
      "Iteration: 0 Loss: 0.411443 acc :0.994024\n",
      "Iteration: 100 Loss: 0.400996 acc :0.992048\n",
      "validation Accuracy (66): 0.8997\n",
      "Iteration: 0 Loss: 0.411239 acc :0.99004\n",
      "Iteration: 100 Loss: 0.401847 acc :0.992048\n",
      "validation Accuracy (67): 0.9042\n",
      "Iteration: 0 Loss: 0.413662 acc :0.988048\n",
      "Iteration: 100 Loss: 0.405541 acc :0.994036\n",
      "validation Accuracy (68): 0.9023\n",
      "Iteration: 0 Loss: 0.409292 acc :0.992032\n",
      "Iteration: 100 Loss: 0.406403 acc :0.99006\n",
      "validation Accuracy (69): 0.9004\n",
      "Iteration: 0 Loss: 0.411973 acc :0.99004\n",
      "Iteration: 100 Loss: 0.398605 acc :0.998012\n",
      "validation Accuracy (70): 0.9012\n",
      "Iteration: 0 Loss: 0.41071 acc :0.992032\n",
      "Iteration: 100 Loss: 0.402468 acc :0.992048\n",
      "validation Accuracy (71): 0.9011\n",
      "Iteration: 0 Loss: 0.412799 acc :0.988048\n",
      "Iteration: 100 Loss: 0.402876 acc :0.992048\n",
      "validation Accuracy (72): 0.9049\n",
      "Iteration: 0 Loss: 0.41032 acc :0.992032\n",
      "Iteration: 100 Loss: 0.40343 acc :0.992048\n",
      "validation Accuracy (73): 0.9019\n",
      "Iteration: 0 Loss: 0.407845 acc :0.994024\n",
      "Iteration: 100 Loss: 0.404196 acc :0.996024\n",
      "validation Accuracy (74): 0.9013\n",
      "Iteration: 0 Loss: 0.408364 acc :0.986056\n",
      "Iteration: 100 Loss: 0.404846 acc :0.994036\n",
      "validation Accuracy (75): 0.9043\n",
      "Iteration: 0 Loss: 0.400835 acc :0.998008\n",
      "Iteration: 100 Loss: 0.4058 acc :0.994036\n",
      "validation Accuracy (76): 0.9042\n",
      "Iteration: 0 Loss: 0.415035 acc :0.992032\n",
      "Iteration: 100 Loss: 0.404952 acc :0.994036\n",
      "validation Accuracy (77): 0.9032\n",
      "Iteration: 0 Loss: 0.409525 acc :0.99004\n",
      "Iteration: 100 Loss: 0.402322 acc :0.988072\n",
      "validation Accuracy (78): 0.9007\n",
      "Iteration: 0 Loss: 0.412976 acc :0.992032\n",
      "Iteration: 100 Loss: 0.402323 acc :0.992048\n",
      "validation Accuracy (79): 0.9039\n",
      "Iteration: 0 Loss: 0.413898 acc :0.99004\n",
      "Iteration: 100 Loss: 0.39778 acc :0.996024\n",
      "validation Accuracy (80): 0.9041\n",
      "Iteration: 0 Loss: 0.413006 acc :0.992032\n",
      "Iteration: 100 Loss: 0.401093 acc :0.994036\n",
      "validation Accuracy (81): 0.9017\n",
      "Iteration: 0 Loss: 0.409745 acc :0.992032\n",
      "Iteration: 100 Loss: 0.399545 acc :0.992048\n",
      "validation Accuracy (82): 0.9009\n",
      "Iteration: 0 Loss: 0.408824 acc :0.994024\n",
      "Iteration: 100 Loss: 0.40022 acc :0.99006\n",
      "validation Accuracy (83): 0.9023\n",
      "Iteration: 0 Loss: 0.409065 acc :0.994024\n",
      "Iteration: 100 Loss: 0.40654 acc :0.992048\n",
      "validation Accuracy (84): 0.9051\n",
      "Iteration: 0 Loss: 0.41071 acc :0.988048\n",
      "Iteration: 100 Loss: 0.398627 acc :0.992048\n",
      "validation Accuracy (85): 0.9044\n",
      "Iteration: 0 Loss: 0.413938 acc :0.992032\n",
      "Iteration: 100 Loss: 0.399654 acc :0.990059\n",
      "validation Accuracy (86): 0.9042\n",
      "Iteration: 0 Loss: 0.404955 acc :0.992032\n",
      "Iteration: 100 Loss: 0.403253 acc :0.996024\n",
      "validation Accuracy (87): 0.9046\n",
      "Iteration: 0 Loss: 0.408781 acc :0.994024\n",
      "Iteration: 100 Loss: 0.405093 acc :0.988072\n",
      "validation Accuracy (88): 0.8969\n",
      "Iteration: 0 Loss: 0.4095 acc :0.992032\n",
      "Iteration: 100 Loss: 0.401471 acc :0.992048\n",
      "validation Accuracy (89): 0.903\n",
      "Iteration: 0 Loss: 0.411868 acc :0.988048\n",
      "Iteration: 100 Loss: 0.402827 acc :0.986083\n",
      "validation Accuracy (90): 0.9041\n",
      "Iteration: 0 Loss: 0.40999 acc :0.99004\n",
      "Iteration: 100 Loss: 0.403264 acc :0.992048\n",
      "validation Accuracy (91): 0.9011\n",
      "Iteration: 0 Loss: 0.413765 acc :0.99004\n",
      "Iteration: 100 Loss: 0.397704 acc :0.994036\n",
      "validation Accuracy (92): 0.9036\n",
      "Iteration: 0 Loss: 0.415959 acc :0.992032\n",
      "Iteration: 100 Loss: 0.400222 acc :0.994036\n",
      "validation Accuracy (93): 0.9045\n",
      "Iteration: 0 Loss: 0.414826 acc :0.994024\n",
      "Iteration: 100 Loss: 0.409117 acc :0.992048\n",
      "validation Accuracy (94): 0.9043\n",
      "Iteration: 0 Loss: 0.414828 acc :0.992032\n",
      "Iteration: 100 Loss: 0.400137 acc :0.992048\n",
      "validation Accuracy (95): 0.9046\n",
      "Iteration: 0 Loss: 0.412416 acc :0.988048\n",
      "Iteration: 100 Loss: 0.403977 acc :0.99006\n",
      "validation Accuracy (96): 0.9045\n",
      "Iteration: 0 Loss: 0.405802 acc :0.992032\n",
      "Iteration: 100 Loss: 0.400442 acc :0.992048\n",
      "validation Accuracy (97): 0.9049\n",
      "Iteration: 0 Loss: 0.406146 acc :0.996016\n",
      "Iteration: 100 Loss: 0.405844 acc :0.988071\n",
      "validation Accuracy (98): 0.9076\n",
      "Iteration: 0 Loss: 0.406771 acc :1.0\n",
      "Iteration: 100 Loss: 0.405767 acc :0.992048\n",
      "validation Accuracy (99): 0.9051\n"
     ]
    }
   ],
   "source": [
    "# %% We'll now train in minibatches and report accuracy, loss:\n",
    "iter_per_epoch = 200\n",
    "n_epochs = 100\n",
    "train_size = 100000\n",
    "regular_lambda_=0.001\n",
    "\n",
    "indices = np.linspace(0, 100000 - 1, iter_per_epoch)\n",
    "indices = indices.astype('int')\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    for iter_i in range(iter_per_epoch - 1):\n",
    "        batch_xs = X_train[indices[iter_i]:indices[iter_i+1]]\n",
    "        batch_ys = Y_train[indices[iter_i]:indices[iter_i+1]]\n",
    "        \n",
    "        if iter_i % 100 == 0:\n",
    "            loss,accuracy_ = sess.run([cross_entropy,accuracy],\n",
    "                            feed_dict={\n",
    "                                x: batch_xs,\n",
    "                                y: batch_ys,\n",
    "                                regular_lambda: regular_lambda_,\n",
    "                                keep_prob:1\n",
    "                            })\n",
    "            print('Iteration: ' + str(iter_i) + ' Loss: ' + str(loss) +' acc :' +str(accuracy_))\n",
    "\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            x: batch_xs, y: batch_ys, learning_rate:0.0005, keep_prob:0.4, regular_lambda:regular_lambda_})\n",
    "\n",
    "\n",
    "    print('validation Accuracy (%d): ' % epoch_i + str(sess.run(accuracy,\n",
    "                                                     feed_dict={\n",
    "                                                         x: X_valid,\n",
    "                                                         y: Y_valid,\n",
    "                                                         keep_prob:1\n",
    "                                                     })))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ce7128eb-d5b2-473b-aa3f-f959e03186e9"
    }
   },
   "source": [
    "# sec[1-0] Create transfromer layer\n",
    "\n",
    "## raw-> conv -> fc ->fc -> stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "cc692ddd-13ce-4e7d-a440-0a7e2634c9e7"
    }
   },
   "outputs": [],
   "source": [
    "def create_stn():\n",
    "    # %% We can add dropout for regularizing and to reduce overfitting like so:\n",
    "    keep_prob = tf.placeholder(tf.float32,name='KP')\n",
    "    regular_lambda = tf.placeholder(tf.float32,name='RL')\n",
    "    learning_rate = tf.placeholder(tf.float32,name='LR')\n",
    "\n",
    "    # %% Placeholders for 40x40 resolution\n",
    "    x = tf.placeholder(tf.float32, [None, 1600])\n",
    "    y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "    x_tensor = tf.reshape(x, [-1, 40, 40, 1])\n",
    "    filter_size = 3\n",
    "    n_filters_1 = 32\n",
    "    W_conv1_loc1 = weight_variable([filter_size, filter_size, 1, n_filters_1])\n",
    "    b_conv1_loc1 = bias_variable([n_filters_1])\n",
    "\n",
    "    W_fc_loc1 = weight_variable([1600, 20])\n",
    "    b_fc_loc1 = bias_variable([20])\n",
    "\n",
    "    #STN-conv_1-relu\n",
    "    h_conv1_loc1 = tf.nn.relu(\n",
    "        tf.nn.conv2d(input=x_tensor,\n",
    "                     filter=W_conv1_loc1,\n",
    "                     strides=[1, 2, 2, 1],\n",
    "                     padding='SAME') +\n",
    "        b_conv1_loc1)\n",
    "    h_conv1_loc1_drop = tf.nn.dropout(h_conv1_loc1, keep_prob)\n",
    "    h_conv1_loc1_flat = tf.reshape(h_conv1_loc1_drop, [-1, 20* 20 * n_filters_1])\n",
    "\n",
    "\n",
    "    #STN-FC-relu\n",
    "    n_fc_local=256\n",
    "    W_fc_loc1 = weight_variable([20* 20* n_filters_1, n_fc_local])\n",
    "    b_fc_loc1 = bias_variable([n_fc_local])\n",
    "    h_fc_loc1 = tf.nn.relu(tf.matmul(h_conv1_loc1_flat, W_fc_loc1) + b_fc_loc1)\n",
    "\n",
    "\n",
    "    #STN-FC-tanh\n",
    "    initial = np.array([[1., 0, 0], [0, 1., 0]])\n",
    "    initial = initial.astype('float32')\n",
    "    initial = initial.flatten()\n",
    "    b_fc_loc2 = tf.Variable(initial_value=initial, name='b_fc_loc2')\n",
    "    W_fc_loc2 = weight_variable([n_fc_local, 6])\n",
    "\n",
    "    h_fc_loc2 = tf.nn.tanh(tf.matmul(h_fc_loc1, W_fc_loc2) + b_fc_loc2)\n",
    "\n",
    "\n",
    "    # %% We'll create a spatial transformer module to identify discriminative\n",
    "    # %% patches\n",
    "    out_size = (40, 40)\n",
    "    h_trans = transformer(x_tensor, h_fc_loc2, out_size)\n",
    "\n",
    "    regu_stn=tf.nn.l2_loss(b_fc_loc2)+tf.nn.l2_loss(W_fc_loc2)+\\\n",
    "            tf.nn.l2_loss(W_fc_loc1)+tf.nn.l2_loss(b_fc_loc1)+\\\n",
    "            tf.nn.l2_loss(W_conv1_loc1)+tf.nn.l2_loss(b_conv1_loc1)\n",
    "    return [x,y,h_trans,regu_stn,h_fc_loc2,keep_prob,regular_lambda,learning_rate]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sec[1-1] FC with stn ~76% (Fc without stn ~30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a stn network\n",
    "x,y,h_trans,regu_stn,h_fc_loc2,keep_prob,regular_lambda,learning_rate = create_stn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add FC layers\n",
    "\n",
    "x_tensor=tf.reshape(h_trans, [-1, 1600])\n",
    "\n",
    "W_FCN = weight_variable([1600,10])\n",
    "B_FCN = weight_variable([10])\n",
    "\n",
    "y_logits = tf.matmul(x_tensor, W_FCN) + B_FCN\n",
    "\n",
    "# loss function\n",
    "regu = tf.nn.l2_loss(W_FCN)+tf.nn.l2_loss(B_FCN)+regu_stn\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=y_logits, labels=y))+regu*regular_lambda\n",
    "\n",
    "\n",
    "#optimizer\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate_decay = tf.train.exponential_decay(learning_rate, global_step,\n",
    "                                           100000, 0.96, staircase=True)\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate_decay)\n",
    "optimizer = opt.minimize(cross_entropy,global_step = global_step)\n",
    "\n",
    "# monitor accuracy\n",
    "tf_predictions=tf.argmax(y_logits, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(y_logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: 0.891941 acc :0.856574\n",
      "Iteration: 20 Loss: 0.875044 acc :0.844622\n",
      "Iteration: 40 Loss: 0.844243 acc :0.850598\n",
      "Iteration: 60 Loss: 0.872092 acc :0.844622\n",
      "Iteration: 80 Loss: 0.824863 acc :0.858847\n",
      "Iteration: 100 Loss: 0.785356 acc :0.874751\n",
      "Iteration: 120 Loss: 0.844027 acc :0.848907\n",
      "Iteration: 140 Loss: 0.77686 acc :0.878486\n",
      "Iteration: 160 Loss: 0.802483 acc :0.858566\n",
      "Iteration: 180 Loss: 0.83186 acc :0.856574\n",
      "validation Accuracy (0): 0.7508\n",
      "Iteration: 0 Loss: 0.778913 acc :0.860558\n",
      "Iteration: 20 Loss: 0.791442 acc :0.86255\n",
      "Iteration: 40 Loss: 0.802207 acc :0.870518\n",
      "Iteration: 60 Loss: 0.794356 acc :0.850598\n",
      "Iteration: 80 Loss: 0.762941 acc :0.864811\n",
      "Iteration: 100 Loss: 0.763159 acc :0.864811\n",
      "Iteration: 120 Loss: 0.78588 acc :0.866799\n",
      "Iteration: 140 Loss: 0.778754 acc :0.866534\n",
      "Iteration: 160 Loss: 0.735926 acc :0.884462\n",
      "Iteration: 180 Loss: 0.814609 acc :0.854582\n",
      "validation Accuracy (1): 0.7505\n",
      "Iteration: 0 Loss: 0.756035 acc :0.86255\n",
      "Iteration: 20 Loss: 0.784682 acc :0.87251\n",
      "Iteration: 40 Loss: 0.808624 acc :0.866534\n",
      "Iteration: 60 Loss: 0.778561 acc :0.860558\n",
      "Iteration: 80 Loss: 0.756043 acc :0.882704\n",
      "Iteration: 100 Loss: 0.739418 acc :0.874751\n",
      "Iteration: 120 Loss: 0.811413 acc :0.858847\n",
      "Iteration: 140 Loss: 0.758892 acc :0.890438\n",
      "Iteration: 160 Loss: 0.74248 acc :0.876494\n",
      "Iteration: 180 Loss: 0.780608 acc :0.868526\n",
      "validation Accuracy (2): 0.7532\n",
      "Iteration: 0 Loss: 0.777236 acc :0.860558\n",
      "Iteration: 20 Loss: 0.773654 acc :0.878486\n",
      "Iteration: 40 Loss: 0.756658 acc :0.906375\n",
      "Iteration: 60 Loss: 0.744301 acc :0.880478\n",
      "Iteration: 80 Loss: 0.718023 acc :0.884692\n",
      "Iteration: 100 Loss: 0.726154 acc :0.876739\n",
      "Iteration: 120 Loss: 0.787713 acc :0.874751\n",
      "Iteration: 140 Loss: 0.746981 acc :0.886454\n",
      "Iteration: 160 Loss: 0.741986 acc :0.874502\n",
      "Iteration: 180 Loss: 0.77829 acc :0.876494\n",
      "validation Accuracy (3): 0.7509\n",
      "Iteration: 0 Loss: 0.74514 acc :0.88247\n",
      "Iteration: 20 Loss: 0.759275 acc :0.874502\n",
      "Iteration: 40 Loss: 0.787598 acc :0.870518\n",
      "Iteration: 60 Loss: 0.770893 acc :0.88247\n",
      "Iteration: 80 Loss: 0.734786 acc :0.87674\n",
      "Iteration: 100 Loss: 0.727013 acc :0.890656\n",
      "Iteration: 120 Loss: 0.793406 acc :0.878728\n",
      "Iteration: 140 Loss: 0.72824 acc :0.894422\n",
      "Iteration: 160 Loss: 0.748202 acc :0.88247\n",
      "Iteration: 180 Loss: 0.785883 acc :0.880478\n",
      "validation Accuracy (4): 0.7595\n",
      "Iteration: 0 Loss: 0.760069 acc :0.874502\n",
      "Iteration: 20 Loss: 0.771827 acc :0.888446\n",
      "Iteration: 40 Loss: 0.785182 acc :0.87251\n",
      "Iteration: 60 Loss: 0.749029 acc :0.894422\n",
      "Iteration: 80 Loss: 0.744926 acc :0.880716\n",
      "Iteration: 100 Loss: 0.728411 acc :0.890656\n",
      "Iteration: 120 Loss: 0.769448 acc :0.878728\n",
      "Iteration: 140 Loss: 0.713153 acc :0.896414\n",
      "Iteration: 160 Loss: 0.731714 acc :0.880478\n",
      "Iteration: 180 Loss: 0.778142 acc :0.884462\n",
      "validation Accuracy (5): 0.752\n",
      "Iteration: 0 Loss: 0.737754 acc :0.890438\n",
      "Iteration: 20 Loss: 0.754135 acc :0.880478\n",
      "Iteration: 40 Loss: 0.745325 acc :0.886454\n",
      "Iteration: 60 Loss: 0.769289 acc :0.878486\n",
      "Iteration: 80 Loss: 0.714239 acc :0.894632\n",
      "Iteration: 100 Loss: 0.714575 acc :0.882704\n",
      "Iteration: 120 Loss: 0.776534 acc :0.868787\n",
      "Iteration: 140 Loss: 0.723745 acc :0.886454\n",
      "Iteration: 160 Loss: 0.750363 acc :0.870518\n",
      "Iteration: 180 Loss: 0.756355 acc :0.888446\n",
      "validation Accuracy (6): 0.7625\n",
      "Iteration: 0 Loss: 0.715625 acc :0.896414\n",
      "Iteration: 20 Loss: 0.736407 acc :0.888446\n",
      "Iteration: 40 Loss: 0.746245 acc :0.884462\n",
      "Iteration: 60 Loss: 0.762515 acc :0.886454\n",
      "Iteration: 80 Loss: 0.74413 acc :0.884692\n",
      "Iteration: 100 Loss: 0.712786 acc :0.890656\n",
      "Iteration: 120 Loss: 0.768814 acc :0.882704\n",
      "Iteration: 140 Loss: 0.728599 acc :0.896414\n",
      "Iteration: 160 Loss: 0.703139 acc :0.908367\n",
      "Iteration: 180 Loss: 0.774391 acc :0.876494\n",
      "validation Accuracy (7): 0.7513\n",
      "Iteration: 0 Loss: 0.734762 acc :0.89243\n",
      "Iteration: 20 Loss: 0.726165 acc :0.896414\n",
      "Iteration: 40 Loss: 0.743397 acc :0.896414\n",
      "Iteration: 60 Loss: 0.802686 acc :0.864542\n",
      "Iteration: 80 Loss: 0.768553 acc :0.87674\n",
      "Iteration: 100 Loss: 0.702458 acc :0.900596\n",
      "Iteration: 120 Loss: 0.752554 acc :0.868787\n",
      "Iteration: 140 Loss: 0.732396 acc :0.914343\n",
      "Iteration: 160 Loss: 0.701777 acc :0.898406\n",
      "Iteration: 180 Loss: 0.789629 acc :0.870518\n",
      "validation Accuracy (8): 0.7589\n",
      "Iteration: 0 Loss: 0.734469 acc :0.884462\n",
      "Iteration: 20 Loss: 0.704265 acc :0.914343\n",
      "Iteration: 40 Loss: 0.748152 acc :0.88247\n",
      "Iteration: 60 Loss: 0.745797 acc :0.890438\n",
      "Iteration: 80 Loss: 0.733045 acc :0.888668\n",
      "Iteration: 100 Loss: 0.733691 acc :0.870775\n",
      "Iteration: 120 Loss: 0.798018 acc :0.856859\n",
      "Iteration: 140 Loss: 0.744518 acc :0.894422\n",
      "Iteration: 160 Loss: 0.723204 acc :0.890438\n",
      "Iteration: 180 Loss: 0.765095 acc :0.878486\n",
      "validation Accuracy (9): 0.759\n",
      "Iteration: 0 Loss: 0.75465 acc :0.894422\n",
      "Iteration: 20 Loss: 0.726632 acc :0.910359\n",
      "Iteration: 40 Loss: 0.738448 acc :0.896414\n",
      "Iteration: 60 Loss: 0.74231 acc :0.906374\n",
      "Iteration: 80 Loss: 0.725074 acc :0.894632\n",
      "Iteration: 100 Loss: 0.741382 acc :0.884692\n",
      "Iteration: 120 Loss: 0.809829 acc :0.850895\n",
      "Iteration: 140 Loss: 0.724269 acc :0.894422\n",
      "Iteration: 160 Loss: 0.689061 acc :0.896414\n",
      "Iteration: 180 Loss: 0.799164 acc :0.85259\n",
      "validation Accuracy (10): 0.7512\n",
      "Iteration: 0 Loss: 0.742924 acc :0.894422\n",
      "Iteration: 20 Loss: 0.774531 acc :0.89243\n",
      "Iteration: 40 Loss: 0.749318 acc :0.884462\n",
      "Iteration: 60 Loss: 0.742337 acc :0.904383\n",
      "Iteration: 80 Loss: 0.728974 acc :0.890656\n",
      "Iteration: 100 Loss: 0.69767 acc :0.904573\n",
      "Iteration: 120 Loss: 0.767484 acc :0.872763\n",
      "Iteration: 140 Loss: 0.718624 acc :0.896414\n",
      "Iteration: 160 Loss: 0.691144 acc :0.90239\n",
      "Iteration: 180 Loss: 0.756985 acc :0.894422\n",
      "validation Accuracy (11): 0.755\n",
      "Iteration: 0 Loss: 0.695206 acc :0.90239\n",
      "Iteration: 20 Loss: 0.723122 acc :0.900398\n",
      "Iteration: 40 Loss: 0.715672 acc :0.898406\n",
      "Iteration: 60 Loss: 0.719964 acc :0.89243\n",
      "Iteration: 80 Loss: 0.722306 acc :0.916501\n",
      "Iteration: 100 Loss: 0.71999 acc :0.890656\n",
      "Iteration: 120 Loss: 0.749676 acc :0.87674\n",
      "Iteration: 140 Loss: 0.732289 acc :0.894422\n",
      "Iteration: 160 Loss: 0.695751 acc :0.896414\n",
      "Iteration: 180 Loss: 0.791619 acc :0.874502\n",
      "validation Accuracy (12): 0.7562\n",
      "Iteration: 0 Loss: 0.718289 acc :0.904382\n",
      "Iteration: 20 Loss: 0.702261 acc :0.924303\n",
      "Iteration: 40 Loss: 0.731357 acc :0.890438\n",
      "Iteration: 60 Loss: 0.74864 acc :0.888446\n",
      "Iteration: 80 Loss: 0.725534 acc :0.894632\n",
      "Iteration: 100 Loss: 0.717288 acc :0.890656\n",
      "Iteration: 120 Loss: 0.751841 acc :0.898608\n",
      "Iteration: 140 Loss: 0.74321 acc :0.898406\n",
      "Iteration: 160 Loss: 0.7047 acc :0.898406\n",
      "Iteration: 180 Loss: 0.780839 acc :0.898406\n",
      "validation Accuracy (13): 0.7557\n",
      "Iteration: 0 Loss: 0.720678 acc :0.912351\n",
      "Iteration: 20 Loss: 0.725514 acc :0.898406\n",
      "Iteration: 40 Loss: 0.725978 acc :0.88247\n",
      "Iteration: 60 Loss: 0.755684 acc :0.888446\n",
      "Iteration: 80 Loss: 0.689353 acc :0.912525\n",
      "Iteration: 100 Loss: 0.711576 acc :0.89662\n",
      "Iteration: 120 Loss: 0.775939 acc :0.888668\n",
      "Iteration: 140 Loss: 0.712233 acc :0.906375\n",
      "Iteration: 160 Loss: 0.687714 acc :0.904382\n",
      "Iteration: 180 Loss: 0.722193 acc :0.898406\n",
      "validation Accuracy (14): 0.753\n",
      "Iteration: 0 Loss: 0.699473 acc :0.906375\n",
      "Iteration: 20 Loss: 0.709735 acc :0.916335\n",
      "Iteration: 40 Loss: 0.702801 acc :0.90239\n",
      "Iteration: 60 Loss: 0.746839 acc :0.900398\n",
      "Iteration: 80 Loss: 0.719009 acc :0.898608\n",
      "Iteration: 100 Loss: 0.728701 acc :0.900596\n",
      "Iteration: 120 Loss: 0.735899 acc :0.890656\n",
      "Iteration: 140 Loss: 0.707364 acc :0.904382\n",
      "Iteration: 160 Loss: 0.688556 acc :0.908367\n",
      "Iteration: 180 Loss: 0.763891 acc :0.890438\n",
      "validation Accuracy (15): 0.7578\n",
      "Iteration: 0 Loss: 0.718635 acc :0.89243\n",
      "Iteration: 20 Loss: 0.719831 acc :0.920319\n",
      "Iteration: 40 Loss: 0.738031 acc :0.896414\n",
      "Iteration: 60 Loss: 0.726257 acc :0.896414\n",
      "Iteration: 80 Loss: 0.737888 acc :0.88668\n",
      "Iteration: 100 Loss: 0.714474 acc :0.904573\n",
      "Iteration: 120 Loss: 0.737472 acc :0.88668\n",
      "Iteration: 140 Loss: 0.735279 acc :0.884462\n",
      "Iteration: 160 Loss: 0.73127 acc :0.890438\n",
      "Iteration: 180 Loss: 0.787528 acc :0.88247\n",
      "validation Accuracy (16): 0.7547\n",
      "Iteration: 0 Loss: 0.677897 acc :0.924303\n",
      "Iteration: 20 Loss: 0.744179 acc :0.898406\n",
      "Iteration: 40 Loss: 0.723712 acc :0.904383\n",
      "Iteration: 60 Loss: 0.782301 acc :0.874502\n",
      "Iteration: 80 Loss: 0.733812 acc :0.902584\n",
      "Iteration: 100 Loss: 0.704276 acc :0.910537\n",
      "Iteration: 120 Loss: 0.750582 acc :0.89662\n",
      "Iteration: 140 Loss: 0.712269 acc :0.890438\n",
      "Iteration: 160 Loss: 0.736806 acc :0.894422\n",
      "Iteration: 180 Loss: 0.775586 acc :0.884462\n",
      "validation Accuracy (17): 0.7619\n",
      "Iteration: 0 Loss: 0.691716 acc :0.920319\n",
      "Iteration: 20 Loss: 0.707884 acc :0.910359\n",
      "Iteration: 40 Loss: 0.717503 acc :0.914343\n",
      "Iteration: 60 Loss: 0.725292 acc :0.914343\n",
      "Iteration: 80 Loss: 0.719138 acc :0.900596\n",
      "Iteration: 100 Loss: 0.717313 acc :0.888668\n",
      "Iteration: 120 Loss: 0.738359 acc :0.900596\n",
      "Iteration: 140 Loss: 0.727796 acc :0.906375\n",
      "Iteration: 160 Loss: 0.687047 acc :0.912351\n",
      "Iteration: 180 Loss: 0.785626 acc :0.89243\n",
      "validation Accuracy (18): 0.7524\n",
      "Iteration: 0 Loss: 0.705617 acc :0.914343\n",
      "Iteration: 20 Loss: 0.706196 acc :0.904383\n",
      "Iteration: 40 Loss: 0.719122 acc :0.89243\n",
      "Iteration: 60 Loss: 0.757214 acc :0.896414\n",
      "Iteration: 80 Loss: 0.734478 acc :0.892644\n",
      "Iteration: 100 Loss: 0.710348 acc :0.902584\n",
      "Iteration: 120 Loss: 0.759731 acc :0.890656\n",
      "Iteration: 140 Loss: 0.73108 acc :0.90239\n",
      "Iteration: 160 Loss: 0.722032 acc :0.894422\n",
      "Iteration: 180 Loss: 0.792735 acc :0.868526\n",
      "validation Accuracy (19): 0.7581\n",
      "Iteration: 0 Loss: 0.692938 acc :0.912351\n",
      "Iteration: 20 Loss: 0.728263 acc :0.918327\n",
      "Iteration: 40 Loss: 0.718167 acc :0.904383\n",
      "Iteration: 60 Loss: 0.741451 acc :0.898406\n",
      "Iteration: 80 Loss: 0.713366 acc :0.910537\n",
      "Iteration: 100 Loss: 0.728936 acc :0.88668\n",
      "Iteration: 120 Loss: 0.747815 acc :0.894632\n",
      "Iteration: 140 Loss: 0.730777 acc :0.906375\n",
      "Iteration: 160 Loss: 0.688727 acc :0.916335\n",
      "Iteration: 180 Loss: 0.76442 acc :0.880478\n",
      "validation Accuracy (20): 0.7554\n",
      "Iteration: 0 Loss: 0.689453 acc :0.904382\n",
      "Iteration: 20 Loss: 0.696387 acc :0.922311\n",
      "Iteration: 40 Loss: 0.700376 acc :0.898406\n",
      "Iteration: 60 Loss: 0.726996 acc :0.904383\n",
      "Iteration: 80 Loss: 0.735491 acc :0.888668\n",
      "Iteration: 100 Loss: 0.71564 acc :0.906561\n",
      "Iteration: 120 Loss: 0.772179 acc :0.872763\n",
      "Iteration: 140 Loss: 0.721328 acc :0.898406\n",
      "Iteration: 160 Loss: 0.688215 acc :0.910359\n",
      "Iteration: 180 Loss: 0.758907 acc :0.890438\n",
      "validation Accuracy (21): 0.755\n",
      "Iteration: 0 Loss: 0.709677 acc :0.920319\n",
      "Iteration: 20 Loss: 0.711083 acc :0.912351\n",
      "Iteration: 40 Loss: 0.692128 acc :0.918327\n",
      "Iteration: 60 Loss: 0.737602 acc :0.906375\n",
      "Iteration: 80 Loss: 0.697623 acc :0.910537\n",
      "Iteration: 100 Loss: 0.711415 acc :0.89662\n",
      "Iteration: 120 Loss: 0.759452 acc :0.892644\n",
      "Iteration: 140 Loss: 0.724426 acc :0.894422\n",
      "Iteration: 160 Loss: 0.693308 acc :0.90239\n",
      "Iteration: 180 Loss: 0.787724 acc :0.880478\n",
      "validation Accuracy (22): 0.7559\n",
      "Iteration: 0 Loss: 0.665381 acc :0.924303\n",
      "Iteration: 20 Loss: 0.714756 acc :0.910359\n",
      "Iteration: 40 Loss: 0.697049 acc :0.916335\n",
      "Iteration: 60 Loss: 0.734924 acc :0.908367\n",
      "Iteration: 80 Loss: 0.704065 acc :0.920477\n",
      "Iteration: 100 Loss: 0.71728 acc :0.900596\n",
      "Iteration: 120 Loss: 0.795451 acc :0.868787\n",
      "Iteration: 140 Loss: 0.718745 acc :0.904382\n",
      "Iteration: 160 Loss: 0.680314 acc :0.910359\n",
      "Iteration: 180 Loss: 0.750074 acc :0.884462\n",
      "validation Accuracy (23): 0.7558\n",
      "Iteration: 0 Loss: 0.705217 acc :0.904383\n",
      "Iteration: 20 Loss: 0.71016 acc :0.910359\n",
      "Iteration: 40 Loss: 0.712247 acc :0.906374\n",
      "Iteration: 60 Loss: 0.713141 acc :0.912351\n",
      "Iteration: 80 Loss: 0.700054 acc :0.904572\n",
      "Iteration: 100 Loss: 0.696085 acc :0.914513\n",
      "Iteration: 120 Loss: 0.748594 acc :0.884692\n",
      "Iteration: 140 Loss: 0.721102 acc :0.910359\n",
      "Iteration: 160 Loss: 0.672972 acc :0.916335\n",
      "Iteration: 180 Loss: 0.767377 acc :0.884462\n",
      "validation Accuracy (24): 0.7556\n",
      "Iteration: 0 Loss: 0.700163 acc :0.906375\n",
      "Iteration: 20 Loss: 0.747665 acc :0.904382\n",
      "Iteration: 40 Loss: 0.66299 acc :0.924303\n",
      "Iteration: 60 Loss: 0.69935 acc :0.916335\n",
      "Iteration: 80 Loss: 0.713297 acc :0.898608\n",
      "Iteration: 100 Loss: 0.699118 acc :0.906561\n",
      "Iteration: 120 Loss: 0.750651 acc :0.89662\n",
      "Iteration: 140 Loss: 0.720963 acc :0.912351\n",
      "Iteration: 160 Loss: 0.679332 acc :0.918327\n",
      "Iteration: 180 Loss: 0.772266 acc :0.876494\n",
      "validation Accuracy (25): 0.7547\n",
      "Iteration: 0 Loss: 0.713423 acc :0.908367\n",
      "Iteration: 20 Loss: 0.732507 acc :0.896414\n",
      "Iteration: 40 Loss: 0.698949 acc :0.930279\n",
      "Iteration: 60 Loss: 0.705758 acc :0.912351\n",
      "Iteration: 80 Loss: 0.703418 acc :0.926441\n",
      "Iteration: 100 Loss: 0.691501 acc :0.898608\n",
      "Iteration: 120 Loss: 0.747719 acc :0.890656\n",
      "Iteration: 140 Loss: 0.730508 acc :0.90239\n",
      "Iteration: 160 Loss: 0.675131 acc :0.910359\n",
      "Iteration: 180 Loss: 0.794623 acc :0.874502\n",
      "validation Accuracy (26): 0.7585\n",
      "Iteration: 0 Loss: 0.695269 acc :0.910359\n",
      "Iteration: 20 Loss: 0.725379 acc :0.912351\n",
      "Iteration: 40 Loss: 0.688877 acc :0.908367\n",
      "Iteration: 60 Loss: 0.725814 acc :0.916335\n",
      "Iteration: 80 Loss: 0.719615 acc :0.908549\n",
      "Iteration: 100 Loss: 0.727131 acc :0.888668\n",
      "Iteration: 120 Loss: 0.752274 acc :0.894632\n",
      "Iteration: 140 Loss: 0.695909 acc :0.914343\n",
      "Iteration: 160 Loss: 0.695051 acc :0.902391\n",
      "Iteration: 180 Loss: 0.746123 acc :0.886454\n",
      "validation Accuracy (27): 0.7584\n",
      "Iteration: 0 Loss: 0.710045 acc :0.896414\n",
      "Iteration: 20 Loss: 0.737599 acc :0.90239\n",
      "Iteration: 40 Loss: 0.682506 acc :0.916335\n",
      "Iteration: 60 Loss: 0.735217 acc :0.900398\n",
      "Iteration: 80 Loss: 0.705923 acc :0.898608\n",
      "Iteration: 100 Loss: 0.686829 acc :0.918489\n",
      "Iteration: 120 Loss: 0.744427 acc :0.890656\n",
      "Iteration: 140 Loss: 0.713183 acc :0.912351\n",
      "Iteration: 160 Loss: 0.698516 acc :0.900398\n",
      "Iteration: 180 Loss: 0.779735 acc :0.886454\n",
      "validation Accuracy (28): 0.7546\n",
      "Iteration: 0 Loss: 0.706229 acc :0.912351\n",
      "Iteration: 20 Loss: 0.735056 acc :0.904383\n",
      "Iteration: 40 Loss: 0.694134 acc :0.918327\n",
      "Iteration: 60 Loss: 0.707973 acc :0.912351\n",
      "Iteration: 80 Loss: 0.693794 acc :0.920477\n",
      "Iteration: 100 Loss: 0.697463 acc :0.898608\n",
      "Iteration: 120 Loss: 0.763432 acc :0.888668\n",
      "Iteration: 140 Loss: 0.68019 acc :0.914343\n",
      "Iteration: 160 Loss: 0.674788 acc :0.910359\n",
      "Iteration: 180 Loss: 0.748723 acc :0.876494\n",
      "validation Accuracy (29): 0.7616\n",
      "Iteration: 0 Loss: 0.702419 acc :0.912351\n",
      "Iteration: 20 Loss: 0.707914 acc :0.926295\n",
      "Iteration: 40 Loss: 0.706101 acc :0.912351\n",
      "Iteration: 60 Loss: 0.726854 acc :0.908367\n",
      "Iteration: 80 Loss: 0.70109 acc :0.906561\n",
      "Iteration: 100 Loss: 0.684871 acc :0.904573\n",
      "Iteration: 120 Loss: 0.780705 acc :0.88668\n",
      "Iteration: 140 Loss: 0.69182 acc :0.908367\n",
      "Iteration: 160 Loss: 0.683536 acc :0.894422\n",
      "Iteration: 180 Loss: 0.738316 acc :0.894422\n",
      "validation Accuracy (30): 0.752\n",
      "Iteration: 0 Loss: 0.700255 acc :0.910359\n",
      "Iteration: 20 Loss: 0.723635 acc :0.904382\n",
      "Iteration: 40 Loss: 0.686217 acc :0.912351\n",
      "Iteration: 60 Loss: 0.752131 acc :0.888446\n",
      "Iteration: 80 Loss: 0.678119 acc :0.914513\n",
      "Iteration: 100 Loss: 0.677401 acc :0.914513\n",
      "Iteration: 120 Loss: 0.742739 acc :0.902584\n",
      "Iteration: 140 Loss: 0.701509 acc :0.920319\n",
      "Iteration: 160 Loss: 0.702856 acc :0.900398\n",
      "Iteration: 180 Loss: 0.71986 acc :0.890438\n",
      "validation Accuracy (31): 0.7591\n",
      "Iteration: 0 Loss: 0.703265 acc :0.912351\n",
      "Iteration: 20 Loss: 0.695177 acc :0.916335\n",
      "Iteration: 40 Loss: 0.726503 acc :0.908367\n",
      "Iteration: 60 Loss: 0.731736 acc :0.908367\n",
      "Iteration: 80 Loss: 0.711163 acc :0.908549\n",
      "Iteration: 100 Loss: 0.68505 acc :0.922465\n",
      "Iteration: 120 Loss: 0.733441 acc :0.902584\n",
      "Iteration: 140 Loss: 0.723211 acc :0.912351\n",
      "Iteration: 160 Loss: 0.681667 acc :0.906375\n",
      "Iteration: 180 Loss: 0.731718 acc :0.888446\n",
      "validation Accuracy (32): 0.7579\n",
      "Iteration: 0 Loss: 0.686246 acc :0.926295\n",
      "Iteration: 20 Loss: 0.709721 acc :0.914343\n",
      "Iteration: 40 Loss: 0.712125 acc :0.898406\n",
      "Iteration: 60 Loss: 0.728111 acc :0.894422\n",
      "Iteration: 80 Loss: 0.694879 acc :0.910537\n",
      "Iteration: 100 Loss: 0.690001 acc :0.910537\n",
      "Iteration: 120 Loss: 0.761729 acc :0.88668\n",
      "Iteration: 140 Loss: 0.716585 acc :0.900398\n",
      "Iteration: 160 Loss: 0.657664 acc :0.930279\n",
      "Iteration: 180 Loss: 0.734079 acc :0.908367\n",
      "validation Accuracy (33): 0.7567\n",
      "Iteration: 0 Loss: 0.683283 acc :0.922311\n",
      "Iteration: 20 Loss: 0.727951 acc :0.914343\n",
      "Iteration: 40 Loss: 0.726549 acc :0.896414\n",
      "Iteration: 60 Loss: 0.699232 acc :0.920319\n",
      "Iteration: 80 Loss: 0.706004 acc :0.906561\n",
      "Iteration: 100 Loss: 0.680181 acc :0.920477\n",
      "Iteration: 120 Loss: 0.75946 acc :0.89662\n",
      "Iteration: 140 Loss: 0.70536 acc :0.914343\n",
      "Iteration: 160 Loss: 0.692991 acc :0.912351\n",
      "Iteration: 180 Loss: 0.719619 acc :0.912351\n",
      "validation Accuracy (34): 0.7519\n",
      "Iteration: 0 Loss: 0.711037 acc :0.898406\n",
      "Iteration: 20 Loss: 0.6949 acc :0.928287\n",
      "Iteration: 40 Loss: 0.723101 acc :0.888446\n",
      "Iteration: 60 Loss: 0.712845 acc :0.906375\n",
      "Iteration: 80 Loss: 0.701589 acc :0.904573\n",
      "Iteration: 100 Loss: 0.704784 acc :0.910537\n",
      "Iteration: 120 Loss: 0.742354 acc :0.88668\n",
      "Iteration: 140 Loss: 0.7026 acc :0.918327\n",
      "Iteration: 160 Loss: 0.704176 acc :0.908367\n",
      "Iteration: 180 Loss: 0.734959 acc :0.876494\n",
      "validation Accuracy (35): 0.7562\n",
      "Iteration: 0 Loss: 0.689411 acc :0.924303\n",
      "Iteration: 20 Loss: 0.712814 acc :0.910359\n",
      "Iteration: 40 Loss: 0.695732 acc :0.904382\n",
      "Iteration: 60 Loss: 0.736175 acc :0.912351\n",
      "Iteration: 80 Loss: 0.695474 acc :0.914513\n",
      "Iteration: 100 Loss: 0.696833 acc :0.918489\n",
      "Iteration: 120 Loss: 0.74948 acc :0.894632\n",
      "Iteration: 140 Loss: 0.693182 acc :0.916335\n",
      "Iteration: 160 Loss: 0.716935 acc :0.89243\n",
      "Iteration: 180 Loss: 0.728337 acc :0.898407\n",
      "validation Accuracy (36): 0.7509\n",
      "Iteration: 0 Loss: 0.710126 acc :0.898406\n",
      "Iteration: 20 Loss: 0.712351 acc :0.912351\n",
      "Iteration: 40 Loss: 0.716788 acc :0.896414\n",
      "Iteration: 60 Loss: 0.747649 acc :0.878486\n",
      "Iteration: 80 Loss: 0.71349 acc :0.904572\n",
      "Iteration: 100 Loss: 0.688018 acc :0.908549\n",
      "Iteration: 120 Loss: 0.747169 acc :0.89662\n",
      "Iteration: 140 Loss: 0.703256 acc :0.910359\n",
      "Iteration: 160 Loss: 0.69574 acc :0.910359\n",
      "Iteration: 180 Loss: 0.747036 acc :0.894422\n",
      "validation Accuracy (37): 0.7581\n",
      "Iteration: 0 Loss: 0.709422 acc :0.904382\n",
      "Iteration: 20 Loss: 0.698017 acc :0.924303\n",
      "Iteration: 40 Loss: 0.700513 acc :0.906375\n",
      "Iteration: 60 Loss: 0.723655 acc :0.904382\n",
      "Iteration: 80 Loss: 0.708207 acc :0.910537\n",
      "Iteration: 100 Loss: 0.711431 acc :0.890656\n",
      "Iteration: 120 Loss: 0.783473 acc :0.87674\n",
      "Iteration: 140 Loss: 0.698684 acc :0.916335\n",
      "Iteration: 160 Loss: 0.73844 acc :0.904382\n",
      "Iteration: 180 Loss: 0.761043 acc :0.884462\n",
      "validation Accuracy (38): 0.7604\n",
      "Iteration: 0 Loss: 0.706448 acc :0.916335\n",
      "Iteration: 20 Loss: 0.698234 acc :0.908367\n",
      "Iteration: 40 Loss: 0.714124 acc :0.90239\n",
      "Iteration: 60 Loss: 0.710399 acc :0.922311\n",
      "Iteration: 80 Loss: 0.704036 acc :0.900596\n",
      "Iteration: 100 Loss: 0.699637 acc :0.906561\n",
      "Iteration: 120 Loss: 0.725231 acc :0.898608\n",
      "Iteration: 140 Loss: 0.705011 acc :0.920319\n",
      "Iteration: 160 Loss: 0.687422 acc :0.906375\n",
      "Iteration: 180 Loss: 0.770763 acc :0.884462\n",
      "validation Accuracy (39): 0.7573\n",
      "Iteration: 0 Loss: 0.689523 acc :0.918327\n",
      "Iteration: 20 Loss: 0.695677 acc :0.918327\n",
      "Iteration: 40 Loss: 0.725501 acc :0.89243\n",
      "Iteration: 60 Loss: 0.745948 acc :0.89243\n",
      "Iteration: 80 Loss: 0.723521 acc :0.900596\n",
      "Iteration: 100 Loss: 0.699562 acc :0.902584\n",
      "Iteration: 120 Loss: 0.748002 acc :0.908549\n",
      "Iteration: 140 Loss: 0.692981 acc :0.906375\n",
      "Iteration: 160 Loss: 0.712339 acc :0.900398\n",
      "Iteration: 180 Loss: 0.730909 acc :0.900398\n",
      "validation Accuracy (40): 0.7595\n",
      "Iteration: 0 Loss: 0.681418 acc :0.914343\n",
      "Iteration: 20 Loss: 0.683737 acc :0.922311\n",
      "Iteration: 40 Loss: 0.714945 acc :0.900398\n",
      "Iteration: 60 Loss: 0.727438 acc :0.904383\n",
      "Iteration: 80 Loss: 0.699438 acc :0.910537\n",
      "Iteration: 100 Loss: 0.721884 acc :0.906561\n",
      "Iteration: 120 Loss: 0.753158 acc :0.904573\n",
      "Iteration: 140 Loss: 0.689138 acc :0.916335\n",
      "Iteration: 160 Loss: 0.685577 acc :0.912351\n",
      "Iteration: 180 Loss: 0.747464 acc :0.898406\n",
      "validation Accuracy (41): 0.759\n",
      "Iteration: 0 Loss: 0.683769 acc :0.914343\n",
      "Iteration: 20 Loss: 0.697892 acc :0.908367\n",
      "Iteration: 40 Loss: 0.718113 acc :0.898406\n",
      "Iteration: 60 Loss: 0.703647 acc :0.908367\n",
      "Iteration: 80 Loss: 0.675732 acc :0.912525\n",
      "Iteration: 100 Loss: 0.719513 acc :0.898608\n",
      "Iteration: 120 Loss: 0.741727 acc :0.892644\n",
      "Iteration: 140 Loss: 0.703954 acc :0.908367\n",
      "Iteration: 160 Loss: 0.708013 acc :0.90239\n",
      "Iteration: 180 Loss: 0.765779 acc :0.896414\n",
      "validation Accuracy (42): 0.7558\n",
      "Iteration: 0 Loss: 0.690303 acc :0.920319\n",
      "Iteration: 20 Loss: 0.688013 acc :0.922311\n",
      "Iteration: 40 Loss: 0.729444 acc :0.894422\n",
      "Iteration: 60 Loss: 0.689087 acc :0.928287\n",
      "Iteration: 80 Loss: 0.698969 acc :0.932406\n",
      "Iteration: 100 Loss: 0.697261 acc :0.910537\n",
      "Iteration: 120 Loss: 0.734249 acc :0.898608\n",
      "Iteration: 140 Loss: 0.693117 acc :0.916335\n",
      "Iteration: 160 Loss: 0.6924 acc :0.912351\n",
      "Iteration: 180 Loss: 0.758832 acc :0.89243\n",
      "validation Accuracy (43): 0.7546\n",
      "Iteration: 0 Loss: 0.700371 acc :0.906375\n",
      "Iteration: 20 Loss: 0.716132 acc :0.906375\n",
      "Iteration: 40 Loss: 0.695153 acc :0.922311\n",
      "Iteration: 60 Loss: 0.735799 acc :0.894422\n",
      "Iteration: 80 Loss: 0.714436 acc :0.902584\n",
      "Iteration: 100 Loss: 0.715909 acc :0.898608\n",
      "Iteration: 120 Loss: 0.74298 acc :0.888668\n",
      "Iteration: 140 Loss: 0.70873 acc :0.922311\n",
      "Iteration: 160 Loss: 0.702415 acc :0.906375\n",
      "Iteration: 180 Loss: 0.75276 acc :0.880478\n",
      "validation Accuracy (44): 0.7491\n",
      "Iteration: 0 Loss: 0.692482 acc :0.922311\n",
      "Iteration: 20 Loss: 0.68516 acc :0.926295\n",
      "Iteration: 40 Loss: 0.698221 acc :0.922311\n",
      "Iteration: 60 Loss: 0.697613 acc :0.922311\n",
      "Iteration: 80 Loss: 0.682381 acc :0.922465\n",
      "Iteration: 100 Loss: 0.69122 acc :0.910537\n",
      "Iteration: 120 Loss: 0.729094 acc :0.888668\n",
      "Iteration: 140 Loss: 0.706761 acc :0.916335\n",
      "Iteration: 160 Loss: 0.723785 acc :0.898406\n",
      "Iteration: 180 Loss: 0.73277 acc :0.89243\n",
      "validation Accuracy (45): 0.7489\n",
      "Iteration: 0 Loss: 0.694983 acc :0.908367\n",
      "Iteration: 20 Loss: 0.716064 acc :0.916335\n",
      "Iteration: 40 Loss: 0.697982 acc :0.912351\n",
      "Iteration: 60 Loss: 0.709299 acc :0.916335\n",
      "Iteration: 80 Loss: 0.684336 acc :0.922465\n",
      "Iteration: 100 Loss: 0.733497 acc :0.892644\n",
      "Iteration: 120 Loss: 0.73967 acc :0.892644\n",
      "Iteration: 140 Loss: 0.699376 acc :0.922311\n",
      "Iteration: 160 Loss: 0.683143 acc :0.912351\n",
      "Iteration: 180 Loss: 0.745883 acc :0.884462\n",
      "validation Accuracy (46): 0.7558\n",
      "Iteration: 0 Loss: 0.717781 acc :0.908367\n",
      "Iteration: 20 Loss: 0.706918 acc :0.916335\n",
      "Iteration: 40 Loss: 0.694614 acc :0.920319\n",
      "Iteration: 60 Loss: 0.719139 acc :0.914343\n",
      "Iteration: 80 Loss: 0.692085 acc :0.916501\n",
      "Iteration: 100 Loss: 0.710042 acc :0.906561\n",
      "Iteration: 120 Loss: 0.752811 acc :0.884692\n",
      "Iteration: 140 Loss: 0.717942 acc :0.902391\n",
      "Iteration: 160 Loss: 0.688787 acc :0.908367\n",
      "Iteration: 180 Loss: 0.729781 acc :0.888446\n",
      "validation Accuracy (47): 0.7538\n",
      "Iteration: 0 Loss: 0.733628 acc :0.908367\n",
      "Iteration: 20 Loss: 0.67762 acc :0.936255\n",
      "Iteration: 40 Loss: 0.68418 acc :0.916335\n",
      "Iteration: 60 Loss: 0.715234 acc :0.918327\n",
      "Iteration: 80 Loss: 0.677158 acc :0.908549\n",
      "Iteration: 100 Loss: 0.699602 acc :0.904573\n",
      "Iteration: 120 Loss: 0.733732 acc :0.898608\n",
      "Iteration: 140 Loss: 0.708258 acc :0.90239\n",
      "Iteration: 160 Loss: 0.689522 acc :0.912351\n",
      "Iteration: 180 Loss: 0.746057 acc :0.894422\n",
      "validation Accuracy (48): 0.7536\n",
      "Iteration: 0 Loss: 0.704636 acc :0.918327\n",
      "Iteration: 20 Loss: 0.69634 acc :0.914343\n",
      "Iteration: 40 Loss: 0.69917 acc :0.908367\n",
      "Iteration: 60 Loss: 0.720536 acc :0.904383\n",
      "Iteration: 80 Loss: 0.710967 acc :0.900596\n",
      "Iteration: 100 Loss: 0.714984 acc :0.906561\n",
      "Iteration: 120 Loss: 0.76326 acc :0.892644\n",
      "Iteration: 140 Loss: 0.704906 acc :0.912351\n",
      "Iteration: 160 Loss: 0.693458 acc :0.912351\n",
      "Iteration: 180 Loss: 0.737702 acc :0.90239\n",
      "validation Accuracy (49): 0.7586\n",
      "Iteration: 0 Loss: 0.689822 acc :0.912351\n",
      "Iteration: 20 Loss: 0.705588 acc :0.920319\n",
      "Iteration: 40 Loss: 0.68405 acc :0.918327\n",
      "Iteration: 60 Loss: 0.723056 acc :0.916335\n",
      "Iteration: 80 Loss: 0.71515 acc :0.900596\n",
      "Iteration: 100 Loss: 0.677491 acc :0.920477\n",
      "Iteration: 120 Loss: 0.745397 acc :0.902584\n",
      "Iteration: 140 Loss: 0.673157 acc :0.916335\n",
      "Iteration: 160 Loss: 0.678658 acc :0.924303\n",
      "Iteration: 180 Loss: 0.741755 acc :0.890438\n",
      "validation Accuracy (50): 0.752\n",
      "Iteration: 0 Loss: 0.734203 acc :0.888446\n",
      "Iteration: 20 Loss: 0.707407 acc :0.924303\n",
      "Iteration: 40 Loss: 0.70032 acc :0.910359\n",
      "Iteration: 60 Loss: 0.733631 acc :0.904383\n",
      "Iteration: 80 Loss: 0.683608 acc :0.912525\n",
      "Iteration: 100 Loss: 0.691894 acc :0.918489\n",
      "Iteration: 120 Loss: 0.761887 acc :0.900596\n",
      "Iteration: 140 Loss: 0.707386 acc :0.914343\n",
      "Iteration: 160 Loss: 0.718854 acc :0.90239\n",
      "Iteration: 180 Loss: 0.753591 acc :0.880478\n",
      "validation Accuracy (51): 0.7502\n",
      "Iteration: 0 Loss: 0.70964 acc :0.900398\n",
      "Iteration: 20 Loss: 0.700614 acc :0.920319\n",
      "Iteration: 40 Loss: 0.689132 acc :0.912351\n",
      "Iteration: 60 Loss: 0.720562 acc :0.89243\n",
      "Iteration: 80 Loss: 0.707225 acc :0.910537\n",
      "Iteration: 100 Loss: 0.706465 acc :0.904573\n",
      "Iteration: 120 Loss: 0.782939 acc :0.884692\n",
      "Iteration: 140 Loss: 0.700207 acc :0.906375\n",
      "Iteration: 160 Loss: 0.688769 acc :0.916335\n",
      "Iteration: 180 Loss: 0.738907 acc :0.886454\n",
      "validation Accuracy (52): 0.753\n",
      "Iteration: 0 Loss: 0.688333 acc :0.908367\n",
      "Iteration: 20 Loss: 0.721362 acc :0.910359\n",
      "Iteration: 40 Loss: 0.719432 acc :0.908367\n",
      "Iteration: 60 Loss: 0.716452 acc :0.912351\n",
      "Iteration: 80 Loss: 0.683863 acc :0.926441\n",
      "Iteration: 100 Loss: 0.700817 acc :0.912525\n",
      "Iteration: 120 Loss: 0.745131 acc :0.890656\n",
      "Iteration: 140 Loss: 0.719561 acc :0.916335\n",
      "Iteration: 160 Loss: 0.696903 acc :0.918327\n",
      "Iteration: 180 Loss: 0.75297 acc :0.886454\n",
      "validation Accuracy (53): 0.7582\n",
      "Iteration: 0 Loss: 0.706963 acc :0.906375\n",
      "Iteration: 20 Loss: 0.719809 acc :0.900398\n",
      "Iteration: 40 Loss: 0.714419 acc :0.908367\n",
      "Iteration: 60 Loss: 0.737198 acc :0.896414\n",
      "Iteration: 80 Loss: 0.70054 acc :0.904573\n",
      "Iteration: 100 Loss: 0.682638 acc :0.910537\n",
      "Iteration: 120 Loss: 0.733796 acc :0.888668\n",
      "Iteration: 140 Loss: 0.720835 acc :0.910359\n",
      "Iteration: 160 Loss: 0.703514 acc :0.918327\n",
      "Iteration: 180 Loss: 0.757098 acc :0.878486\n",
      "validation Accuracy (54): 0.7588\n",
      "Iteration: 0 Loss: 0.704714 acc :0.914343\n",
      "Iteration: 20 Loss: 0.697658 acc :0.922311\n",
      "Iteration: 40 Loss: 0.706932 acc :0.910359\n",
      "Iteration: 60 Loss: 0.720735 acc :0.904383\n",
      "Iteration: 80 Loss: 0.687185 acc :0.912525\n",
      "Iteration: 100 Loss: 0.678 acc :0.906561\n",
      "Iteration: 120 Loss: 0.707894 acc :0.910537\n",
      "Iteration: 140 Loss: 0.71213 acc :0.90239\n",
      "Iteration: 160 Loss: 0.699622 acc :0.904382\n",
      "Iteration: 180 Loss: 0.762933 acc :0.880478\n",
      "validation Accuracy (55): 0.7576\n",
      "Iteration: 0 Loss: 0.683468 acc :0.922311\n",
      "Iteration: 20 Loss: 0.693017 acc :0.908367\n",
      "Iteration: 40 Loss: 0.735979 acc :0.884462\n",
      "Iteration: 60 Loss: 0.719491 acc :0.89243\n",
      "Iteration: 80 Loss: 0.702098 acc :0.906561\n",
      "Iteration: 100 Loss: 0.721924 acc :0.89662\n",
      "Iteration: 120 Loss: 0.738926 acc :0.900596\n",
      "Iteration: 140 Loss: 0.697685 acc :0.924303\n",
      "Iteration: 160 Loss: 0.69856 acc :0.928287\n",
      "Iteration: 180 Loss: 0.783175 acc :0.876494\n",
      "validation Accuracy (56): 0.7536\n",
      "Iteration: 0 Loss: 0.699453 acc :0.914343\n",
      "Iteration: 20 Loss: 0.676081 acc :0.938247\n",
      "Iteration: 40 Loss: 0.705259 acc :0.908367\n",
      "Iteration: 60 Loss: 0.71892 acc :0.908367\n",
      "Iteration: 80 Loss: 0.706828 acc :0.900596\n",
      "Iteration: 100 Loss: 0.695872 acc :0.912525\n",
      "Iteration: 120 Loss: 0.762298 acc :0.902584\n",
      "Iteration: 140 Loss: 0.702983 acc :0.918327\n",
      "Iteration: 160 Loss: 0.726457 acc :0.906375\n",
      "Iteration: 180 Loss: 0.74664 acc :0.890438\n",
      "validation Accuracy (57): 0.753\n",
      "Iteration: 0 Loss: 0.695347 acc :0.916335\n",
      "Iteration: 20 Loss: 0.705141 acc :0.918327\n",
      "Iteration: 40 Loss: 0.69194 acc :0.912351\n",
      "Iteration: 60 Loss: 0.701692 acc :0.916335\n",
      "Iteration: 80 Loss: 0.684648 acc :0.894632\n",
      "Iteration: 100 Loss: 0.719148 acc :0.892644\n",
      "Iteration: 120 Loss: 0.747236 acc :0.898608\n",
      "Iteration: 140 Loss: 0.681904 acc :0.918327\n",
      "Iteration: 160 Loss: 0.678059 acc :0.914343\n",
      "Iteration: 180 Loss: 0.741482 acc :0.886454\n",
      "validation Accuracy (58): 0.7558\n",
      "Iteration: 0 Loss: 0.688841 acc :0.920319\n",
      "Iteration: 20 Loss: 0.693564 acc :0.916335\n",
      "Iteration: 40 Loss: 0.680052 acc :0.924303\n",
      "Iteration: 60 Loss: 0.697822 acc :0.922311\n",
      "Iteration: 80 Loss: 0.702577 acc :0.906561\n",
      "Iteration: 100 Loss: 0.685132 acc :0.912525\n",
      "Iteration: 120 Loss: 0.730378 acc :0.89662\n",
      "Iteration: 140 Loss: 0.678595 acc :0.914343\n",
      "Iteration: 160 Loss: 0.695206 acc :0.920319\n",
      "Iteration: 180 Loss: 0.744206 acc :0.894422\n",
      "validation Accuracy (59): 0.7513\n",
      "Iteration: 0 Loss: 0.691467 acc :0.916335\n",
      "Iteration: 20 Loss: 0.681961 acc :0.928287\n",
      "Iteration: 40 Loss: 0.666285 acc :0.930279\n",
      "Iteration: 60 Loss: 0.719763 acc :0.914343\n",
      "Iteration: 80 Loss: 0.70233 acc :0.904572\n",
      "Iteration: 100 Loss: 0.717222 acc :0.908549\n",
      "Iteration: 120 Loss: 0.769375 acc :0.87674\n",
      "Iteration: 140 Loss: 0.699631 acc :0.918327\n",
      "Iteration: 160 Loss: 0.695495 acc :0.920319\n",
      "Iteration: 180 Loss: 0.760572 acc :0.886454\n",
      "validation Accuracy (60): 0.7484\n",
      "Iteration: 0 Loss: 0.69379 acc :0.906374\n",
      "Iteration: 20 Loss: 0.695323 acc :0.924303\n",
      "Iteration: 40 Loss: 0.666611 acc :0.916335\n",
      "Iteration: 60 Loss: 0.708394 acc :0.910359\n",
      "Iteration: 80 Loss: 0.714394 acc :0.904573\n",
      "Iteration: 100 Loss: 0.712161 acc :0.906561\n",
      "Iteration: 120 Loss: 0.734075 acc :0.906561\n",
      "Iteration: 140 Loss: 0.701648 acc :0.908367\n",
      "Iteration: 160 Loss: 0.717742 acc :0.906375\n",
      "Iteration: 180 Loss: 0.734152 acc :0.906375\n",
      "validation Accuracy (61): 0.7574\n",
      "Iteration: 0 Loss: 0.678896 acc :0.926295\n",
      "Iteration: 20 Loss: 0.681541 acc :0.922311\n",
      "Iteration: 40 Loss: 0.697148 acc :0.916335\n",
      "Iteration: 60 Loss: 0.726894 acc :0.898406\n",
      "Iteration: 80 Loss: 0.720005 acc :0.88668\n",
      "Iteration: 100 Loss: 0.694838 acc :0.910537\n",
      "Iteration: 120 Loss: 0.728235 acc :0.900596\n",
      "Iteration: 140 Loss: 0.712565 acc :0.914343\n",
      "Iteration: 160 Loss: 0.688022 acc :0.928287\n",
      "Iteration: 180 Loss: 0.750831 acc :0.884462\n",
      "validation Accuracy (62): 0.7618\n",
      "Iteration: 0 Loss: 0.714834 acc :0.906375\n",
      "Iteration: 20 Loss: 0.722617 acc :0.894422\n",
      "Iteration: 40 Loss: 0.70323 acc :0.904383\n",
      "Iteration: 60 Loss: 0.75096 acc :0.880478\n",
      "Iteration: 80 Loss: 0.710882 acc :0.910537\n",
      "Iteration: 100 Loss: 0.686525 acc :0.910537\n",
      "Iteration: 120 Loss: 0.736005 acc :0.890656\n",
      "Iteration: 140 Loss: 0.706328 acc :0.914343\n",
      "Iteration: 160 Loss: 0.684229 acc :0.912351\n",
      "Iteration: 180 Loss: 0.741481 acc :0.888446\n",
      "validation Accuracy (63): 0.7538\n",
      "Iteration: 0 Loss: 0.687218 acc :0.924303\n",
      "Iteration: 20 Loss: 0.725015 acc :0.900398\n",
      "Iteration: 40 Loss: 0.669998 acc :0.920319\n",
      "Iteration: 60 Loss: 0.702335 acc :0.916335\n",
      "Iteration: 80 Loss: 0.69648 acc :0.922465\n",
      "Iteration: 100 Loss: 0.696207 acc :0.904572\n",
      "Iteration: 120 Loss: 0.728371 acc :0.912525\n",
      "Iteration: 140 Loss: 0.712234 acc :0.910359\n",
      "Iteration: 160 Loss: 0.684255 acc :0.920319\n",
      "Iteration: 180 Loss: 0.732852 acc :0.894422\n",
      "validation Accuracy (64): 0.7564\n",
      "Iteration: 0 Loss: 0.706547 acc :0.904382\n",
      "Iteration: 20 Loss: 0.7241 acc :0.910359\n",
      "Iteration: 40 Loss: 0.707034 acc :0.908367\n",
      "Iteration: 60 Loss: 0.719631 acc :0.904382\n",
      "Iteration: 80 Loss: 0.660158 acc :0.922465\n",
      "Iteration: 100 Loss: 0.713847 acc :0.89662\n",
      "Iteration: 120 Loss: 0.725097 acc :0.894632\n",
      "Iteration: 140 Loss: 0.703426 acc :0.910359\n",
      "Iteration: 160 Loss: 0.689429 acc :0.920319\n",
      "Iteration: 180 Loss: 0.705785 acc :0.888446\n",
      "validation Accuracy (65): 0.7567\n",
      "Iteration: 0 Loss: 0.722045 acc :0.924303\n",
      "Iteration: 20 Loss: 0.696328 acc :0.918327\n",
      "Iteration: 40 Loss: 0.682152 acc :0.920319\n",
      "Iteration: 60 Loss: 0.697228 acc :0.924303\n",
      "Iteration: 80 Loss: 0.693132 acc :0.914513\n",
      "Iteration: 100 Loss: 0.711643 acc :0.89662\n",
      "Iteration: 120 Loss: 0.728412 acc :0.894632\n",
      "Iteration: 140 Loss: 0.715999 acc :0.914343\n",
      "Iteration: 160 Loss: 0.685858 acc :0.906375\n",
      "Iteration: 180 Loss: 0.704355 acc :0.908367\n",
      "validation Accuracy (66): 0.7608\n",
      "Iteration: 0 Loss: 0.709191 acc :0.908367\n",
      "Iteration: 20 Loss: 0.696868 acc :0.926295\n",
      "Iteration: 40 Loss: 0.701488 acc :0.914343\n",
      "Iteration: 60 Loss: 0.703606 acc :0.920319\n",
      "Iteration: 80 Loss: 0.690456 acc :0.906561\n",
      "Iteration: 100 Loss: 0.694211 acc :0.902584\n",
      "Iteration: 120 Loss: 0.742343 acc :0.900596\n",
      "Iteration: 140 Loss: 0.719501 acc :0.906375\n",
      "Iteration: 160 Loss: 0.718526 acc :0.90239\n",
      "Iteration: 180 Loss: 0.741921 acc :0.880478\n",
      "validation Accuracy (67): 0.7466\n",
      "Iteration: 0 Loss: 0.714487 acc :0.898406\n",
      "Iteration: 20 Loss: 0.694 acc :0.924303\n",
      "Iteration: 40 Loss: 0.689796 acc :0.904382\n",
      "Iteration: 60 Loss: 0.739106 acc :0.894422\n",
      "Iteration: 80 Loss: 0.675892 acc :0.924453\n",
      "Iteration: 100 Loss: 0.705654 acc :0.89662\n",
      "Iteration: 120 Loss: 0.738706 acc :0.900596\n",
      "Iteration: 140 Loss: 0.667647 acc :0.932271\n",
      "Iteration: 160 Loss: 0.702706 acc :0.922311\n",
      "Iteration: 180 Loss: 0.766786 acc :0.886454\n",
      "validation Accuracy (68): 0.7558\n",
      "Iteration: 0 Loss: 0.688494 acc :0.924303\n",
      "Iteration: 20 Loss: 0.708805 acc :0.924303\n",
      "Iteration: 40 Loss: 0.714879 acc :0.916335\n",
      "Iteration: 60 Loss: 0.718862 acc :0.900398\n",
      "Iteration: 80 Loss: 0.707613 acc :0.902584\n",
      "Iteration: 100 Loss: 0.717436 acc :0.904572\n",
      "Iteration: 120 Loss: 0.740349 acc :0.898608\n",
      "Iteration: 140 Loss: 0.686406 acc :0.910359\n",
      "Iteration: 160 Loss: 0.695869 acc :0.906375\n",
      "Iteration: 180 Loss: 0.720258 acc :0.908367\n",
      "validation Accuracy (69): 0.7566\n",
      "Iteration: 0 Loss: 0.696875 acc :0.916335\n",
      "Iteration: 20 Loss: 0.73053 acc :0.90239\n",
      "Iteration: 40 Loss: 0.725094 acc :0.904382\n",
      "Iteration: 60 Loss: 0.719535 acc :0.90239\n",
      "Iteration: 80 Loss: 0.69747 acc :0.920477\n",
      "Iteration: 100 Loss: 0.712384 acc :0.906561\n",
      "Iteration: 120 Loss: 0.722793 acc :0.908549\n",
      "Iteration: 140 Loss: 0.684099 acc :0.930279\n",
      "Iteration: 160 Loss: 0.729427 acc :0.904382\n",
      "Iteration: 180 Loss: 0.752128 acc :0.89243\n",
      "validation Accuracy (70): 0.7593\n",
      "Iteration: 0 Loss: 0.704149 acc :0.90239\n",
      "Iteration: 20 Loss: 0.689287 acc :0.924303\n",
      "Iteration: 40 Loss: 0.720049 acc :0.924303\n",
      "Iteration: 60 Loss: 0.713099 acc :0.910359\n",
      "Iteration: 80 Loss: 0.679091 acc :0.924453\n",
      "Iteration: 100 Loss: 0.70383 acc :0.908549\n",
      "Iteration: 120 Loss: 0.77674 acc :0.880716\n",
      "Iteration: 140 Loss: 0.712785 acc :0.910359\n",
      "Iteration: 160 Loss: 0.721814 acc :0.886454\n",
      "Iteration: 180 Loss: 0.75461 acc :0.898407\n",
      "validation Accuracy (71): 0.7536\n",
      "Iteration: 0 Loss: 0.720533 acc :0.906375\n",
      "Iteration: 20 Loss: 0.718419 acc :0.918327\n",
      "Iteration: 40 Loss: 0.700442 acc :0.908367\n",
      "Iteration: 60 Loss: 0.712928 acc :0.900398\n",
      "Iteration: 80 Loss: 0.692873 acc :0.908549\n",
      "Iteration: 100 Loss: 0.694187 acc :0.908549\n",
      "Iteration: 120 Loss: 0.773054 acc :0.878728\n",
      "Iteration: 140 Loss: 0.704822 acc :0.910359\n",
      "Iteration: 160 Loss: 0.703882 acc :0.916335\n",
      "Iteration: 180 Loss: 0.738408 acc :0.910359\n",
      "validation Accuracy (72): 0.7544\n",
      "Iteration: 0 Loss: 0.69966 acc :0.896414\n",
      "Iteration: 20 Loss: 0.690175 acc :0.924303\n",
      "Iteration: 40 Loss: 0.688416 acc :0.916335\n",
      "Iteration: 60 Loss: 0.717053 acc :0.904382\n",
      "Iteration: 80 Loss: 0.69864 acc :0.902584\n",
      "Iteration: 100 Loss: 0.676345 acc :0.920477\n",
      "Iteration: 120 Loss: 0.767617 acc :0.890656\n",
      "Iteration: 140 Loss: 0.690711 acc :0.922311\n",
      "Iteration: 160 Loss: 0.711206 acc :0.896414\n",
      "Iteration: 180 Loss: 0.766655 acc :0.884462\n",
      "validation Accuracy (73): 0.7571\n",
      "Iteration: 0 Loss: 0.70297 acc :0.900398\n",
      "Iteration: 20 Loss: 0.704656 acc :0.914343\n",
      "Iteration: 40 Loss: 0.697858 acc :0.914343\n",
      "Iteration: 60 Loss: 0.722591 acc :0.904382\n",
      "Iteration: 80 Loss: 0.677992 acc :0.922465\n",
      "Iteration: 100 Loss: 0.688953 acc :0.916501\n",
      "Iteration: 120 Loss: 0.745593 acc :0.89662\n",
      "Iteration: 140 Loss: 0.691206 acc :0.928287\n",
      "Iteration: 160 Loss: 0.698719 acc :0.914343\n",
      "Iteration: 180 Loss: 0.752272 acc :0.884462\n",
      "validation Accuracy (74): 0.7613\n",
      "Iteration: 0 Loss: 0.682195 acc :0.920319\n",
      "Iteration: 20 Loss: 0.701196 acc :0.920319\n",
      "Iteration: 40 Loss: 0.70827 acc :0.910359\n",
      "Iteration: 60 Loss: 0.707671 acc :0.914343\n",
      "Iteration: 80 Loss: 0.683545 acc :0.918489\n",
      "Iteration: 100 Loss: 0.700855 acc :0.908549\n",
      "Iteration: 120 Loss: 0.714843 acc :0.914513\n",
      "Iteration: 140 Loss: 0.70547 acc :0.916335\n",
      "Iteration: 160 Loss: 0.731319 acc :0.890438\n",
      "Iteration: 180 Loss: 0.727008 acc :0.904382\n",
      "validation Accuracy (75): 0.7619\n",
      "Iteration: 0 Loss: 0.709318 acc :0.906374\n",
      "Iteration: 20 Loss: 0.707589 acc :0.906374\n",
      "Iteration: 40 Loss: 0.712705 acc :0.924303\n",
      "Iteration: 60 Loss: 0.731843 acc :0.90239\n",
      "Iteration: 80 Loss: 0.686979 acc :0.920477\n",
      "Iteration: 100 Loss: 0.694894 acc :0.914513\n",
      "Iteration: 120 Loss: 0.744435 acc :0.902584\n",
      "Iteration: 140 Loss: 0.699608 acc :0.918327\n",
      "Iteration: 160 Loss: 0.720398 acc :0.908367\n",
      "Iteration: 180 Loss: 0.747976 acc :0.90239\n",
      "validation Accuracy (76): 0.7609\n",
      "Iteration: 0 Loss: 0.718208 acc :0.894422\n",
      "Iteration: 20 Loss: 0.722479 acc :0.910359\n",
      "Iteration: 40 Loss: 0.75426 acc :0.896414\n",
      "Iteration: 60 Loss: 0.72894 acc :0.910359\n",
      "Iteration: 80 Loss: 0.693322 acc :0.908549\n",
      "Iteration: 100 Loss: 0.722884 acc :0.902584\n",
      "Iteration: 120 Loss: 0.746068 acc :0.890656\n",
      "Iteration: 140 Loss: 0.679968 acc :0.924303\n",
      "Iteration: 160 Loss: 0.70437 acc :0.904382\n",
      "Iteration: 180 Loss: 0.740633 acc :0.90239\n",
      "validation Accuracy (77): 0.7572\n",
      "Iteration: 0 Loss: 0.709016 acc :0.916335\n",
      "Iteration: 20 Loss: 0.697945 acc :0.920319\n",
      "Iteration: 40 Loss: 0.701179 acc :0.924303\n",
      "Iteration: 60 Loss: 0.739866 acc :0.900398\n",
      "Iteration: 80 Loss: 0.691265 acc :0.904573\n",
      "Iteration: 100 Loss: 0.691845 acc :0.926441\n",
      "Iteration: 120 Loss: 0.729801 acc :0.908549\n",
      "Iteration: 140 Loss: 0.711854 acc :0.918327\n",
      "Iteration: 160 Loss: 0.694963 acc :0.90239\n",
      "Iteration: 180 Loss: 0.728781 acc :0.894422\n",
      "validation Accuracy (78): 0.7535\n",
      "Iteration: 0 Loss: 0.700677 acc :0.898406\n",
      "Iteration: 20 Loss: 0.713407 acc :0.908367\n",
      "Iteration: 40 Loss: 0.693595 acc :0.912351\n",
      "Iteration: 60 Loss: 0.772327 acc :0.89243\n",
      "Iteration: 80 Loss: 0.693885 acc :0.916501\n",
      "Iteration: 100 Loss: 0.691489 acc :0.926441\n",
      "Iteration: 120 Loss: 0.754985 acc :0.882704\n",
      "Iteration: 140 Loss: 0.715021 acc :0.918327\n",
      "Iteration: 160 Loss: 0.686114 acc :0.914343\n",
      "Iteration: 180 Loss: 0.719021 acc :0.928287\n",
      "validation Accuracy (79): 0.7579\n",
      "Iteration: 0 Loss: 0.690043 acc :0.924303\n",
      "Iteration: 20 Loss: 0.700454 acc :0.912351\n",
      "Iteration: 40 Loss: 0.688633 acc :0.924303\n",
      "Iteration: 60 Loss: 0.74217 acc :0.888446\n",
      "Iteration: 80 Loss: 0.689441 acc :0.918489\n",
      "Iteration: 100 Loss: 0.70206 acc :0.912525\n",
      "Iteration: 120 Loss: 0.754539 acc :0.890656\n",
      "Iteration: 140 Loss: 0.712984 acc :0.912351\n",
      "Iteration: 160 Loss: 0.694347 acc :0.924303\n",
      "Iteration: 180 Loss: 0.753855 acc :0.890438\n",
      "validation Accuracy (80): 0.7572\n",
      "Iteration: 0 Loss: 0.658849 acc :0.930279\n",
      "Iteration: 20 Loss: 0.67677 acc :0.920319\n",
      "Iteration: 40 Loss: 0.703229 acc :0.912351\n",
      "Iteration: 60 Loss: 0.722564 acc :0.916335\n",
      "Iteration: 80 Loss: 0.690684 acc :0.912525\n",
      "Iteration: 100 Loss: 0.667182 acc :0.928429\n",
      "Iteration: 120 Loss: 0.726348 acc :0.906561\n",
      "Iteration: 140 Loss: 0.695502 acc :0.918327\n",
      "Iteration: 160 Loss: 0.687835 acc :0.916335\n",
      "Iteration: 180 Loss: 0.738232 acc :0.90239\n",
      "validation Accuracy (81): 0.7603\n",
      "Iteration: 0 Loss: 0.676201 acc :0.930279\n",
      "Iteration: 20 Loss: 0.700468 acc :0.914343\n",
      "Iteration: 40 Loss: 0.699814 acc :0.918327\n",
      "Iteration: 60 Loss: 0.695408 acc :0.912351\n",
      "Iteration: 80 Loss: 0.691434 acc :0.920477\n",
      "Iteration: 100 Loss: 0.699622 acc :0.914513\n",
      "Iteration: 120 Loss: 0.735999 acc :0.88668\n",
      "Iteration: 140 Loss: 0.690763 acc :0.922311\n",
      "Iteration: 160 Loss: 0.693546 acc :0.914343\n",
      "Iteration: 180 Loss: 0.725435 acc :0.89243\n",
      "validation Accuracy (82): 0.7595\n",
      "Iteration: 0 Loss: 0.754948 acc :0.884462\n",
      "Iteration: 20 Loss: 0.708237 acc :0.916335\n",
      "Iteration: 40 Loss: 0.709506 acc :0.920319\n",
      "Iteration: 60 Loss: 0.709365 acc :0.894422\n",
      "Iteration: 80 Loss: 0.69041 acc :0.904572\n",
      "Iteration: 100 Loss: 0.684081 acc :0.924453\n",
      "Iteration: 120 Loss: 0.741329 acc :0.900596\n",
      "Iteration: 140 Loss: 0.722848 acc :0.912351\n",
      "Iteration: 160 Loss: 0.708572 acc :0.894422\n",
      "Iteration: 180 Loss: 0.746221 acc :0.89243\n",
      "validation Accuracy (83): 0.7566\n",
      "Iteration: 0 Loss: 0.701803 acc :0.906375\n",
      "Iteration: 20 Loss: 0.698904 acc :0.906375\n",
      "Iteration: 40 Loss: 0.679415 acc :0.924303\n",
      "Iteration: 60 Loss: 0.708823 acc :0.910359\n",
      "Iteration: 80 Loss: 0.68073 acc :0.916501\n",
      "Iteration: 100 Loss: 0.714714 acc :0.906561\n",
      "Iteration: 120 Loss: 0.741964 acc :0.888668\n",
      "Iteration: 140 Loss: 0.708349 acc :0.914343\n",
      "Iteration: 160 Loss: 0.696036 acc :0.912351\n",
      "Iteration: 180 Loss: 0.738674 acc :0.90239\n",
      "validation Accuracy (84): 0.7541\n",
      "Iteration: 0 Loss: 0.703132 acc :0.918327\n",
      "Iteration: 20 Loss: 0.721619 acc :0.900398\n",
      "Iteration: 40 Loss: 0.67777 acc :0.926295\n",
      "Iteration: 60 Loss: 0.691922 acc :0.912351\n",
      "Iteration: 80 Loss: 0.726057 acc :0.890656\n",
      "Iteration: 100 Loss: 0.683662 acc :0.922465\n",
      "Iteration: 120 Loss: 0.749127 acc :0.902584\n",
      "Iteration: 140 Loss: 0.714709 acc :0.914343\n",
      "Iteration: 160 Loss: 0.707313 acc :0.904382\n",
      "Iteration: 180 Loss: 0.743168 acc :0.898406\n",
      "validation Accuracy (85): 0.7561\n",
      "Iteration: 0 Loss: 0.681698 acc :0.920319\n",
      "Iteration: 20 Loss: 0.704944 acc :0.914343\n",
      "Iteration: 40 Loss: 0.691433 acc :0.912351\n",
      "Iteration: 60 Loss: 0.725689 acc :0.896414\n",
      "Iteration: 80 Loss: 0.682096 acc :0.906561\n",
      "Iteration: 100 Loss: 0.684311 acc :0.920477\n",
      "Iteration: 120 Loss: 0.761886 acc :0.882704\n",
      "Iteration: 140 Loss: 0.730542 acc :0.900398\n",
      "Iteration: 160 Loss: 0.693382 acc :0.930279\n",
      "Iteration: 180 Loss: 0.746765 acc :0.89243\n",
      "validation Accuracy (86): 0.7565\n",
      "Iteration: 0 Loss: 0.701603 acc :0.910359\n",
      "Iteration: 20 Loss: 0.706837 acc :0.932271\n",
      "Iteration: 40 Loss: 0.709552 acc :0.912351\n",
      "Iteration: 60 Loss: 0.719433 acc :0.908367\n",
      "Iteration: 80 Loss: 0.705297 acc :0.898608\n",
      "Iteration: 100 Loss: 0.673291 acc :0.920477\n",
      "Iteration: 120 Loss: 0.724816 acc :0.89662\n",
      "Iteration: 140 Loss: 0.71005 acc :0.918327\n",
      "Iteration: 160 Loss: 0.676076 acc :0.920319\n",
      "Iteration: 180 Loss: 0.74247 acc :0.904383\n",
      "validation Accuracy (87): 0.7532\n",
      "Iteration: 0 Loss: 0.705472 acc :0.904383\n",
      "Iteration: 20 Loss: 0.715163 acc :0.916335\n",
      "Iteration: 40 Loss: 0.72259 acc :0.906375\n",
      "Iteration: 60 Loss: 0.704935 acc :0.90239\n",
      "Iteration: 80 Loss: 0.708451 acc :0.906561\n",
      "Iteration: 100 Loss: 0.686154 acc :0.916501\n",
      "Iteration: 120 Loss: 0.747182 acc :0.894632\n",
      "Iteration: 140 Loss: 0.700412 acc :0.930279\n",
      "Iteration: 160 Loss: 0.675039 acc :0.930279\n",
      "Iteration: 180 Loss: 0.747422 acc :0.884462\n",
      "validation Accuracy (88): 0.7528\n",
      "Iteration: 0 Loss: 0.674372 acc :0.926295\n",
      "Iteration: 20 Loss: 0.728742 acc :0.906375\n",
      "Iteration: 40 Loss: 0.696483 acc :0.914343\n",
      "Iteration: 60 Loss: 0.728992 acc :0.898406\n",
      "Iteration: 80 Loss: 0.700311 acc :0.904573\n",
      "Iteration: 100 Loss: 0.68363 acc :0.928429\n",
      "Iteration: 120 Loss: 0.741915 acc :0.900596\n",
      "Iteration: 140 Loss: 0.703482 acc :0.922311\n",
      "Iteration: 160 Loss: 0.716589 acc :0.900398\n",
      "Iteration: 180 Loss: 0.706207 acc :0.906375\n",
      "validation Accuracy (89): 0.751\n",
      "Iteration: 0 Loss: 0.698845 acc :0.90239\n",
      "Iteration: 20 Loss: 0.696635 acc :0.916335\n",
      "Iteration: 40 Loss: 0.708532 acc :0.910359\n",
      "Iteration: 60 Loss: 0.730102 acc :0.912351\n",
      "Iteration: 80 Loss: 0.688813 acc :0.916501\n",
      "Iteration: 100 Loss: 0.663321 acc :0.922465\n",
      "Iteration: 120 Loss: 0.751575 acc :0.906561\n",
      "Iteration: 140 Loss: 0.706129 acc :0.922311\n",
      "Iteration: 160 Loss: 0.700139 acc :0.912351\n",
      "Iteration: 180 Loss: 0.738997 acc :0.884462\n",
      "validation Accuracy (90): 0.7565\n",
      "Iteration: 0 Loss: 0.680553 acc :0.926295\n",
      "Iteration: 20 Loss: 0.73042 acc :0.894422\n",
      "Iteration: 40 Loss: 0.691515 acc :0.916335\n",
      "Iteration: 60 Loss: 0.703242 acc :0.906375\n",
      "Iteration: 80 Loss: 0.66197 acc :0.916501\n",
      "Iteration: 100 Loss: 0.638218 acc :0.93837\n",
      "Iteration: 120 Loss: 0.749544 acc :0.898608\n",
      "Iteration: 140 Loss: 0.704298 acc :0.920319\n",
      "Iteration: 160 Loss: 0.699733 acc :0.914343\n",
      "Iteration: 180 Loss: 0.749092 acc :0.884462\n",
      "validation Accuracy (91): 0.7518\n",
      "Iteration: 0 Loss: 0.688133 acc :0.926295\n",
      "Iteration: 20 Loss: 0.699629 acc :0.912351\n",
      "Iteration: 40 Loss: 0.686988 acc :0.918327\n",
      "Iteration: 60 Loss: 0.709848 acc :0.906375\n",
      "Iteration: 80 Loss: 0.690332 acc :0.904573\n",
      "Iteration: 100 Loss: 0.680558 acc :0.916501\n",
      "Iteration: 120 Loss: 0.75414 acc :0.89662\n",
      "Iteration: 140 Loss: 0.725777 acc :0.906375\n",
      "Iteration: 160 Loss: 0.676909 acc :0.918327\n",
      "Iteration: 180 Loss: 0.748887 acc :0.900398\n",
      "validation Accuracy (92): 0.7556\n",
      "Iteration: 0 Loss: 0.683394 acc :0.918327\n",
      "Iteration: 20 Loss: 0.670181 acc :0.930279\n",
      "Iteration: 40 Loss: 0.679455 acc :0.928287\n",
      "Iteration: 60 Loss: 0.718446 acc :0.914343\n",
      "Iteration: 80 Loss: 0.704041 acc :0.920477\n",
      "Iteration: 100 Loss: 0.711777 acc :0.908549\n",
      "Iteration: 120 Loss: 0.744656 acc :0.888668\n",
      "Iteration: 140 Loss: 0.693027 acc :0.930279\n",
      "Iteration: 160 Loss: 0.724358 acc :0.904383\n",
      "Iteration: 180 Loss: 0.733542 acc :0.888446\n",
      "validation Accuracy (93): 0.7563\n",
      "Iteration: 0 Loss: 0.695307 acc :0.916335\n",
      "Iteration: 20 Loss: 0.686235 acc :0.912351\n",
      "Iteration: 40 Loss: 0.702689 acc :0.900398\n",
      "Iteration: 60 Loss: 0.711251 acc :0.906375\n",
      "Iteration: 80 Loss: 0.720505 acc :0.904572\n",
      "Iteration: 100 Loss: 0.690326 acc :0.930417\n",
      "Iteration: 120 Loss: 0.757576 acc :0.892644\n",
      "Iteration: 140 Loss: 0.730013 acc :0.904382\n",
      "Iteration: 160 Loss: 0.707132 acc :0.912351\n",
      "Iteration: 180 Loss: 0.743192 acc :0.90239\n",
      "validation Accuracy (94): 0.7563\n",
      "Iteration: 0 Loss: 0.708484 acc :0.926295\n",
      "Iteration: 20 Loss: 0.689406 acc :0.920319\n",
      "Iteration: 40 Loss: 0.689502 acc :0.912351\n",
      "Iteration: 60 Loss: 0.697199 acc :0.918327\n",
      "Iteration: 80 Loss: 0.70785 acc :0.906561\n",
      "Iteration: 100 Loss: 0.676607 acc :0.920477\n",
      "Iteration: 120 Loss: 0.746978 acc :0.89662\n",
      "Iteration: 140 Loss: 0.727244 acc :0.896414\n",
      "Iteration: 160 Loss: 0.705723 acc :0.898406\n",
      "Iteration: 180 Loss: 0.722703 acc :0.906374\n",
      "validation Accuracy (95): 0.7604\n",
      "Iteration: 0 Loss: 0.66237 acc :0.934263\n",
      "Iteration: 20 Loss: 0.684277 acc :0.914343\n",
      "Iteration: 40 Loss: 0.691836 acc :0.914343\n",
      "Iteration: 60 Loss: 0.745151 acc :0.900398\n",
      "Iteration: 80 Loss: 0.681202 acc :0.932405\n",
      "Iteration: 100 Loss: 0.700191 acc :0.914513\n",
      "Iteration: 120 Loss: 0.744619 acc :0.88668\n",
      "Iteration: 140 Loss: 0.69587 acc :0.920319\n",
      "Iteration: 160 Loss: 0.687843 acc :0.918327\n",
      "Iteration: 180 Loss: 0.753969 acc :0.894422\n",
      "validation Accuracy (96): 0.7554\n",
      "Iteration: 0 Loss: 0.667921 acc :0.942231\n",
      "Iteration: 20 Loss: 0.684427 acc :0.928287\n",
      "Iteration: 40 Loss: 0.70637 acc :0.904382\n",
      "Iteration: 60 Loss: 0.746473 acc :0.894422\n",
      "Iteration: 80 Loss: 0.685956 acc :0.922465\n",
      "Iteration: 100 Loss: 0.696302 acc :0.904573\n",
      "Iteration: 120 Loss: 0.737639 acc :0.89662\n",
      "Iteration: 140 Loss: 0.718721 acc :0.90239\n",
      "Iteration: 160 Loss: 0.746955 acc :0.894422\n",
      "Iteration: 180 Loss: 0.753981 acc :0.880478\n",
      "validation Accuracy (97): 0.7573\n",
      "Iteration: 0 Loss: 0.691337 acc :0.926295\n",
      "Iteration: 20 Loss: 0.698241 acc :0.900398\n",
      "Iteration: 40 Loss: 0.685758 acc :0.912351\n",
      "Iteration: 60 Loss: 0.704928 acc :0.904383\n",
      "Iteration: 80 Loss: 0.695341 acc :0.914513\n",
      "Iteration: 100 Loss: 0.692455 acc :0.916501\n",
      "Iteration: 120 Loss: 0.749306 acc :0.894632\n",
      "Iteration: 140 Loss: 0.723982 acc :0.914343\n",
      "Iteration: 160 Loss: 0.700172 acc :0.90239\n",
      "Iteration: 180 Loss: 0.713181 acc :0.904383\n",
      "validation Accuracy (98): 0.7592\n",
      "Iteration: 0 Loss: 0.692896 acc :0.920319\n",
      "Iteration: 20 Loss: 0.688272 acc :0.90239\n",
      "Iteration: 40 Loss: 0.684471 acc :0.918327\n",
      "Iteration: 60 Loss: 0.712662 acc :0.904382\n",
      "Iteration: 80 Loss: 0.710955 acc :0.910537\n",
      "Iteration: 100 Loss: 0.729572 acc :0.894632\n",
      "Iteration: 120 Loss: 0.732223 acc :0.892644\n",
      "Iteration: 140 Loss: 0.712469 acc :0.920319\n",
      "Iteration: 160 Loss: 0.682734 acc :0.910359\n",
      "Iteration: 180 Loss: 0.729974 acc :0.90239\n",
      "validation Accuracy (99): 0.7575\n",
      "Iteration: 0 Loss: 0.682554 acc :0.924303\n",
      "Iteration: 20 Loss: 0.684836 acc :0.922311\n",
      "Iteration: 40 Loss: 0.686465 acc :0.912351\n",
      "Iteration: 60 Loss: 0.685886 acc :0.922311\n",
      "Iteration: 80 Loss: 0.703068 acc :0.912525\n",
      "Iteration: 100 Loss: 0.696415 acc :0.916501\n",
      "Iteration: 120 Loss: 0.764301 acc :0.888668\n",
      "Iteration: 140 Loss: 0.723144 acc :0.904382\n",
      "Iteration: 160 Loss: 0.709471 acc :0.90239\n",
      "Iteration: 180 Loss: 0.735092 acc :0.914343\n",
      "validation Accuracy (100): 0.7588\n",
      "Iteration: 0 Loss: 0.693954 acc :0.906375\n",
      "Iteration: 20 Loss: 0.71621 acc :0.912351\n",
      "Iteration: 40 Loss: 0.686087 acc :0.918327\n",
      "Iteration: 60 Loss: 0.720472 acc :0.894422\n",
      "Iteration: 80 Loss: 0.693312 acc :0.902584\n",
      "Iteration: 100 Loss: 0.704204 acc :0.912525\n",
      "Iteration: 120 Loss: 0.778013 acc :0.882704\n",
      "Iteration: 140 Loss: 0.70411 acc :0.904382\n",
      "Iteration: 160 Loss: 0.690673 acc :0.912351\n",
      "Iteration: 180 Loss: 0.748815 acc :0.884462\n",
      "validation Accuracy (101): 0.756\n",
      "Iteration: 0 Loss: 0.699336 acc :0.906375\n",
      "Iteration: 20 Loss: 0.698398 acc :0.916335\n",
      "Iteration: 40 Loss: 0.671425 acc :0.912351\n",
      "Iteration: 60 Loss: 0.728098 acc :0.900398\n",
      "Iteration: 80 Loss: 0.686955 acc :0.920477\n",
      "Iteration: 100 Loss: 0.69329 acc :0.910537\n",
      "Iteration: 120 Loss: 0.733774 acc :0.908549\n",
      "Iteration: 140 Loss: 0.686819 acc :0.916335\n",
      "Iteration: 160 Loss: 0.683227 acc :0.922311\n",
      "Iteration: 180 Loss: 0.737501 acc :0.916335\n",
      "validation Accuracy (102): 0.7578\n",
      "Iteration: 0 Loss: 0.697336 acc :0.916335\n",
      "Iteration: 20 Loss: 0.690449 acc :0.918327\n",
      "Iteration: 40 Loss: 0.68905 acc :0.904383\n",
      "Iteration: 60 Loss: 0.691933 acc :0.914343\n",
      "Iteration: 80 Loss: 0.671019 acc :0.930417\n",
      "Iteration: 100 Loss: 0.705726 acc :0.902584\n",
      "Iteration: 120 Loss: 0.728837 acc :0.900596\n",
      "Iteration: 140 Loss: 0.685924 acc :0.922311\n",
      "Iteration: 160 Loss: 0.691814 acc :0.916335\n",
      "Iteration: 180 Loss: 0.73675 acc :0.880478\n",
      "validation Accuracy (103): 0.7503\n",
      "Iteration: 0 Loss: 0.70731 acc :0.916335\n",
      "Iteration: 20 Loss: 0.681469 acc :0.910359\n",
      "Iteration: 40 Loss: 0.673112 acc :0.914343\n",
      "Iteration: 60 Loss: 0.696492 acc :0.916335\n",
      "Iteration: 80 Loss: 0.67415 acc :0.920477\n",
      "Iteration: 100 Loss: 0.714422 acc :0.902584\n",
      "Iteration: 120 Loss: 0.726178 acc :0.900596\n",
      "Iteration: 140 Loss: 0.730002 acc :0.890438\n",
      "Iteration: 160 Loss: 0.712131 acc :0.908367\n",
      "Iteration: 180 Loss: 0.753844 acc :0.910359\n",
      "validation Accuracy (104): 0.7561\n",
      "Iteration: 0 Loss: 0.757215 acc :0.89243\n",
      "Iteration: 20 Loss: 0.712557 acc :0.912351\n",
      "Iteration: 40 Loss: 0.686703 acc :0.914343\n",
      "Iteration: 60 Loss: 0.705866 acc :0.904383\n",
      "Iteration: 80 Loss: 0.70455 acc :0.906561\n",
      "Iteration: 100 Loss: 0.690871 acc :0.924453\n",
      "Iteration: 120 Loss: 0.745435 acc :0.892644\n",
      "Iteration: 140 Loss: 0.667952 acc :0.916335\n",
      "Iteration: 160 Loss: 0.705242 acc :0.908367\n",
      "Iteration: 180 Loss: 0.739735 acc :0.894422\n",
      "validation Accuracy (105): 0.7562\n",
      "Iteration: 0 Loss: 0.73157 acc :0.89243\n",
      "Iteration: 20 Loss: 0.697757 acc :0.920319\n",
      "Iteration: 40 Loss: 0.689718 acc :0.920319\n",
      "Iteration: 60 Loss: 0.728917 acc :0.900398\n",
      "Iteration: 80 Loss: 0.703375 acc :0.912525\n",
      "Iteration: 100 Loss: 0.694273 acc :0.916501\n",
      "Iteration: 120 Loss: 0.731743 acc :0.892644\n",
      "Iteration: 140 Loss: 0.687528 acc :0.914343\n",
      "Iteration: 160 Loss: 0.677382 acc :0.916335\n",
      "Iteration: 180 Loss: 0.737807 acc :0.898406\n",
      "validation Accuracy (106): 0.7524\n",
      "Iteration: 0 Loss: 0.682733 acc :0.914343\n",
      "Iteration: 20 Loss: 0.684107 acc :0.928287\n",
      "Iteration: 40 Loss: 0.695392 acc :0.904383\n",
      "Iteration: 60 Loss: 0.714325 acc :0.894422\n",
      "Iteration: 80 Loss: 0.697384 acc :0.908549\n",
      "Iteration: 100 Loss: 0.681127 acc :0.932405\n",
      "Iteration: 120 Loss: 0.717646 acc :0.904573\n",
      "Iteration: 140 Loss: 0.715932 acc :0.910359\n",
      "Iteration: 160 Loss: 0.66765 acc :0.932271\n",
      "Iteration: 180 Loss: 0.751695 acc :0.874502\n",
      "validation Accuracy (107): 0.7506\n",
      "Iteration: 0 Loss: 0.692942 acc :0.926295\n",
      "Iteration: 20 Loss: 0.711298 acc :0.922311\n",
      "Iteration: 40 Loss: 0.6687 acc :0.924303\n",
      "Iteration: 60 Loss: 0.714691 acc :0.914343\n",
      "Iteration: 80 Loss: 0.66707 acc :0.922465\n",
      "Iteration: 100 Loss: 0.702467 acc :0.902584\n",
      "Iteration: 120 Loss: 0.735832 acc :0.906561\n",
      "Iteration: 140 Loss: 0.685362 acc :0.918327\n",
      "Iteration: 160 Loss: 0.687038 acc :0.912351\n",
      "Iteration: 180 Loss: 0.756772 acc :0.88247\n",
      "validation Accuracy (108): 0.749\n",
      "Iteration: 0 Loss: 0.697464 acc :0.912351\n",
      "Iteration: 20 Loss: 0.703443 acc :0.922311\n",
      "Iteration: 40 Loss: 0.684923 acc :0.916335\n",
      "Iteration: 60 Loss: 0.732555 acc :0.910359\n",
      "Iteration: 80 Loss: 0.68251 acc :0.926441\n",
      "Iteration: 100 Loss: 0.693665 acc :0.914513\n",
      "Iteration: 120 Loss: 0.733823 acc :0.892644\n",
      "Iteration: 140 Loss: 0.678122 acc :0.922311\n",
      "Iteration: 160 Loss: 0.689095 acc :0.924303\n",
      "Iteration: 180 Loss: 0.74867 acc :0.89243\n",
      "validation Accuracy (109): 0.754\n",
      "Iteration: 0 Loss: 0.705049 acc :0.912351\n",
      "Iteration: 20 Loss: 0.729226 acc :0.900398\n",
      "Iteration: 40 Loss: 0.696257 acc :0.90239\n",
      "Iteration: 60 Loss: 0.749306 acc :0.89243\n",
      "Iteration: 80 Loss: 0.699417 acc :0.912525\n",
      "Iteration: 100 Loss: 0.684143 acc :0.922465\n",
      "Iteration: 120 Loss: 0.761449 acc :0.888668\n",
      "Iteration: 140 Loss: 0.703807 acc :0.916335\n",
      "Iteration: 160 Loss: 0.688883 acc :0.924303\n",
      "Iteration: 180 Loss: 0.720424 acc :0.908367\n",
      "validation Accuracy (110): 0.7493\n",
      "Iteration: 0 Loss: 0.712076 acc :0.906375\n",
      "Iteration: 20 Loss: 0.692099 acc :0.914343\n",
      "Iteration: 40 Loss: 0.704291 acc :0.906375\n",
      "Iteration: 60 Loss: 0.724289 acc :0.916335\n",
      "Iteration: 80 Loss: 0.677565 acc :0.918489\n",
      "Iteration: 100 Loss: 0.693226 acc :0.902584\n",
      "Iteration: 120 Loss: 0.755326 acc :0.894632\n",
      "Iteration: 140 Loss: 0.682747 acc :0.922311\n",
      "Iteration: 160 Loss: 0.695047 acc :0.914343\n",
      "Iteration: 180 Loss: 0.739825 acc :0.88247\n",
      "validation Accuracy (111): 0.7565\n",
      "Iteration: 0 Loss: 0.699512 acc :0.922311\n",
      "Iteration: 20 Loss: 0.717323 acc :0.90239\n",
      "Iteration: 40 Loss: 0.66524 acc :0.918327\n",
      "Iteration: 60 Loss: 0.73603 acc :0.924303\n",
      "Iteration: 80 Loss: 0.687421 acc :0.922465\n",
      "Iteration: 100 Loss: 0.655978 acc :0.934394\n",
      "Iteration: 120 Loss: 0.75274 acc :0.888668\n",
      "Iteration: 140 Loss: 0.706302 acc :0.906375\n",
      "Iteration: 160 Loss: 0.711484 acc :0.900398\n",
      "Iteration: 180 Loss: 0.724506 acc :0.908367\n",
      "validation Accuracy (112): 0.7558\n",
      "Iteration: 0 Loss: 0.711785 acc :0.898406\n",
      "Iteration: 20 Loss: 0.7287 acc :0.910359\n",
      "Iteration: 40 Loss: 0.721863 acc :0.900398\n",
      "Iteration: 60 Loss: 0.743721 acc :0.896414\n",
      "Iteration: 80 Loss: 0.704578 acc :0.904572\n",
      "Iteration: 100 Loss: 0.662756 acc :0.928429\n",
      "Iteration: 120 Loss: 0.731865 acc :0.904573\n",
      "Iteration: 140 Loss: 0.698971 acc :0.924303\n",
      "Iteration: 160 Loss: 0.727985 acc :0.890438\n",
      "Iteration: 180 Loss: 0.736703 acc :0.910359\n",
      "validation Accuracy (113): 0.7567\n",
      "Iteration: 0 Loss: 0.694771 acc :0.918327\n",
      "Iteration: 20 Loss: 0.709888 acc :0.908367\n",
      "Iteration: 40 Loss: 0.701065 acc :0.90239\n",
      "Iteration: 60 Loss: 0.714291 acc :0.914343\n",
      "Iteration: 80 Loss: 0.692596 acc :0.912525\n",
      "Iteration: 100 Loss: 0.738639 acc :0.898608\n",
      "Iteration: 120 Loss: 0.70648 acc :0.912525\n",
      "Iteration: 140 Loss: 0.714998 acc :0.902391\n",
      "Iteration: 160 Loss: 0.69456 acc :0.906375\n",
      "Iteration: 180 Loss: 0.778356 acc :0.87251\n",
      "validation Accuracy (114): 0.7541\n",
      "Iteration: 0 Loss: 0.709663 acc :0.910359\n",
      "Iteration: 20 Loss: 0.689284 acc :0.920319\n",
      "Iteration: 40 Loss: 0.705596 acc :0.902391\n",
      "Iteration: 60 Loss: 0.723524 acc :0.904382\n",
      "Iteration: 80 Loss: 0.668725 acc :0.934394\n",
      "Iteration: 100 Loss: 0.681781 acc :0.920477\n",
      "Iteration: 120 Loss: 0.771314 acc :0.87674\n",
      "Iteration: 140 Loss: 0.698046 acc :0.916335\n",
      "Iteration: 160 Loss: 0.706648 acc :0.904382\n",
      "Iteration: 180 Loss: 0.755468 acc :0.890438\n",
      "validation Accuracy (115): 0.7565\n",
      "Iteration: 0 Loss: 0.703276 acc :0.90239\n",
      "Iteration: 20 Loss: 0.701455 acc :0.920319\n",
      "Iteration: 40 Loss: 0.72293 acc :0.896414\n",
      "Iteration: 60 Loss: 0.707231 acc :0.904383\n",
      "Iteration: 80 Loss: 0.68357 acc :0.924453\n",
      "Iteration: 100 Loss: 0.673587 acc :0.914513\n",
      "Iteration: 120 Loss: 0.744756 acc :0.882704\n",
      "Iteration: 140 Loss: 0.718136 acc :0.898406\n",
      "Iteration: 160 Loss: 0.686323 acc :0.914343\n",
      "Iteration: 180 Loss: 0.699757 acc :0.914343\n",
      "validation Accuracy (116): 0.7609\n",
      "Iteration: 0 Loss: 0.700771 acc :0.914343\n",
      "Iteration: 20 Loss: 0.676548 acc :0.930279\n",
      "Iteration: 40 Loss: 0.7036 acc :0.910359\n",
      "Iteration: 60 Loss: 0.72575 acc :0.89243\n",
      "Iteration: 80 Loss: 0.690962 acc :0.920477\n",
      "Iteration: 100 Loss: 0.673829 acc :0.922465\n",
      "Iteration: 120 Loss: 0.781207 acc :0.870775\n",
      "Iteration: 140 Loss: 0.704017 acc :0.918327\n",
      "Iteration: 160 Loss: 0.694515 acc :0.922311\n",
      "Iteration: 180 Loss: 0.728803 acc :0.894422\n",
      "validation Accuracy (117): 0.7618\n",
      "Iteration: 0 Loss: 0.713689 acc :0.90239\n",
      "Iteration: 20 Loss: 0.677977 acc :0.918327\n",
      "Iteration: 40 Loss: 0.679222 acc :0.928287\n",
      "Iteration: 60 Loss: 0.706988 acc :0.908367\n",
      "Iteration: 80 Loss: 0.711605 acc :0.902584\n",
      "Iteration: 100 Loss: 0.704241 acc :0.900596\n",
      "Iteration: 120 Loss: 0.773692 acc :0.890656\n",
      "Iteration: 140 Loss: 0.701325 acc :0.926295\n",
      "Iteration: 160 Loss: 0.691504 acc :0.918327\n",
      "Iteration: 180 Loss: 0.737293 acc :0.894422\n",
      "validation Accuracy (118): 0.7633\n",
      "Iteration: 0 Loss: 0.672469 acc :0.928287\n",
      "Iteration: 20 Loss: 0.673541 acc :0.924303\n",
      "Iteration: 40 Loss: 0.709971 acc :0.906375\n",
      "Iteration: 60 Loss: 0.714767 acc :0.906375\n",
      "Iteration: 80 Loss: 0.708703 acc :0.902584\n",
      "Iteration: 100 Loss: 0.677828 acc :0.918489\n",
      "Iteration: 120 Loss: 0.774029 acc :0.876739\n",
      "Iteration: 140 Loss: 0.763748 acc :0.896414\n",
      "Iteration: 160 Loss: 0.693538 acc :0.922311\n",
      "Iteration: 180 Loss: 0.717924 acc :0.908367\n",
      "validation Accuracy (119): 0.7595\n",
      "Iteration: 0 Loss: 0.699772 acc :0.906375\n",
      "Iteration: 20 Loss: 0.695609 acc :0.906375\n",
      "Iteration: 40 Loss: 0.715464 acc :0.896414\n",
      "Iteration: 60 Loss: 0.728765 acc :0.900398\n",
      "Iteration: 80 Loss: 0.702802 acc :0.916501\n",
      "Iteration: 100 Loss: 0.662644 acc :0.924453\n",
      "Iteration: 120 Loss: 0.725163 acc :0.898608\n",
      "Iteration: 140 Loss: 0.745875 acc :0.906375\n",
      "Iteration: 160 Loss: 0.710669 acc :0.918327\n",
      "Iteration: 180 Loss: 0.735679 acc :0.898406\n",
      "validation Accuracy (120): 0.7574\n",
      "Iteration: 0 Loss: 0.692015 acc :0.916335\n",
      "Iteration: 20 Loss: 0.679577 acc :0.906375\n",
      "Iteration: 40 Loss: 0.699426 acc :0.918327\n",
      "Iteration: 60 Loss: 0.736688 acc :0.896414\n",
      "Iteration: 80 Loss: 0.70582 acc :0.906561\n",
      "Iteration: 100 Loss: 0.70386 acc :0.906561\n",
      "Iteration: 120 Loss: 0.76314 acc :0.888668\n",
      "Iteration: 140 Loss: 0.730749 acc :0.918327\n",
      "Iteration: 160 Loss: 0.697868 acc :0.914343\n",
      "Iteration: 180 Loss: 0.740179 acc :0.896414\n",
      "validation Accuracy (121): 0.7597\n",
      "Iteration: 0 Loss: 0.697822 acc :0.900398\n",
      "Iteration: 20 Loss: 0.694301 acc :0.926295\n",
      "Iteration: 40 Loss: 0.695618 acc :0.920319\n",
      "Iteration: 60 Loss: 0.718198 acc :0.888446\n",
      "Iteration: 80 Loss: 0.714121 acc :0.914513\n",
      "Iteration: 100 Loss: 0.697338 acc :0.916501\n",
      "Iteration: 120 Loss: 0.748484 acc :0.892644\n",
      "Iteration: 140 Loss: 0.732272 acc :0.910359\n",
      "Iteration: 160 Loss: 0.693406 acc :0.896414\n",
      "Iteration: 180 Loss: 0.731278 acc :0.904383\n",
      "validation Accuracy (122): 0.7622\n",
      "Iteration: 0 Loss: 0.69091 acc :0.912351\n",
      "Iteration: 20 Loss: 0.739805 acc :0.904383\n",
      "Iteration: 40 Loss: 0.691428 acc :0.904383\n",
      "Iteration: 60 Loss: 0.720451 acc :0.90239\n",
      "Iteration: 80 Loss: 0.69228 acc :0.914513\n",
      "Iteration: 100 Loss: 0.681307 acc :0.914513\n",
      "Iteration: 120 Loss: 0.756251 acc :0.89662\n",
      "Iteration: 140 Loss: 0.696045 acc :0.922311\n",
      "Iteration: 160 Loss: 0.685528 acc :0.904383\n",
      "Iteration: 180 Loss: 0.762772 acc :0.888446\n",
      "validation Accuracy (123): 0.76\n",
      "Iteration: 0 Loss: 0.696328 acc :0.914343\n",
      "Iteration: 20 Loss: 0.710891 acc :0.914343\n",
      "Iteration: 40 Loss: 0.686916 acc :0.904382\n",
      "Iteration: 60 Loss: 0.706363 acc :0.912351\n",
      "Iteration: 80 Loss: 0.702334 acc :0.910537\n",
      "Iteration: 100 Loss: 0.717903 acc :0.900596\n",
      "Iteration: 120 Loss: 0.736201 acc :0.894632\n",
      "Iteration: 140 Loss: 0.705602 acc :0.912351\n",
      "Iteration: 160 Loss: 0.706834 acc :0.906375\n",
      "Iteration: 180 Loss: 0.72765 acc :0.900398\n",
      "validation Accuracy (124): 0.754\n",
      "Iteration: 0 Loss: 0.706615 acc :0.912351\n",
      "Iteration: 20 Loss: 0.711169 acc :0.910359\n",
      "Iteration: 40 Loss: 0.695421 acc :0.920319\n",
      "Iteration: 60 Loss: 0.730747 acc :0.898406\n",
      "Iteration: 80 Loss: 0.6987 acc :0.906561\n",
      "Iteration: 100 Loss: 0.716309 acc :0.906561\n",
      "Iteration: 120 Loss: 0.73808 acc :0.89662\n",
      "Iteration: 140 Loss: 0.737038 acc :0.900398\n",
      "Iteration: 160 Loss: 0.689907 acc :0.918327\n",
      "Iteration: 180 Loss: 0.744248 acc :0.906375\n",
      "validation Accuracy (125): 0.7638\n",
      "Iteration: 0 Loss: 0.679145 acc :0.910359\n",
      "Iteration: 20 Loss: 0.718773 acc :0.908367\n",
      "Iteration: 40 Loss: 0.70381 acc :0.916335\n",
      "Iteration: 60 Loss: 0.730641 acc :0.898406\n",
      "Iteration: 80 Loss: 0.693221 acc :0.904573\n",
      "Iteration: 100 Loss: 0.69397 acc :0.90656\n",
      "Iteration: 120 Loss: 0.747379 acc :0.908549\n",
      "Iteration: 140 Loss: 0.726684 acc :0.910359\n",
      "Iteration: 160 Loss: 0.687811 acc :0.918327\n",
      "Iteration: 180 Loss: 0.712042 acc :0.916335\n",
      "validation Accuracy (126): 0.7593\n",
      "Iteration: 0 Loss: 0.695373 acc :0.920319\n",
      "Iteration: 20 Loss: 0.690168 acc :0.930279\n",
      "Iteration: 40 Loss: 0.691405 acc :0.922311\n",
      "Iteration: 60 Loss: 0.729286 acc :0.880478\n",
      "Iteration: 80 Loss: 0.709318 acc :0.900596\n",
      "Iteration: 100 Loss: 0.708422 acc :0.89662\n",
      "Iteration: 120 Loss: 0.71635 acc :0.918489\n",
      "Iteration: 140 Loss: 0.712311 acc :0.90239\n",
      "Iteration: 160 Loss: 0.699793 acc :0.926295\n",
      "Iteration: 180 Loss: 0.716119 acc :0.920319\n",
      "validation Accuracy (127): 0.7564\n",
      "Iteration: 0 Loss: 0.678163 acc :0.920319\n",
      "Iteration: 20 Loss: 0.699312 acc :0.918327\n",
      "Iteration: 40 Loss: 0.681393 acc :0.914343\n",
      "Iteration: 60 Loss: 0.723497 acc :0.90239\n",
      "Iteration: 80 Loss: 0.711576 acc :0.910537\n",
      "Iteration: 100 Loss: 0.697601 acc :0.906561\n",
      "Iteration: 120 Loss: 0.723447 acc :0.904572\n",
      "Iteration: 140 Loss: 0.706273 acc :0.920319\n",
      "Iteration: 160 Loss: 0.754788 acc :0.888446\n",
      "Iteration: 180 Loss: 0.711985 acc :0.912351\n",
      "validation Accuracy (128): 0.7568\n",
      "Iteration: 0 Loss: 0.701792 acc :0.910359\n",
      "Iteration: 20 Loss: 0.694542 acc :0.912351\n",
      "Iteration: 40 Loss: 0.688582 acc :0.910359\n",
      "Iteration: 60 Loss: 0.703042 acc :0.906375\n",
      "Iteration: 80 Loss: 0.689367 acc :0.922465\n",
      "Iteration: 100 Loss: 0.705264 acc :0.912525\n",
      "Iteration: 120 Loss: 0.726296 acc :0.900596\n",
      "Iteration: 140 Loss: 0.689863 acc :0.924303\n",
      "Iteration: 160 Loss: 0.693406 acc :0.910359\n",
      "Iteration: 180 Loss: 0.709327 acc :0.912351\n",
      "validation Accuracy (129): 0.7582\n",
      "Iteration: 0 Loss: 0.669479 acc :0.928287\n",
      "Iteration: 20 Loss: 0.72927 acc :0.904383\n",
      "Iteration: 40 Loss: 0.696793 acc :0.908367\n",
      "Iteration: 60 Loss: 0.691002 acc :0.916335\n",
      "Iteration: 80 Loss: 0.740051 acc :0.890656\n",
      "Iteration: 100 Loss: 0.707676 acc :0.890656\n",
      "Iteration: 120 Loss: 0.728065 acc :0.908549\n",
      "Iteration: 140 Loss: 0.706637 acc :0.918327\n",
      "Iteration: 160 Loss: 0.715566 acc :0.890438\n",
      "Iteration: 180 Loss: 0.694668 acc :0.912351\n",
      "validation Accuracy (130): 0.7581\n",
      "Iteration: 0 Loss: 0.652089 acc :0.924303\n",
      "Iteration: 20 Loss: 0.709026 acc :0.922311\n",
      "Iteration: 40 Loss: 0.689316 acc :0.912351\n",
      "Iteration: 60 Loss: 0.720919 acc :0.904382\n",
      "Iteration: 80 Loss: 0.69399 acc :0.908549\n",
      "Iteration: 100 Loss: 0.703778 acc :0.904572\n",
      "Iteration: 120 Loss: 0.729142 acc :0.898608\n",
      "Iteration: 140 Loss: 0.707827 acc :0.918327\n",
      "Iteration: 160 Loss: 0.6828 acc :0.918327\n",
      "Iteration: 180 Loss: 0.706421 acc :0.912351\n",
      "validation Accuracy (131): 0.7593\n",
      "Iteration: 0 Loss: 0.696075 acc :0.912351\n",
      "Iteration: 20 Loss: 0.692612 acc :0.920319\n",
      "Iteration: 40 Loss: 0.719059 acc :0.908367\n",
      "Iteration: 60 Loss: 0.691441 acc :0.918327\n",
      "Iteration: 80 Loss: 0.709642 acc :0.904572\n",
      "Iteration: 100 Loss: 0.694394 acc :0.910537\n",
      "Iteration: 120 Loss: 0.733405 acc :0.910537\n",
      "Iteration: 140 Loss: 0.721844 acc :0.916335\n",
      "Iteration: 160 Loss: 0.68215 acc :0.930279\n",
      "Iteration: 180 Loss: 0.705169 acc :0.912351\n",
      "validation Accuracy (132): 0.7506\n",
      "Iteration: 0 Loss: 0.704479 acc :0.914343\n",
      "Iteration: 20 Loss: 0.692436 acc :0.920319\n",
      "Iteration: 40 Loss: 0.703325 acc :0.914343\n",
      "Iteration: 60 Loss: 0.714668 acc :0.90239\n",
      "Iteration: 80 Loss: 0.708187 acc :0.900596\n",
      "Iteration: 100 Loss: 0.704242 acc :0.910537\n",
      "Iteration: 120 Loss: 0.728251 acc :0.898608\n",
      "Iteration: 140 Loss: 0.700455 acc :0.914343\n",
      "Iteration: 160 Loss: 0.701023 acc :0.916335\n",
      "Iteration: 180 Loss: 0.735138 acc :0.896414\n",
      "validation Accuracy (133): 0.7563\n",
      "Iteration: 0 Loss: 0.697996 acc :0.906375\n",
      "Iteration: 20 Loss: 0.684983 acc :0.916335\n",
      "Iteration: 40 Loss: 0.686054 acc :0.924303\n",
      "Iteration: 60 Loss: 0.699826 acc :0.908367\n",
      "Iteration: 80 Loss: 0.710948 acc :0.902584\n",
      "Iteration: 100 Loss: 0.700954 acc :0.924453\n",
      "Iteration: 120 Loss: 0.725722 acc :0.910537\n",
      "Iteration: 140 Loss: 0.697214 acc :0.920319\n",
      "Iteration: 160 Loss: 0.728775 acc :0.904383\n",
      "Iteration: 180 Loss: 0.728128 acc :0.898406\n",
      "validation Accuracy (134): 0.7549\n",
      "Iteration: 0 Loss: 0.681524 acc :0.928287\n",
      "Iteration: 20 Loss: 0.697452 acc :0.914343\n",
      "Iteration: 40 Loss: 0.69607 acc :0.910359\n",
      "Iteration: 60 Loss: 0.745621 acc :0.890438\n",
      "Iteration: 80 Loss: 0.686309 acc :0.930417\n",
      "Iteration: 100 Loss: 0.689521 acc :0.916501\n",
      "Iteration: 120 Loss: 0.737226 acc :0.902584\n",
      "Iteration: 140 Loss: 0.714393 acc :0.922311\n",
      "Iteration: 160 Loss: 0.715846 acc :0.904382\n",
      "Iteration: 180 Loss: 0.694393 acc :0.912351\n",
      "validation Accuracy (135): 0.7503\n",
      "Iteration: 0 Loss: 0.74565 acc :0.900398\n",
      "Iteration: 20 Loss: 0.716291 acc :0.910359\n",
      "Iteration: 40 Loss: 0.712937 acc :0.918327\n",
      "Iteration: 60 Loss: 0.720625 acc :0.906375\n",
      "Iteration: 80 Loss: 0.712912 acc :0.908549\n",
      "Iteration: 100 Loss: 0.699989 acc :0.904572\n",
      "Iteration: 120 Loss: 0.726325 acc :0.908549\n",
      "Iteration: 140 Loss: 0.70843 acc :0.918327\n",
      "Iteration: 160 Loss: 0.680286 acc :0.920319\n",
      "Iteration: 180 Loss: 0.713337 acc :0.90239\n",
      "validation Accuracy (136): 0.7544\n",
      "Iteration: 0 Loss: 0.722539 acc :0.898406\n",
      "Iteration: 20 Loss: 0.697321 acc :0.914343\n",
      "Iteration: 40 Loss: 0.691893 acc :0.906375\n",
      "Iteration: 60 Loss: 0.731459 acc :0.898406\n",
      "Iteration: 80 Loss: 0.688118 acc :0.926441\n",
      "Iteration: 100 Loss: 0.672493 acc :0.920477\n",
      "Iteration: 120 Loss: 0.744926 acc :0.898608\n",
      "Iteration: 140 Loss: 0.716189 acc :0.924303\n",
      "Iteration: 160 Loss: 0.706152 acc :0.910359\n",
      "Iteration: 180 Loss: 0.713257 acc :0.900398\n",
      "validation Accuracy (137): 0.7573\n",
      "Iteration: 0 Loss: 0.73079 acc :0.906375\n",
      "Iteration: 20 Loss: 0.713067 acc :0.896414\n",
      "Iteration: 40 Loss: 0.702556 acc :0.900398\n",
      "Iteration: 60 Loss: 0.706984 acc :0.910359\n",
      "Iteration: 80 Loss: 0.671502 acc :0.928429\n",
      "Iteration: 100 Loss: 0.684086 acc :0.920477\n",
      "Iteration: 120 Loss: 0.732346 acc :0.904572\n",
      "Iteration: 140 Loss: 0.71268 acc :0.918327\n",
      "Iteration: 160 Loss: 0.705162 acc :0.916335\n",
      "Iteration: 180 Loss: 0.721366 acc :0.900398\n",
      "validation Accuracy (138): 0.7604\n",
      "Iteration: 0 Loss: 0.683056 acc :0.930279\n",
      "Iteration: 20 Loss: 0.701634 acc :0.918327\n",
      "Iteration: 40 Loss: 0.7003 acc :0.906375\n",
      "Iteration: 60 Loss: 0.711693 acc :0.908367\n",
      "Iteration: 80 Loss: 0.686157 acc :0.912525\n",
      "Iteration: 100 Loss: 0.699514 acc :0.908549\n",
      "Iteration: 120 Loss: 0.751976 acc :0.902584\n",
      "Iteration: 140 Loss: 0.691329 acc :0.910359\n",
      "Iteration: 160 Loss: 0.682961 acc :0.916335\n",
      "Iteration: 180 Loss: 0.728447 acc :0.89243\n",
      "validation Accuracy (139): 0.759\n",
      "Iteration: 0 Loss: 0.692895 acc :0.920319\n",
      "Iteration: 20 Loss: 0.688578 acc :0.926295\n",
      "Iteration: 40 Loss: 0.659942 acc :0.928287\n",
      "Iteration: 60 Loss: 0.738743 acc :0.906375\n",
      "Iteration: 80 Loss: 0.663269 acc :0.934394\n",
      "Iteration: 100 Loss: 0.698977 acc :0.916501\n",
      "Iteration: 120 Loss: 0.736511 acc :0.908549\n",
      "Iteration: 140 Loss: 0.707419 acc :0.912351\n",
      "Iteration: 160 Loss: 0.733049 acc :0.898406\n",
      "Iteration: 180 Loss: 0.68814 acc :0.912351\n",
      "validation Accuracy (140): 0.7545\n",
      "Iteration: 0 Loss: 0.712266 acc :0.918327\n",
      "Iteration: 20 Loss: 0.699242 acc :0.918327\n",
      "Iteration: 40 Loss: 0.698667 acc :0.90239\n",
      "Iteration: 60 Loss: 0.719089 acc :0.908367\n",
      "Iteration: 80 Loss: 0.675356 acc :0.924453\n",
      "Iteration: 100 Loss: 0.688855 acc :0.910537\n",
      "Iteration: 120 Loss: 0.735266 acc :0.898608\n",
      "Iteration: 140 Loss: 0.716913 acc :0.914343\n",
      "Iteration: 160 Loss: 0.705193 acc :0.912351\n",
      "Iteration: 180 Loss: 0.715025 acc :0.910359\n",
      "validation Accuracy (141): 0.7614\n",
      "Iteration: 0 Loss: 0.697112 acc :0.918327\n",
      "Iteration: 20 Loss: 0.687385 acc :0.930279\n",
      "Iteration: 40 Loss: 0.697912 acc :0.90239\n",
      "Iteration: 60 Loss: 0.707253 acc :0.918327\n",
      "Iteration: 80 Loss: 0.703474 acc :0.910537\n",
      "Iteration: 100 Loss: 0.72648 acc :0.894632\n",
      "Iteration: 120 Loss: 0.721006 acc :0.904572\n",
      "Iteration: 140 Loss: 0.699877 acc :0.920319\n",
      "Iteration: 160 Loss: 0.721881 acc :0.906375\n",
      "Iteration: 180 Loss: 0.715388 acc :0.916335\n",
      "validation Accuracy (142): 0.7588\n",
      "Iteration: 0 Loss: 0.685552 acc :0.920319\n",
      "Iteration: 20 Loss: 0.719112 acc :0.908367\n",
      "Iteration: 40 Loss: 0.679496 acc :0.916335\n",
      "Iteration: 60 Loss: 0.68813 acc :0.920319\n",
      "Iteration: 80 Loss: 0.701279 acc :0.906561\n",
      "Iteration: 100 Loss: 0.691626 acc :0.906561\n",
      "Iteration: 120 Loss: 0.725539 acc :0.902584\n",
      "Iteration: 140 Loss: 0.715758 acc :0.908367\n",
      "Iteration: 160 Loss: 0.721526 acc :0.894422\n",
      "Iteration: 180 Loss: 0.723224 acc :0.900398\n",
      "validation Accuracy (143): 0.7581\n",
      "Iteration: 0 Loss: 0.6925 acc :0.918327\n",
      "Iteration: 20 Loss: 0.673317 acc :0.910359\n",
      "Iteration: 40 Loss: 0.689407 acc :0.928287\n",
      "Iteration: 60 Loss: 0.716892 acc :0.916335\n",
      "Iteration: 80 Loss: 0.714477 acc :0.902584\n",
      "Iteration: 100 Loss: 0.677963 acc :0.926441\n",
      "Iteration: 120 Loss: 0.736442 acc :0.900596\n",
      "Iteration: 140 Loss: 0.673652 acc :0.926295\n",
      "Iteration: 160 Loss: 0.686304 acc :0.900398\n",
      "Iteration: 180 Loss: 0.709171 acc :0.906375\n",
      "validation Accuracy (144): 0.7532\n",
      "Iteration: 0 Loss: 0.710224 acc :0.918327\n",
      "Iteration: 20 Loss: 0.686927 acc :0.920319\n",
      "Iteration: 40 Loss: 0.700136 acc :0.914343\n",
      "Iteration: 60 Loss: 0.686396 acc :0.926295\n",
      "Iteration: 80 Loss: 0.664921 acc :0.922465\n",
      "Iteration: 100 Loss: 0.688583 acc :0.926441\n",
      "Iteration: 120 Loss: 0.742372 acc :0.880716\n",
      "Iteration: 140 Loss: 0.695587 acc :0.912351\n",
      "Iteration: 160 Loss: 0.718902 acc :0.90239\n",
      "Iteration: 180 Loss: 0.715702 acc :0.908367\n",
      "validation Accuracy (145): 0.7541\n",
      "Iteration: 0 Loss: 0.690754 acc :0.908367\n",
      "Iteration: 20 Loss: 0.685376 acc :0.916335\n",
      "Iteration: 40 Loss: 0.694913 acc :0.916335\n",
      "Iteration: 60 Loss: 0.708786 acc :0.914343\n",
      "Iteration: 80 Loss: 0.676193 acc :0.912525\n",
      "Iteration: 100 Loss: 0.685051 acc :0.924453\n",
      "Iteration: 120 Loss: 0.764363 acc :0.900596\n",
      "Iteration: 140 Loss: 0.680994 acc :0.928287\n",
      "Iteration: 160 Loss: 0.684543 acc :0.914343\n",
      "Iteration: 180 Loss: 0.739258 acc :0.900398\n",
      "validation Accuracy (146): 0.7574\n",
      "Iteration: 0 Loss: 0.697838 acc :0.90239\n",
      "Iteration: 20 Loss: 0.702313 acc :0.908367\n",
      "Iteration: 40 Loss: 0.684082 acc :0.916335\n",
      "Iteration: 60 Loss: 0.695735 acc :0.918327\n",
      "Iteration: 80 Loss: 0.704803 acc :0.910537\n",
      "Iteration: 100 Loss: 0.667535 acc :0.916501\n",
      "Iteration: 120 Loss: 0.744804 acc :0.900596\n",
      "Iteration: 140 Loss: 0.734298 acc :0.916335\n",
      "Iteration: 160 Loss: 0.693235 acc :0.896414\n",
      "Iteration: 180 Loss: 0.720099 acc :0.900398\n",
      "validation Accuracy (147): 0.7636\n",
      "Iteration: 0 Loss: 0.750025 acc :0.900398\n",
      "Iteration: 20 Loss: 0.698362 acc :0.924303\n",
      "Iteration: 40 Loss: 0.708193 acc :0.920319\n",
      "Iteration: 60 Loss: 0.712061 acc :0.908367\n",
      "Iteration: 80 Loss: 0.694756 acc :0.922465\n",
      "Iteration: 100 Loss: 0.691447 acc :0.910537\n",
      "Iteration: 120 Loss: 0.754753 acc :0.908549\n",
      "Iteration: 140 Loss: 0.702761 acc :0.928287\n",
      "Iteration: 160 Loss: 0.732005 acc :0.896414\n",
      "Iteration: 180 Loss: 0.727161 acc :0.906375\n",
      "validation Accuracy (148): 0.7599\n",
      "Iteration: 0 Loss: 0.708862 acc :0.908367\n",
      "Iteration: 20 Loss: 0.698303 acc :0.910359\n",
      "Iteration: 40 Loss: 0.713026 acc :0.898406\n",
      "Iteration: 60 Loss: 0.707903 acc :0.918327\n",
      "Iteration: 80 Loss: 0.677611 acc :0.924453\n",
      "Iteration: 100 Loss: 0.68644 acc :0.922465\n",
      "Iteration: 120 Loss: 0.716991 acc :0.904573\n",
      "Iteration: 140 Loss: 0.695742 acc :0.910359\n",
      "Iteration: 160 Loss: 0.684646 acc :0.916335\n",
      "Iteration: 180 Loss: 0.718759 acc :0.886454\n",
      "validation Accuracy (149): 0.7629\n",
      "Iteration: 0 Loss: 0.701801 acc :0.914343\n",
      "Iteration: 20 Loss: 0.671823 acc :0.922311\n",
      "Iteration: 40 Loss: 0.691308 acc :0.908367\n",
      "Iteration: 60 Loss: 0.726602 acc :0.90239\n",
      "Iteration: 80 Loss: 0.678203 acc :0.916501\n",
      "Iteration: 100 Loss: 0.67735 acc :0.928429\n",
      "Iteration: 120 Loss: 0.737213 acc :0.904573\n",
      "Iteration: 140 Loss: 0.696352 acc :0.908367\n",
      "Iteration: 160 Loss: 0.727481 acc :0.906375\n",
      "Iteration: 180 Loss: 0.727947 acc :0.900398\n",
      "validation Accuracy (150): 0.7571\n",
      "Iteration: 0 Loss: 0.707483 acc :0.904383\n",
      "Iteration: 20 Loss: 0.722673 acc :0.912351\n",
      "Iteration: 40 Loss: 0.677925 acc :0.928287\n",
      "Iteration: 60 Loss: 0.729888 acc :0.912351\n",
      "Iteration: 80 Loss: 0.711738 acc :0.894632\n",
      "Iteration: 100 Loss: 0.715606 acc :0.892644\n",
      "Iteration: 120 Loss: 0.718542 acc :0.906561\n",
      "Iteration: 140 Loss: 0.679103 acc :0.928287\n",
      "Iteration: 160 Loss: 0.694924 acc :0.914343\n",
      "Iteration: 180 Loss: 0.712774 acc :0.908367\n",
      "validation Accuracy (151): 0.7552\n",
      "Iteration: 0 Loss: 0.72141 acc :0.916335\n",
      "Iteration: 20 Loss: 0.693471 acc :0.910359\n",
      "Iteration: 40 Loss: 0.699748 acc :0.918327\n",
      "Iteration: 60 Loss: 0.711653 acc :0.914343\n",
      "Iteration: 80 Loss: 0.718411 acc :0.904572\n",
      "Iteration: 100 Loss: 0.690307 acc :0.926441\n",
      "Iteration: 120 Loss: 0.733484 acc :0.900596\n",
      "Iteration: 140 Loss: 0.688654 acc :0.930279\n",
      "Iteration: 160 Loss: 0.675111 acc :0.920319\n",
      "Iteration: 180 Loss: 0.720505 acc :0.89243\n",
      "validation Accuracy (152): 0.7587\n",
      "Iteration: 0 Loss: 0.717309 acc :0.912351\n",
      "Iteration: 20 Loss: 0.696086 acc :0.920319\n",
      "Iteration: 40 Loss: 0.676882 acc :0.922311\n",
      "Iteration: 60 Loss: 0.717576 acc :0.90239\n",
      "Iteration: 80 Loss: 0.69951 acc :0.910537\n",
      "Iteration: 100 Loss: 0.697901 acc :0.912525\n",
      "Iteration: 120 Loss: 0.731055 acc :0.910537\n",
      "Iteration: 140 Loss: 0.695647 acc :0.912351\n",
      "Iteration: 160 Loss: 0.70016 acc :0.904382\n",
      "Iteration: 180 Loss: 0.723512 acc :0.89243\n",
      "validation Accuracy (153): 0.7595\n",
      "Iteration: 0 Loss: 0.697615 acc :0.912351\n",
      "Iteration: 20 Loss: 0.706622 acc :0.920319\n",
      "Iteration: 40 Loss: 0.680786 acc :0.932271\n",
      "Iteration: 60 Loss: 0.754955 acc :0.884462\n",
      "Iteration: 80 Loss: 0.690685 acc :0.910537\n",
      "Iteration: 100 Loss: 0.695155 acc :0.914513\n",
      "Iteration: 120 Loss: 0.71525 acc :0.914513\n",
      "Iteration: 140 Loss: 0.686921 acc :0.926295\n",
      "Iteration: 160 Loss: 0.732138 acc :0.90239\n",
      "Iteration: 180 Loss: 0.707642 acc :0.906375\n",
      "validation Accuracy (154): 0.7604\n",
      "Iteration: 0 Loss: 0.697247 acc :0.928287\n",
      "Iteration: 20 Loss: 0.703952 acc :0.920319\n",
      "Iteration: 40 Loss: 0.69602 acc :0.910359\n",
      "Iteration: 60 Loss: 0.712854 acc :0.904382\n",
      "Iteration: 80 Loss: 0.694027 acc :0.900596\n",
      "Iteration: 100 Loss: 0.688909 acc :0.914513\n",
      "Iteration: 120 Loss: 0.735253 acc :0.910537\n",
      "Iteration: 140 Loss: 0.688817 acc :0.908367\n",
      "Iteration: 160 Loss: 0.69371 acc :0.902391\n",
      "Iteration: 180 Loss: 0.729248 acc :0.90239\n",
      "validation Accuracy (155): 0.7604\n",
      "Iteration: 0 Loss: 0.709468 acc :0.906375\n",
      "Iteration: 20 Loss: 0.701775 acc :0.920319\n",
      "Iteration: 40 Loss: 0.681498 acc :0.912351\n",
      "Iteration: 60 Loss: 0.695622 acc :0.926295\n",
      "Iteration: 80 Loss: 0.724275 acc :0.89662\n",
      "Iteration: 100 Loss: 0.688714 acc :0.918489\n",
      "Iteration: 120 Loss: 0.749686 acc :0.906561\n",
      "Iteration: 140 Loss: 0.709701 acc :0.908367\n",
      "Iteration: 160 Loss: 0.712201 acc :0.90239\n",
      "Iteration: 180 Loss: 0.745003 acc :0.890438\n",
      "validation Accuracy (156): 0.762\n",
      "Iteration: 0 Loss: 0.694247 acc :0.920319\n",
      "Iteration: 20 Loss: 0.718129 acc :0.922311\n",
      "Iteration: 40 Loss: 0.688663 acc :0.916335\n",
      "Iteration: 60 Loss: 0.696273 acc :0.926295\n",
      "Iteration: 80 Loss: 0.699095 acc :0.916501\n",
      "Iteration: 100 Loss: 0.692234 acc :0.912525\n",
      "Iteration: 120 Loss: 0.754137 acc :0.89662\n",
      "Iteration: 140 Loss: 0.673637 acc :0.918327\n",
      "Iteration: 160 Loss: 0.720397 acc :0.904383\n",
      "Iteration: 180 Loss: 0.739934 acc :0.88247\n",
      "validation Accuracy (157): 0.7615\n",
      "Iteration: 0 Loss: 0.698793 acc :0.918327\n",
      "Iteration: 20 Loss: 0.686483 acc :0.920319\n",
      "Iteration: 40 Loss: 0.687494 acc :0.926295\n",
      "Iteration: 60 Loss: 0.710662 acc :0.912351\n",
      "Iteration: 80 Loss: 0.703617 acc :0.902584\n",
      "Iteration: 100 Loss: 0.710166 acc :0.910537\n",
      "Iteration: 120 Loss: 0.720997 acc :0.906561\n",
      "Iteration: 140 Loss: 0.685171 acc :0.912351\n",
      "Iteration: 160 Loss: 0.682358 acc :0.918327\n",
      "Iteration: 180 Loss: 0.72308 acc :0.90239\n",
      "validation Accuracy (158): 0.7594\n",
      "Iteration: 0 Loss: 0.685169 acc :0.924303\n",
      "Iteration: 20 Loss: 0.711729 acc :0.914343\n",
      "Iteration: 40 Loss: 0.688221 acc :0.920319\n",
      "Iteration: 60 Loss: 0.694052 acc :0.924303\n",
      "Iteration: 80 Loss: 0.684411 acc :0.916501\n",
      "Iteration: 100 Loss: 0.713745 acc :0.894632\n",
      "Iteration: 120 Loss: 0.740059 acc :0.900596\n",
      "Iteration: 140 Loss: 0.686252 acc :0.934263\n",
      "Iteration: 160 Loss: 0.715528 acc :0.910359\n",
      "Iteration: 180 Loss: 0.706365 acc :0.906375\n",
      "validation Accuracy (159): 0.7614\n",
      "Iteration: 0 Loss: 0.688632 acc :0.926295\n",
      "Iteration: 20 Loss: 0.714413 acc :0.906375\n",
      "Iteration: 40 Loss: 0.69859 acc :0.912351\n",
      "Iteration: 60 Loss: 0.720301 acc :0.910359\n",
      "Iteration: 80 Loss: 0.697983 acc :0.902584\n",
      "Iteration: 100 Loss: 0.689991 acc :0.910537\n",
      "Iteration: 120 Loss: 0.723635 acc :0.912525\n",
      "Iteration: 140 Loss: 0.685063 acc :0.932271\n",
      "Iteration: 160 Loss: 0.703882 acc :0.898406\n",
      "Iteration: 180 Loss: 0.700205 acc :0.906375\n",
      "validation Accuracy (160): 0.7628\n",
      "Iteration: 0 Loss: 0.714859 acc :0.918327\n",
      "Iteration: 20 Loss: 0.709165 acc :0.912351\n",
      "Iteration: 40 Loss: 0.679307 acc :0.922311\n",
      "Iteration: 60 Loss: 0.694067 acc :0.906375\n",
      "Iteration: 80 Loss: 0.697318 acc :0.904572\n",
      "Iteration: 100 Loss: 0.681256 acc :0.920477\n",
      "Iteration: 120 Loss: 0.757728 acc :0.900596\n",
      "Iteration: 140 Loss: 0.692145 acc :0.924303\n",
      "Iteration: 160 Loss: 0.723233 acc :0.900398\n",
      "Iteration: 180 Loss: 0.722816 acc :0.914343\n",
      "validation Accuracy (161): 0.7591\n",
      "Iteration: 0 Loss: 0.674848 acc :0.932271\n",
      "Iteration: 20 Loss: 0.710311 acc :0.920319\n",
      "Iteration: 40 Loss: 0.694397 acc :0.898406\n",
      "Iteration: 60 Loss: 0.667217 acc :0.926295\n",
      "Iteration: 80 Loss: 0.713352 acc :0.898608\n",
      "Iteration: 100 Loss: 0.680004 acc :0.926441\n",
      "Iteration: 120 Loss: 0.737625 acc :0.898608\n",
      "Iteration: 140 Loss: 0.695204 acc :0.914343\n",
      "Iteration: 160 Loss: 0.697564 acc :0.910359\n",
      "Iteration: 180 Loss: 0.726338 acc :0.900398\n",
      "validation Accuracy (162): 0.7581\n",
      "Iteration: 0 Loss: 0.694341 acc :0.914343\n",
      "Iteration: 20 Loss: 0.724406 acc :0.908367\n",
      "Iteration: 40 Loss: 0.698677 acc :0.914343\n",
      "Iteration: 60 Loss: 0.70045 acc :0.924303\n",
      "Iteration: 80 Loss: 0.698029 acc :0.916501\n",
      "Iteration: 100 Loss: 0.676288 acc :0.918489\n",
      "Iteration: 120 Loss: 0.730905 acc :0.882704\n",
      "Iteration: 140 Loss: 0.694277 acc :0.924303\n",
      "Iteration: 160 Loss: 0.708352 acc :0.912351\n",
      "Iteration: 180 Loss: 0.720447 acc :0.906375\n",
      "validation Accuracy (163): 0.7634\n",
      "Iteration: 0 Loss: 0.731985 acc :0.888446\n",
      "Iteration: 20 Loss: 0.687754 acc :0.938247\n",
      "Iteration: 40 Loss: 0.707483 acc :0.924303\n",
      "Iteration: 60 Loss: 0.679848 acc :0.912351\n",
      "Iteration: 80 Loss: 0.697716 acc :0.906561\n",
      "Iteration: 100 Loss: 0.700053 acc :0.914513\n",
      "Iteration: 120 Loss: 0.747345 acc :0.89662\n",
      "Iteration: 140 Loss: 0.695333 acc :0.912351\n",
      "Iteration: 160 Loss: 0.688295 acc :0.912351\n",
      "Iteration: 180 Loss: 0.698154 acc :0.906375\n",
      "validation Accuracy (164): 0.7616\n",
      "Iteration: 0 Loss: 0.67663 acc :0.922311\n",
      "Iteration: 20 Loss: 0.696154 acc :0.914343\n",
      "Iteration: 40 Loss: 0.697787 acc :0.918327\n",
      "Iteration: 60 Loss: 0.732904 acc :0.906375\n",
      "Iteration: 80 Loss: 0.700714 acc :0.908549\n",
      "Iteration: 100 Loss: 0.691373 acc :0.908549\n",
      "Iteration: 120 Loss: 0.739029 acc :0.908549\n",
      "Iteration: 140 Loss: 0.695236 acc :0.922311\n",
      "Iteration: 160 Loss: 0.716901 acc :0.908367\n",
      "Iteration: 180 Loss: 0.713582 acc :0.912351\n",
      "validation Accuracy (165): 0.7598\n",
      "Iteration: 0 Loss: 0.700237 acc :0.920319\n",
      "Iteration: 20 Loss: 0.69601 acc :0.920319\n",
      "Iteration: 40 Loss: 0.69896 acc :0.906375\n",
      "Iteration: 60 Loss: 0.704723 acc :0.904382\n",
      "Iteration: 80 Loss: 0.697369 acc :0.908549\n",
      "Iteration: 100 Loss: 0.684117 acc :0.918489\n",
      "Iteration: 120 Loss: 0.726561 acc :0.912525\n",
      "Iteration: 140 Loss: 0.70872 acc :0.914343\n",
      "Iteration: 160 Loss: 0.705761 acc :0.908367\n",
      "Iteration: 180 Loss: 0.699099 acc :0.914343\n",
      "validation Accuracy (166): 0.7619\n",
      "Iteration: 0 Loss: 0.683599 acc :0.920319\n",
      "Iteration: 20 Loss: 0.692164 acc :0.922311\n",
      "Iteration: 40 Loss: 0.689378 acc :0.920319\n",
      "Iteration: 60 Loss: 0.765446 acc :0.900398\n",
      "Iteration: 80 Loss: 0.708387 acc :0.910537\n",
      "Iteration: 100 Loss: 0.686845 acc :0.908549\n",
      "Iteration: 120 Loss: 0.733948 acc :0.902584\n",
      "Iteration: 140 Loss: 0.714236 acc :0.922311\n",
      "Iteration: 160 Loss: 0.703239 acc :0.900398\n",
      "Iteration: 180 Loss: 0.710961 acc :0.900398\n",
      "validation Accuracy (167): 0.7593\n",
      "Iteration: 0 Loss: 0.711369 acc :0.914343\n",
      "Iteration: 20 Loss: 0.69255 acc :0.920319\n",
      "Iteration: 40 Loss: 0.695847 acc :0.918327\n",
      "Iteration: 60 Loss: 0.713677 acc :0.904383\n",
      "Iteration: 80 Loss: 0.693084 acc :0.926441\n",
      "Iteration: 100 Loss: 0.685816 acc :0.914513\n",
      "Iteration: 120 Loss: 0.714775 acc :0.916501\n",
      "Iteration: 140 Loss: 0.705174 acc :0.906375\n",
      "Iteration: 160 Loss: 0.690058 acc :0.924303\n",
      "Iteration: 180 Loss: 0.701215 acc :0.912351\n",
      "validation Accuracy (168): 0.7634\n",
      "Iteration: 0 Loss: 0.711758 acc :0.898406\n",
      "Iteration: 20 Loss: 0.70381 acc :0.918327\n",
      "Iteration: 40 Loss: 0.697464 acc :0.904382\n",
      "Iteration: 60 Loss: 0.70949 acc :0.910359\n",
      "Iteration: 80 Loss: 0.692164 acc :0.914513\n",
      "Iteration: 100 Loss: 0.67672 acc :0.920477\n",
      "Iteration: 120 Loss: 0.705863 acc :0.916501\n",
      "Iteration: 140 Loss: 0.713125 acc :0.914343\n",
      "Iteration: 160 Loss: 0.71622 acc :0.908367\n",
      "Iteration: 180 Loss: 0.730516 acc :0.90239\n",
      "validation Accuracy (169): 0.7607\n",
      "Iteration: 0 Loss: 0.689288 acc :0.920319\n",
      "Iteration: 20 Loss: 0.697796 acc :0.928287\n",
      "Iteration: 40 Loss: 0.688288 acc :0.924303\n",
      "Iteration: 60 Loss: 0.679928 acc :0.924303\n",
      "Iteration: 80 Loss: 0.694942 acc :0.914513\n",
      "Iteration: 100 Loss: 0.675093 acc :0.916501\n",
      "Iteration: 120 Loss: 0.741274 acc :0.902584\n",
      "Iteration: 140 Loss: 0.704588 acc :0.928287\n",
      "Iteration: 160 Loss: 0.681586 acc :0.928287\n",
      "Iteration: 180 Loss: 0.709783 acc :0.918327\n",
      "validation Accuracy (170): 0.7658\n",
      "Iteration: 0 Loss: 0.672975 acc :0.926295\n",
      "Iteration: 20 Loss: 0.693583 acc :0.924303\n",
      "Iteration: 40 Loss: 0.668174 acc :0.930279\n",
      "Iteration: 60 Loss: 0.68977 acc :0.922311\n",
      "Iteration: 80 Loss: 0.694978 acc :0.912525\n",
      "Iteration: 100 Loss: 0.696267 acc :0.918489\n",
      "Iteration: 120 Loss: 0.724799 acc :0.912525\n",
      "Iteration: 140 Loss: 0.678252 acc :0.930279\n",
      "Iteration: 160 Loss: 0.704629 acc :0.910359\n",
      "Iteration: 180 Loss: 0.713439 acc :0.910359\n",
      "validation Accuracy (171): 0.7616\n",
      "Iteration: 0 Loss: 0.690393 acc :0.922311\n",
      "Iteration: 20 Loss: 0.713188 acc :0.916335\n",
      "Iteration: 40 Loss: 0.680121 acc :0.914343\n",
      "Iteration: 60 Loss: 0.726362 acc :0.90239\n",
      "Iteration: 80 Loss: 0.699515 acc :0.908549\n",
      "Iteration: 100 Loss: 0.697333 acc :0.910537\n",
      "Iteration: 120 Loss: 0.7341 acc :0.908549\n",
      "Iteration: 140 Loss: 0.749112 acc :0.90239\n",
      "Iteration: 160 Loss: 0.733649 acc :0.904383\n",
      "Iteration: 180 Loss: 0.718226 acc :0.90239\n",
      "validation Accuracy (172): 0.7614\n",
      "Iteration: 0 Loss: 0.705129 acc :0.90239\n",
      "Iteration: 20 Loss: 0.710611 acc :0.906375\n",
      "Iteration: 40 Loss: 0.711983 acc :0.900398\n",
      "Iteration: 60 Loss: 0.721573 acc :0.908367\n",
      "Iteration: 80 Loss: 0.674846 acc :0.928429\n",
      "Iteration: 100 Loss: 0.690786 acc :0.900596\n",
      "Iteration: 120 Loss: 0.748324 acc :0.884692\n",
      "Iteration: 140 Loss: 0.72111 acc :0.918327\n",
      "Iteration: 160 Loss: 0.705107 acc :0.908367\n",
      "Iteration: 180 Loss: 0.75574 acc :0.894422\n",
      "validation Accuracy (173): 0.7541\n",
      "Iteration: 0 Loss: 0.688967 acc :0.920319\n",
      "Iteration: 20 Loss: 0.69129 acc :0.914343\n",
      "Iteration: 40 Loss: 0.688739 acc :0.916335\n",
      "Iteration: 60 Loss: 0.744548 acc :0.898406\n",
      "Iteration: 80 Loss: 0.689775 acc :0.910537\n",
      "Iteration: 100 Loss: 0.682159 acc :0.914513\n",
      "Iteration: 120 Loss: 0.745555 acc :0.892644\n",
      "Iteration: 140 Loss: 0.720436 acc :0.904382\n",
      "Iteration: 160 Loss: 0.699402 acc :0.918327\n",
      "Iteration: 180 Loss: 0.756367 acc :0.894422\n",
      "validation Accuracy (174): 0.7608\n",
      "Iteration: 0 Loss: 0.66907 acc :0.924303\n",
      "Iteration: 20 Loss: 0.683313 acc :0.920319\n",
      "Iteration: 40 Loss: 0.664291 acc :0.920319\n",
      "Iteration: 60 Loss: 0.741835 acc :0.902391\n",
      "Iteration: 80 Loss: 0.666549 acc :0.942346\n",
      "Iteration: 100 Loss: 0.705401 acc :0.904572\n",
      "Iteration: 120 Loss: 0.743113 acc :0.894632\n",
      "Iteration: 140 Loss: 0.675189 acc :0.926295\n",
      "Iteration: 160 Loss: 0.711904 acc :0.906375\n",
      "Iteration: 180 Loss: 0.729392 acc :0.918327\n",
      "validation Accuracy (175): 0.757\n",
      "Iteration: 0 Loss: 0.700072 acc :0.916335\n",
      "Iteration: 20 Loss: 0.707668 acc :0.924303\n",
      "Iteration: 40 Loss: 0.669324 acc :0.922311\n",
      "Iteration: 60 Loss: 0.728275 acc :0.888446\n",
      "Iteration: 80 Loss: 0.671037 acc :0.930417\n",
      "Iteration: 100 Loss: 0.689706 acc :0.908549\n",
      "Iteration: 120 Loss: 0.730635 acc :0.904572\n",
      "Iteration: 140 Loss: 0.675437 acc :0.926295\n",
      "Iteration: 160 Loss: 0.693445 acc :0.912351\n",
      "Iteration: 180 Loss: 0.731821 acc :0.906375\n",
      "validation Accuracy (176): 0.7615\n",
      "Iteration: 0 Loss: 0.699346 acc :0.916335\n",
      "Iteration: 20 Loss: 0.705141 acc :0.918327\n",
      "Iteration: 40 Loss: 0.679238 acc :0.926295\n",
      "Iteration: 60 Loss: 0.704117 acc :0.912351\n",
      "Iteration: 80 Loss: 0.68342 acc :0.922465\n",
      "Iteration: 100 Loss: 0.684187 acc :0.922465\n",
      "Iteration: 120 Loss: 0.70949 acc :0.910537\n",
      "Iteration: 140 Loss: 0.708713 acc :0.912351\n",
      "Iteration: 160 Loss: 0.679615 acc :0.920319\n",
      "Iteration: 180 Loss: 0.738539 acc :0.886454\n",
      "validation Accuracy (177): 0.7584\n",
      "Iteration: 0 Loss: 0.705506 acc :0.90239\n",
      "Iteration: 20 Loss: 0.707633 acc :0.918327\n",
      "Iteration: 40 Loss: 0.69786 acc :0.910359\n",
      "Iteration: 60 Loss: 0.713924 acc :0.912351\n",
      "Iteration: 80 Loss: 0.677124 acc :0.920477\n",
      "Iteration: 100 Loss: 0.691211 acc :0.914513\n",
      "Iteration: 120 Loss: 0.730776 acc :0.89662\n",
      "Iteration: 140 Loss: 0.695325 acc :0.920319\n",
      "Iteration: 160 Loss: 0.703506 acc :0.916335\n",
      "Iteration: 180 Loss: 0.729151 acc :0.908367\n",
      "validation Accuracy (178): 0.761\n",
      "Iteration: 0 Loss: 0.707351 acc :0.912351\n",
      "Iteration: 20 Loss: 0.693722 acc :0.924303\n",
      "Iteration: 40 Loss: 0.716768 acc :0.908367\n",
      "Iteration: 60 Loss: 0.734944 acc :0.894422\n",
      "Iteration: 80 Loss: 0.695447 acc :0.922465\n",
      "Iteration: 100 Loss: 0.682446 acc :0.920477\n",
      "Iteration: 120 Loss: 0.748071 acc :0.892644\n",
      "Iteration: 140 Loss: 0.686805 acc :0.924303\n",
      "Iteration: 160 Loss: 0.693853 acc :0.918327\n",
      "Iteration: 180 Loss: 0.725911 acc :0.896414\n",
      "validation Accuracy (179): 0.7588\n",
      "Iteration: 0 Loss: 0.677737 acc :0.916335\n",
      "Iteration: 20 Loss: 0.693671 acc :0.908367\n",
      "Iteration: 40 Loss: 0.674494 acc :0.916335\n",
      "Iteration: 60 Loss: 0.710226 acc :0.916335\n",
      "Iteration: 80 Loss: 0.677843 acc :0.914513\n",
      "Iteration: 100 Loss: 0.69998 acc :0.904573\n",
      "Iteration: 120 Loss: 0.743841 acc :0.898608\n",
      "Iteration: 140 Loss: 0.715433 acc :0.920319\n",
      "Iteration: 160 Loss: 0.680529 acc :0.916335\n",
      "Iteration: 180 Loss: 0.731641 acc :0.90239\n",
      "validation Accuracy (180): 0.7604\n",
      "Iteration: 0 Loss: 0.704207 acc :0.904383\n",
      "Iteration: 20 Loss: 0.713897 acc :0.908367\n",
      "Iteration: 40 Loss: 0.687673 acc :0.914343\n",
      "Iteration: 60 Loss: 0.692814 acc :0.914343\n",
      "Iteration: 80 Loss: 0.704416 acc :0.906561\n",
      "Iteration: 100 Loss: 0.686087 acc :0.902584\n",
      "Iteration: 120 Loss: 0.746508 acc :0.920477\n",
      "Iteration: 140 Loss: 0.689119 acc :0.916335\n",
      "Iteration: 160 Loss: 0.683733 acc :0.922311\n",
      "Iteration: 180 Loss: 0.743637 acc :0.884462\n",
      "validation Accuracy (181): 0.762\n",
      "Iteration: 0 Loss: 0.680643 acc :0.934263\n",
      "Iteration: 20 Loss: 0.696094 acc :0.914343\n",
      "Iteration: 40 Loss: 0.700277 acc :0.918327\n",
      "Iteration: 60 Loss: 0.700903 acc :0.922311\n",
      "Iteration: 80 Loss: 0.676566 acc :0.926441\n",
      "Iteration: 100 Loss: 0.680646 acc :0.926441\n",
      "Iteration: 120 Loss: 0.71316 acc :0.918489\n",
      "Iteration: 140 Loss: 0.670237 acc :0.930279\n",
      "Iteration: 160 Loss: 0.715082 acc :0.916335\n",
      "Iteration: 180 Loss: 0.715523 acc :0.904382\n",
      "validation Accuracy (182): 0.7566\n",
      "Iteration: 0 Loss: 0.679293 acc :0.924303\n",
      "Iteration: 20 Loss: 0.707754 acc :0.910359\n",
      "Iteration: 40 Loss: 0.684011 acc :0.928287\n",
      "Iteration: 60 Loss: 0.729524 acc :0.894422\n",
      "Iteration: 80 Loss: 0.696697 acc :0.902584\n",
      "Iteration: 100 Loss: 0.68942 acc :0.908549\n",
      "Iteration: 120 Loss: 0.722381 acc :0.894632\n",
      "Iteration: 140 Loss: 0.669421 acc :0.936255\n",
      "Iteration: 160 Loss: 0.690657 acc :0.920319\n",
      "Iteration: 180 Loss: 0.742657 acc :0.896414\n",
      "validation Accuracy (183): 0.7602\n",
      "Iteration: 0 Loss: 0.681227 acc :0.918327\n",
      "Iteration: 20 Loss: 0.681634 acc :0.914343\n",
      "Iteration: 40 Loss: 0.705838 acc :0.912351\n",
      "Iteration: 60 Loss: 0.759582 acc :0.890438\n",
      "Iteration: 80 Loss: 0.707109 acc :0.890656\n",
      "Iteration: 100 Loss: 0.67786 acc :0.920477\n",
      "Iteration: 120 Loss: 0.742357 acc :0.892644\n",
      "Iteration: 140 Loss: 0.712522 acc :0.930279\n",
      "Iteration: 160 Loss: 0.696603 acc :0.916335\n",
      "Iteration: 180 Loss: 0.733552 acc :0.894422\n",
      "validation Accuracy (184): 0.7607\n",
      "Iteration: 0 Loss: 0.667782 acc :0.928287\n",
      "Iteration: 20 Loss: 0.70134 acc :0.922311\n",
      "Iteration: 40 Loss: 0.703169 acc :0.908367\n",
      "Iteration: 60 Loss: 0.714151 acc :0.910359\n",
      "Iteration: 80 Loss: 0.663893 acc :0.934394\n",
      "Iteration: 100 Loss: 0.679966 acc :0.926441\n",
      "Iteration: 120 Loss: 0.745965 acc :0.890656\n",
      "Iteration: 140 Loss: 0.663027 acc :0.936255\n",
      "Iteration: 160 Loss: 0.688748 acc :0.916335\n",
      "Iteration: 180 Loss: 0.701498 acc :0.926295\n",
      "validation Accuracy (185): 0.7572\n",
      "Iteration: 0 Loss: 0.734132 acc :0.898406\n",
      "Iteration: 20 Loss: 0.704019 acc :0.906375\n",
      "Iteration: 40 Loss: 0.69073 acc :0.924303\n",
      "Iteration: 60 Loss: 0.767576 acc :0.898406\n",
      "Iteration: 80 Loss: 0.681358 acc :0.916501\n",
      "Iteration: 100 Loss: 0.667356 acc :0.922465\n",
      "Iteration: 120 Loss: 0.75216 acc :0.892644\n",
      "Iteration: 140 Loss: 0.671276 acc :0.936255\n",
      "Iteration: 160 Loss: 0.68364 acc :0.910359\n",
      "Iteration: 180 Loss: 0.716944 acc :0.908367\n",
      "validation Accuracy (186): 0.7567\n",
      "Iteration: 0 Loss: 0.691896 acc :0.924303\n",
      "Iteration: 20 Loss: 0.682003 acc :0.918327\n",
      "Iteration: 40 Loss: 0.696181 acc :0.916335\n",
      "Iteration: 60 Loss: 0.747278 acc :0.904383\n",
      "Iteration: 80 Loss: 0.700331 acc :0.912525\n",
      "Iteration: 100 Loss: 0.666601 acc :0.920477\n",
      "Iteration: 120 Loss: 0.759292 acc :0.88668\n",
      "Iteration: 140 Loss: 0.706376 acc :0.914343\n",
      "Iteration: 160 Loss: 0.713964 acc :0.896414\n",
      "Iteration: 180 Loss: 0.741708 acc :0.90239\n",
      "validation Accuracy (187): 0.7604\n",
      "Iteration: 0 Loss: 0.679633 acc :0.928287\n",
      "Iteration: 20 Loss: 0.707429 acc :0.924303\n",
      "Iteration: 40 Loss: 0.674286 acc :0.916335\n",
      "Iteration: 60 Loss: 0.72871 acc :0.908367\n",
      "Iteration: 80 Loss: 0.686667 acc :0.922465\n",
      "Iteration: 100 Loss: 0.683405 acc :0.908549\n",
      "Iteration: 120 Loss: 0.737234 acc :0.898608\n",
      "Iteration: 140 Loss: 0.699514 acc :0.920319\n",
      "Iteration: 160 Loss: 0.690983 acc :0.916335\n",
      "Iteration: 180 Loss: 0.72516 acc :0.906375\n",
      "validation Accuracy (188): 0.7579\n",
      "Iteration: 0 Loss: 0.688169 acc :0.914343\n",
      "Iteration: 20 Loss: 0.731054 acc :0.896414\n",
      "Iteration: 40 Loss: 0.694056 acc :0.912351\n",
      "Iteration: 60 Loss: 0.74598 acc :0.886454\n",
      "Iteration: 80 Loss: 0.704488 acc :0.922465\n",
      "Iteration: 100 Loss: 0.664746 acc :0.916501\n",
      "Iteration: 120 Loss: 0.741939 acc :0.898608\n",
      "Iteration: 140 Loss: 0.689969 acc :0.924303\n",
      "Iteration: 160 Loss: 0.702354 acc :0.916335\n",
      "Iteration: 180 Loss: 0.742445 acc :0.906375\n",
      "validation Accuracy (189): 0.7629\n",
      "Iteration: 0 Loss: 0.688237 acc :0.920319\n",
      "Iteration: 20 Loss: 0.711222 acc :0.910359\n",
      "Iteration: 40 Loss: 0.702238 acc :0.912351\n",
      "Iteration: 60 Loss: 0.699914 acc :0.916335\n",
      "Iteration: 80 Loss: 0.675021 acc :0.920477\n",
      "Iteration: 100 Loss: 0.68903 acc :0.922465\n",
      "Iteration: 120 Loss: 0.721352 acc :0.908549\n",
      "Iteration: 140 Loss: 0.67024 acc :0.918327\n",
      "Iteration: 160 Loss: 0.689091 acc :0.936255\n",
      "Iteration: 180 Loss: 0.716687 acc :0.914343\n",
      "validation Accuracy (190): 0.7625\n",
      "Iteration: 0 Loss: 0.66777 acc :0.928287\n",
      "Iteration: 20 Loss: 0.71235 acc :0.922311\n",
      "Iteration: 40 Loss: 0.702127 acc :0.910359\n",
      "Iteration: 60 Loss: 0.734248 acc :0.894422\n",
      "Iteration: 80 Loss: 0.686154 acc :0.914513\n",
      "Iteration: 100 Loss: 0.667916 acc :0.908549\n",
      "Iteration: 120 Loss: 0.733311 acc :0.892644\n",
      "Iteration: 140 Loss: 0.676662 acc :0.942231\n",
      "Iteration: 160 Loss: 0.70991 acc :0.912351\n",
      "Iteration: 180 Loss: 0.718854 acc :0.902391\n",
      "validation Accuracy (191): 0.765\n",
      "Iteration: 0 Loss: 0.702195 acc :0.920319\n",
      "Iteration: 20 Loss: 0.688298 acc :0.920319\n",
      "Iteration: 40 Loss: 0.682019 acc :0.920319\n",
      "Iteration: 60 Loss: 0.739838 acc :0.90239\n",
      "Iteration: 80 Loss: 0.682729 acc :0.912525\n",
      "Iteration: 100 Loss: 0.662747 acc :0.914513\n",
      "Iteration: 120 Loss: 0.710334 acc :0.904572\n",
      "Iteration: 140 Loss: 0.698519 acc :0.908367\n",
      "Iteration: 160 Loss: 0.70023 acc :0.910359\n",
      "Iteration: 180 Loss: 0.710854 acc :0.908367\n",
      "validation Accuracy (192): 0.7545\n",
      "Iteration: 0 Loss: 0.697182 acc :0.900398\n",
      "Iteration: 20 Loss: 0.69428 acc :0.916335\n",
      "Iteration: 40 Loss: 0.699316 acc :0.916335\n",
      "Iteration: 60 Loss: 0.727765 acc :0.898406\n",
      "Iteration: 80 Loss: 0.705883 acc :0.912525\n",
      "Iteration: 100 Loss: 0.664752 acc :0.930417\n",
      "Iteration: 120 Loss: 0.751981 acc :0.898608\n",
      "Iteration: 140 Loss: 0.705099 acc :0.920319\n",
      "Iteration: 160 Loss: 0.708609 acc :0.906374\n",
      "Iteration: 180 Loss: 0.689921 acc :0.922311\n",
      "validation Accuracy (193): 0.758\n",
      "Iteration: 0 Loss: 0.710554 acc :0.910359\n",
      "Iteration: 20 Loss: 0.689442 acc :0.932271\n",
      "Iteration: 40 Loss: 0.70515 acc :0.914343\n",
      "Iteration: 60 Loss: 0.726794 acc :0.900398\n",
      "Iteration: 80 Loss: 0.693964 acc :0.916501\n",
      "Iteration: 100 Loss: 0.703758 acc :0.914513\n",
      "Iteration: 120 Loss: 0.737399 acc :0.908549\n",
      "Iteration: 140 Loss: 0.708076 acc :0.916335\n",
      "Iteration: 160 Loss: 0.701735 acc :0.908367\n",
      "Iteration: 180 Loss: 0.695942 acc :0.910359\n",
      "validation Accuracy (194): 0.7559\n",
      "Iteration: 0 Loss: 0.704292 acc :0.916335\n",
      "Iteration: 20 Loss: 0.692028 acc :0.912351\n",
      "Iteration: 40 Loss: 0.687487 acc :0.90239\n",
      "Iteration: 60 Loss: 0.713462 acc :0.914343\n",
      "Iteration: 80 Loss: 0.702943 acc :0.916501\n",
      "Iteration: 100 Loss: 0.664222 acc :0.934394\n",
      "Iteration: 120 Loss: 0.735825 acc :0.898608\n",
      "Iteration: 140 Loss: 0.713908 acc :0.914343\n",
      "Iteration: 160 Loss: 0.702878 acc :0.910359\n",
      "Iteration: 180 Loss: 0.726053 acc :0.908367\n",
      "validation Accuracy (195): 0.7552\n",
      "Iteration: 0 Loss: 0.708972 acc :0.916335\n",
      "Iteration: 20 Loss: 0.72519 acc :0.910359\n",
      "Iteration: 40 Loss: 0.713438 acc :0.908367\n",
      "Iteration: 60 Loss: 0.738557 acc :0.904383\n",
      "Iteration: 80 Loss: 0.696367 acc :0.922465\n",
      "Iteration: 100 Loss: 0.686038 acc :0.916501\n",
      "Iteration: 120 Loss: 0.744476 acc :0.894632\n",
      "Iteration: 140 Loss: 0.668996 acc :0.942231\n",
      "Iteration: 160 Loss: 0.686298 acc :0.918327\n",
      "Iteration: 180 Loss: 0.714681 acc :0.916335\n",
      "validation Accuracy (196): 0.7542\n",
      "Iteration: 0 Loss: 0.680225 acc :0.920319\n",
      "Iteration: 20 Loss: 0.670762 acc :0.930279\n",
      "Iteration: 40 Loss: 0.678498 acc :0.922311\n",
      "Iteration: 60 Loss: 0.721372 acc :0.908367\n",
      "Iteration: 80 Loss: 0.72007 acc :0.908549\n",
      "Iteration: 100 Loss: 0.67961 acc :0.924453\n",
      "Iteration: 120 Loss: 0.734141 acc :0.892644\n",
      "Iteration: 140 Loss: 0.702242 acc :0.922311\n",
      "Iteration: 160 Loss: 0.693734 acc :0.918327\n",
      "Iteration: 180 Loss: 0.69345 acc :0.918327\n",
      "validation Accuracy (197): 0.7587\n",
      "Iteration: 0 Loss: 0.687697 acc :0.920319\n",
      "Iteration: 20 Loss: 0.695079 acc :0.918327\n",
      "Iteration: 40 Loss: 0.693867 acc :0.918327\n",
      "Iteration: 60 Loss: 0.694291 acc :0.914343\n",
      "Iteration: 80 Loss: 0.696553 acc :0.908549\n",
      "Iteration: 100 Loss: 0.704538 acc :0.908549\n",
      "Iteration: 120 Loss: 0.728135 acc :0.916501\n",
      "Iteration: 140 Loss: 0.709444 acc :0.928287\n",
      "Iteration: 160 Loss: 0.702064 acc :0.928287\n",
      "Iteration: 180 Loss: 0.758142 acc :0.898407\n",
      "validation Accuracy (198): 0.7571\n",
      "Iteration: 0 Loss: 0.711757 acc :0.912351\n",
      "Iteration: 20 Loss: 0.701135 acc :0.926295\n",
      "Iteration: 40 Loss: 0.669535 acc :0.934263\n",
      "Iteration: 60 Loss: 0.701238 acc :0.930279\n",
      "Iteration: 80 Loss: 0.697016 acc :0.916501\n",
      "Iteration: 100 Loss: 0.701177 acc :0.916501\n",
      "Iteration: 120 Loss: 0.744853 acc :0.898608\n",
      "Iteration: 140 Loss: 0.663163 acc :0.926295\n",
      "Iteration: 160 Loss: 0.707302 acc :0.920319\n",
      "Iteration: 180 Loss: 0.721754 acc :0.900398\n",
      "validation Accuracy (199): 0.7601\n"
     ]
    }
   ],
   "source": [
    "Y_train = dense_to_one_hot(y_train, n_classes=10)\n",
    "Y_valid = dense_to_one_hot(y_valid, n_classes=10)\n",
    "Y_test = dense_to_one_hot(y_test, n_classes=10)\n",
    "\n",
    "# %% We'll now train in minibatches and report accuracy, loss:\n",
    "iter_per_epoch = 200\n",
    "n_epochs = 200\n",
    "train_size = 100000\n",
    "regular_lambda_=0.001\n",
    "\n",
    "indices = np.linspace(0, 100000 - 1, iter_per_epoch)\n",
    "indices = indices.astype('int')\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    for iter_i in range(iter_per_epoch - 1):\n",
    "        batch_xs = X_train[indices[iter_i]:indices[iter_i+1]]\n",
    "        batch_ys = Y_train[indices[iter_i]:indices[iter_i+1]]\n",
    "        \n",
    "        if iter_i % 20 == 0:\n",
    "            loss,accuracy_ = sess.run([cross_entropy,accuracy],\n",
    "                            feed_dict={\n",
    "                                x: batch_xs,\n",
    "                                y: batch_ys,\n",
    "                                regular_lambda: regular_lambda_,\n",
    "                                keep_prob:1\n",
    "                            })\n",
    "            print('Iteration: ' + str(iter_i) + ' Loss: ' + str(loss) +' acc :' +str(accuracy_))\n",
    "\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            x: batch_xs, y: batch_ys, learning_rate:0.001, keep_prob:0.6, regular_lambda:regular_lambda_})\n",
    "\n",
    "\n",
    "    print('validation Accuracy (%d): ' % epoch_i + str(sess.run(accuracy,\n",
    "                                                     feed_dict={\n",
    "                                                         x: X_valid,\n",
    "                                                         y: Y_valid,\n",
    "                                                         keep_prob:1\n",
    "                                                     })))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renew=tf.assign(global_step,100000)\n",
    "sess.run(renew)\n",
    "sess.run(global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b1d222ea-5f91-4473-8965-42cf9f1f8519"
    }
   },
   "source": [
    "# sec[1-2] CNN with stn acc :~0.94(  without stn :~ 0.9)\n",
    "## stn-conv-conv-fc-softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a stn network\n",
    "x,y,h_trans,regu_stn,h_fc_loc2,keep_prob,regular_lambda,learning_rate = create_stn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b0dd4ad3-7f0d-47ab-b864-fdff94e8dacb"
    }
   },
   "outputs": [],
   "source": [
    "# %% We'll setup the first convolutional layer\n",
    "# Weight matrix is [height x width x input_channels x output_channels]\n",
    "filter_size = 3\n",
    "n_filters_1 = 16\n",
    "W_conv1 = weight_variable([filter_size, filter_size, 1, n_filters_1])\n",
    "\n",
    "# %% Bias is [output_channels]\n",
    "b_conv1 = bias_variable([n_filters_1])\n",
    "\n",
    "# %% Now we can build a graph which does the first layer of convolution:\n",
    "# we define our stride as batch x height x width x channels\n",
    "# instead of pooling, we use strides of 2 and more layers\n",
    "# with smaller filters.\n",
    "\n",
    "h_conv1 = tf.nn.relu(\n",
    "    tf.nn.conv2d(input=h_trans,\n",
    "                 filter=W_conv1,\n",
    "                 strides=[1, 2, 2, 1],\n",
    "                 padding='SAME') +\n",
    "    b_conv1)\n",
    "h_conv1_drop = tf.nn.dropout(h_conv1, keep_prob)\n",
    "\n",
    "\n",
    "# %% And just like the first layer, add additional layers to create\n",
    "# a deep net\n",
    "n_filters_2 = 16\n",
    "W_conv2 = weight_variable([filter_size, filter_size, n_filters_1, n_filters_2])\n",
    "b_conv2 = bias_variable([n_filters_2])\n",
    "h_conv2 = tf.nn.relu(\n",
    "    tf.nn.conv2d(input=h_conv1_drop,\n",
    "                 filter=W_conv2,\n",
    "                 strides=[1, 2, 2, 1],\n",
    "                 padding='SAME') +\n",
    "    b_conv2)\n",
    "\n",
    "h_conv2_drop = tf.nn.dropout(h_conv2, keep_prob)\n",
    "\n",
    "# %% We'll now reshape so we can connect to a fully-connected layer:\n",
    "h_conv2_flat = tf.reshape(h_conv2_drop, [-1, 10 * 10 * n_filters_2])\n",
    "\n",
    "# %% Create a fully-connected layer:\n",
    "n_fc = 1024\n",
    "W_fc1 = weight_variable([10 * 10 * n_filters_2, n_fc])\n",
    "b_fc1 = bias_variable([n_fc])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# %% And finally our softmax layer:\n",
    "W_fc2 = weight_variable([n_fc, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "regu_cnn = tf.nn.l2_loss(W_fc1)+tf.nn.l2_loss(W_fc2)+tf.nn.l2_loss(b_fc1)+tf.nn.l2_loss(b_fc2)+\\\n",
    "       tf.nn.l2_loss(W_conv2)+tf.nn.l2_loss(W_conv1)+tf.nn.l2_loss(b_conv2)+tf.nn.l2_loss(b_conv1)\n",
    "    \n",
    "regu=regu_cnn+regu_stn\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate_decay = tf.train.exponential_decay(learning_rate, global_step,\n",
    "                                           4000, 0.96, staircase=True)\n",
    "\n",
    "# %% Define loss/eval/training functions\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=y_logits, labels=y))+regu*regular_lambda\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate_decay)\n",
    "optimizer = opt.minimize(cross_entropy,global_step = global_step)\n",
    "\n",
    "\n",
    "#optimizer = opt.minimize(cross_entropy)\n",
    "\n",
    "#grads = opt.compute_gradients(cross_entropy, [b_fc_loc2])\n",
    "\n",
    "# %% Monitor accuracy\n",
    "tf_predictions=tf.argmax(y_logits, 1)\n",
    "correct_prediction = tf.equal(tf.argmax(y_logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "# %% We now create a new session to actually perform the initialization the\n",
    "# variables:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x7f30056ac7d0>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "20c3fb41-08da-4c09-bc6d-4a789e2c5a32"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: 0.100205 acc :0.98\n",
      "Iteration: 20 Loss: 0.108432 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0768682 acc :1.0\n",
      "Iteration: 60 Loss: 0.105589 acc :0.984064\n",
      "Iteration: 80 Loss: 0.0915196 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0833392 acc :1.0\n",
      "Iteration: 120 Loss: 0.0855283 acc :0.996016\n",
      "Iteration: 140 Loss: 0.113262 acc :0.988\n",
      "Iteration: 160 Loss: 0.0800037 acc :0.992032\n",
      "Iteration: 180 Loss: 0.101958 acc :0.984\n",
      "Iteration: 200 Loss: 0.114219 acc :0.976096\n",
      "Iteration: 220 Loss: 0.101608 acc :0.984\n",
      "Iteration: 240 Loss: 0.104528 acc :0.988048\n",
      "Iteration: 260 Loss: 0.122816 acc :0.976\n",
      "Iteration: 280 Loss: 0.108273 acc :0.992032\n",
      "Iteration: 300 Loss: 0.103837 acc :0.988\n",
      "Iteration: 320 Loss: 0.0819521 acc :0.996016\n",
      "Iteration: 340 Loss: 0.153308 acc :0.972\n",
      "Iteration: 360 Loss: 0.0993057 acc :0.996016\n",
      "Iteration: 380 Loss: 0.113199 acc :0.984\n",
      "validation Accuracy (0): 0.9445\n",
      "Iteration: 0 Loss: 0.106791 acc :0.984\n",
      "Iteration: 20 Loss: 0.114087 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0808763 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0932342 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0957878 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0850077 acc :1.0\n",
      "Iteration: 120 Loss: 0.0823435 acc :1.0\n",
      "Iteration: 140 Loss: 0.116377 acc :0.98\n",
      "Iteration: 160 Loss: 0.083412 acc :0.996016\n",
      "Iteration: 180 Loss: 0.113557 acc :0.976\n",
      "Iteration: 200 Loss: 0.115767 acc :0.976096\n",
      "Iteration: 220 Loss: 0.0942369 acc :0.996\n",
      "Iteration: 240 Loss: 0.11049 acc :0.992032\n",
      "Iteration: 260 Loss: 0.124432 acc :0.976\n",
      "Iteration: 280 Loss: 0.0996564 acc :0.992032\n",
      "Iteration: 300 Loss: 0.109688 acc :0.984\n",
      "Iteration: 320 Loss: 0.0852164 acc :0.996016\n",
      "Iteration: 340 Loss: 0.1478 acc :0.972\n",
      "Iteration: 360 Loss: 0.100437 acc :0.992032\n",
      "Iteration: 380 Loss: 0.114142 acc :0.988\n",
      "validation Accuracy (1): 0.9464\n",
      "Iteration: 0 Loss: 0.107174 acc :0.984\n",
      "Iteration: 20 Loss: 0.11432 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0815474 acc :1.0\n",
      "Iteration: 60 Loss: 0.0939601 acc :0.996016\n",
      "Iteration: 80 Loss: 0.096743 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0875438 acc :0.996016\n",
      "Iteration: 120 Loss: 0.083136 acc :0.996016\n",
      "Iteration: 140 Loss: 0.126786 acc :0.968\n",
      "Iteration: 160 Loss: 0.0814566 acc :0.996016\n",
      "Iteration: 180 Loss: 0.102489 acc :0.984\n",
      "Iteration: 200 Loss: 0.126413 acc :0.976096\n",
      "Iteration: 220 Loss: 0.100686 acc :0.988\n",
      "Iteration: 240 Loss: 0.109383 acc :0.988048\n",
      "Iteration: 260 Loss: 0.126385 acc :0.972\n",
      "Iteration: 280 Loss: 0.107937 acc :0.984064\n",
      "Iteration: 300 Loss: 0.103769 acc :0.98\n",
      "Iteration: 320 Loss: 0.0822765 acc :0.992032\n",
      "Iteration: 340 Loss: 0.145432 acc :0.98\n",
      "Iteration: 360 Loss: 0.103018 acc :0.988048\n",
      "Iteration: 380 Loss: 0.111224 acc :0.984\n",
      "validation Accuracy (2): 0.9433\n",
      "Iteration: 0 Loss: 0.103273 acc :0.988\n",
      "Iteration: 20 Loss: 0.115482 acc :0.98008\n",
      "Iteration: 40 Loss: 0.076485 acc :1.0\n",
      "Iteration: 60 Loss: 0.0984544 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0927161 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0782894 acc :1.0\n",
      "Iteration: 120 Loss: 0.0809854 acc :1.0\n",
      "Iteration: 140 Loss: 0.121567 acc :0.98\n",
      "Iteration: 160 Loss: 0.0754503 acc :1.0\n",
      "Iteration: 180 Loss: 0.093882 acc :0.992\n",
      "Iteration: 200 Loss: 0.109345 acc :0.98008\n",
      "Iteration: 220 Loss: 0.0898708 acc :0.992\n",
      "Iteration: 240 Loss: 0.111022 acc :0.992032\n",
      "Iteration: 260 Loss: 0.123519 acc :0.976\n",
      "Iteration: 280 Loss: 0.108596 acc :0.988048\n",
      "Iteration: 300 Loss: 0.109628 acc :0.984\n",
      "Iteration: 320 Loss: 0.0832606 acc :0.996016\n",
      "Iteration: 340 Loss: 0.146187 acc :0.976\n",
      "Iteration: 360 Loss: 0.10178 acc :0.988048\n",
      "Iteration: 380 Loss: 0.104047 acc :0.988\n",
      "validation Accuracy (3): 0.9443\n",
      "Iteration: 0 Loss: 0.103303 acc :0.984\n",
      "Iteration: 20 Loss: 0.105774 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0764695 acc :0.996016\n",
      "Iteration: 60 Loss: 0.104011 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0991665 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0863383 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0949369 acc :0.988048\n",
      "Iteration: 140 Loss: 0.115057 acc :0.984\n",
      "Iteration: 160 Loss: 0.0747212 acc :1.0\n",
      "Iteration: 180 Loss: 0.094632 acc :0.992\n",
      "Iteration: 200 Loss: 0.11451 acc :0.98008\n",
      "Iteration: 220 Loss: 0.0974327 acc :0.988\n",
      "Iteration: 240 Loss: 0.112476 acc :0.98008\n",
      "Iteration: 260 Loss: 0.129384 acc :0.968\n",
      "Iteration: 280 Loss: 0.107444 acc :0.996016\n",
      "Iteration: 300 Loss: 0.101431 acc :0.984\n",
      "Iteration: 320 Loss: 0.0814355 acc :0.992032\n",
      "Iteration: 340 Loss: 0.147372 acc :0.976\n",
      "Iteration: 360 Loss: 0.0998606 acc :0.988048\n",
      "Iteration: 380 Loss: 0.11063 acc :0.984\n",
      "validation Accuracy (4): 0.9446\n",
      "Iteration: 0 Loss: 0.0979899 acc :0.984\n",
      "Iteration: 20 Loss: 0.112712 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0777101 acc :0.996016\n",
      "Iteration: 60 Loss: 0.092886 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0926193 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0849739 acc :1.0\n",
      "Iteration: 120 Loss: 0.0828692 acc :0.996016\n",
      "Iteration: 140 Loss: 0.122259 acc :0.972\n",
      "Iteration: 160 Loss: 0.0836697 acc :0.996016\n",
      "Iteration: 180 Loss: 0.106801 acc :0.988\n",
      "Iteration: 200 Loss: 0.113089 acc :0.976096\n",
      "Iteration: 220 Loss: 0.0969113 acc :0.992\n",
      "Iteration: 240 Loss: 0.112367 acc :0.988048\n",
      "Iteration: 260 Loss: 0.112801 acc :0.984\n",
      "Iteration: 280 Loss: 0.102307 acc :0.996016\n",
      "Iteration: 300 Loss: 0.100508 acc :0.988\n",
      "Iteration: 320 Loss: 0.0790151 acc :0.996016\n",
      "Iteration: 340 Loss: 0.133731 acc :0.972\n",
      "Iteration: 360 Loss: 0.0974337 acc :0.992032\n",
      "Iteration: 380 Loss: 0.111406 acc :0.984\n",
      "validation Accuracy (5): 0.9464\n",
      "Iteration: 0 Loss: 0.10139 acc :0.984\n",
      "Iteration: 20 Loss: 0.11536 acc :0.976096\n",
      "Iteration: 40 Loss: 0.0770298 acc :1.0\n",
      "Iteration: 60 Loss: 0.100254 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0975564 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0880363 acc :1.0\n",
      "Iteration: 120 Loss: 0.0787381 acc :0.996016\n",
      "Iteration: 140 Loss: 0.112233 acc :0.976\n",
      "Iteration: 160 Loss: 0.0868364 acc :0.992032\n",
      "Iteration: 180 Loss: 0.101844 acc :0.988\n",
      "Iteration: 200 Loss: 0.110184 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0926676 acc :0.988\n",
      "Iteration: 240 Loss: 0.111915 acc :0.984064\n",
      "Iteration: 260 Loss: 0.115216 acc :0.98\n",
      "Iteration: 280 Loss: 0.106656 acc :0.992032\n",
      "Iteration: 300 Loss: 0.100419 acc :0.984\n",
      "Iteration: 320 Loss: 0.0820474 acc :0.992032\n",
      "Iteration: 340 Loss: 0.138343 acc :0.976\n",
      "Iteration: 360 Loss: 0.0944234 acc :0.992032\n",
      "Iteration: 380 Loss: 0.0981761 acc :0.992\n",
      "validation Accuracy (6): 0.9456\n",
      "Iteration: 0 Loss: 0.0920154 acc :0.988\n",
      "Iteration: 20 Loss: 0.106681 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0765022 acc :1.0\n",
      "Iteration: 60 Loss: 0.108791 acc :0.984064\n",
      "Iteration: 80 Loss: 0.100793 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0866818 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0827986 acc :0.996016\n",
      "Iteration: 140 Loss: 0.105913 acc :0.984\n",
      "Iteration: 160 Loss: 0.0766507 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0963883 acc :0.988\n",
      "Iteration: 200 Loss: 0.110169 acc :0.984064\n",
      "Iteration: 220 Loss: 0.110722 acc :0.98\n",
      "Iteration: 240 Loss: 0.117379 acc :0.98008\n",
      "Iteration: 260 Loss: 0.116873 acc :0.984\n",
      "Iteration: 280 Loss: 0.0977284 acc :0.996016\n",
      "Iteration: 300 Loss: 0.101298 acc :0.988\n",
      "Iteration: 320 Loss: 0.0838807 acc :0.992032\n",
      "Iteration: 340 Loss: 0.136243 acc :0.976\n",
      "Iteration: 360 Loss: 0.0928317 acc :0.992032\n",
      "Iteration: 380 Loss: 0.109288 acc :0.988\n",
      "validation Accuracy (7): 0.9463\n",
      "Iteration: 0 Loss: 0.0900998 acc :0.992\n",
      "Iteration: 20 Loss: 0.105714 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0772513 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0963661 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0986886 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0801379 acc :1.0\n",
      "Iteration: 120 Loss: 0.0944398 acc :0.996016\n",
      "Iteration: 140 Loss: 0.118443 acc :0.988\n",
      "Iteration: 160 Loss: 0.0751296 acc :1.0\n",
      "Iteration: 180 Loss: 0.105236 acc :0.98\n",
      "Iteration: 200 Loss: 0.11165 acc :0.98008\n",
      "Iteration: 220 Loss: 0.0984076 acc :0.988\n",
      "Iteration: 240 Loss: 0.108505 acc :0.984064\n",
      "Iteration: 260 Loss: 0.11874 acc :0.98\n",
      "Iteration: 280 Loss: 0.10328 acc :0.988048\n",
      "Iteration: 300 Loss: 0.100823 acc :0.984\n",
      "Iteration: 320 Loss: 0.0862814 acc :0.996016\n",
      "Iteration: 340 Loss: 0.14599 acc :0.976\n",
      "Iteration: 360 Loss: 0.103855 acc :0.988048\n",
      "Iteration: 380 Loss: 0.108493 acc :0.992\n",
      "validation Accuracy (8): 0.9467\n",
      "Iteration: 0 Loss: 0.10438 acc :0.988\n",
      "Iteration: 20 Loss: 0.102494 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0784297 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0927694 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0949795 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0813501 acc :1.0\n",
      "Iteration: 120 Loss: 0.0798026 acc :0.996016\n",
      "Iteration: 140 Loss: 0.104945 acc :0.988\n",
      "Iteration: 160 Loss: 0.0818379 acc :0.996016\n",
      "Iteration: 180 Loss: 0.106161 acc :0.976\n",
      "Iteration: 200 Loss: 0.114058 acc :0.98008\n",
      "Iteration: 220 Loss: 0.0989601 acc :0.988\n",
      "Iteration: 240 Loss: 0.104271 acc :0.988048\n",
      "Iteration: 260 Loss: 0.118618 acc :0.976\n",
      "Iteration: 280 Loss: 0.0961396 acc :0.988048\n",
      "Iteration: 300 Loss: 0.100206 acc :0.984\n",
      "Iteration: 320 Loss: 0.0861452 acc :0.992032\n",
      "Iteration: 340 Loss: 0.140829 acc :0.98\n",
      "Iteration: 360 Loss: 0.105203 acc :0.984064\n",
      "Iteration: 380 Loss: 0.109352 acc :0.984\n",
      "validation Accuracy (9): 0.9462\n",
      "Iteration: 0 Loss: 0.0920732 acc :0.992\n",
      "Iteration: 20 Loss: 0.107945 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0735504 acc :1.0\n",
      "Iteration: 60 Loss: 0.0869107 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0907502 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0785271 acc :1.0\n",
      "Iteration: 120 Loss: 0.0794887 acc :1.0\n",
      "Iteration: 140 Loss: 0.107493 acc :0.988\n",
      "Iteration: 160 Loss: 0.076329 acc :1.0\n",
      "Iteration: 180 Loss: 0.100771 acc :0.984\n",
      "Iteration: 200 Loss: 0.112228 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0981853 acc :0.988\n",
      "Iteration: 240 Loss: 0.113101 acc :0.98008\n",
      "Iteration: 260 Loss: 0.109826 acc :0.98\n",
      "Iteration: 280 Loss: 0.0961135 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0982884 acc :0.988\n",
      "Iteration: 320 Loss: 0.0801943 acc :0.992032\n",
      "Iteration: 340 Loss: 0.151245 acc :0.972\n",
      "Iteration: 360 Loss: 0.0953718 acc :0.996016\n",
      "Iteration: 380 Loss: 0.103473 acc :0.992\n",
      "validation Accuracy (10): 0.9422\n",
      "Iteration: 0 Loss: 0.102364 acc :0.988\n",
      "Iteration: 20 Loss: 0.107284 acc :0.984064\n",
      "Iteration: 40 Loss: 0.077896 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0878035 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0950236 acc :0.988048\n",
      "Iteration: 100 Loss: 0.0842585 acc :1.0\n",
      "Iteration: 120 Loss: 0.0858813 acc :0.996016\n",
      "Iteration: 140 Loss: 0.104081 acc :0.992\n",
      "Iteration: 160 Loss: 0.0776366 acc :0.996016\n",
      "Iteration: 180 Loss: 0.100479 acc :0.984\n",
      "Iteration: 200 Loss: 0.114497 acc :0.976096\n",
      "Iteration: 220 Loss: 0.0999022 acc :0.988\n",
      "Iteration: 240 Loss: 0.114324 acc :0.988048\n",
      "Iteration: 260 Loss: 0.118975 acc :0.98\n",
      "Iteration: 280 Loss: 0.1012 acc :0.996016\n",
      "Iteration: 300 Loss: 0.103528 acc :0.984\n",
      "Iteration: 320 Loss: 0.0843703 acc :0.992032\n",
      "Iteration: 340 Loss: 0.154749 acc :0.972\n",
      "Iteration: 360 Loss: 0.0991535 acc :0.996016\n",
      "Iteration: 380 Loss: 0.106235 acc :0.988\n",
      "validation Accuracy (11): 0.9448\n",
      "Iteration: 0 Loss: 0.0958807 acc :0.996\n",
      "Iteration: 20 Loss: 0.102351 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0795263 acc :0.996016\n",
      "Iteration: 60 Loss: 0.093056 acc :0.988048\n",
      "Iteration: 80 Loss: 0.101591 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0832658 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0869733 acc :0.992032\n",
      "Iteration: 140 Loss: 0.10668 acc :0.98\n",
      "Iteration: 160 Loss: 0.0793274 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0993142 acc :0.98\n",
      "Iteration: 200 Loss: 0.116423 acc :0.98008\n",
      "Iteration: 220 Loss: 0.103749 acc :0.984\n",
      "Iteration: 240 Loss: 0.0966407 acc :0.992032\n",
      "Iteration: 260 Loss: 0.12326 acc :0.976\n",
      "Iteration: 280 Loss: 0.0942209 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0978072 acc :0.992\n",
      "Iteration: 320 Loss: 0.0786571 acc :1.0\n",
      "Iteration: 340 Loss: 0.138529 acc :0.984\n",
      "Iteration: 360 Loss: 0.0955968 acc :0.988048\n",
      "Iteration: 380 Loss: 0.0949626 acc :0.992\n",
      "validation Accuracy (12): 0.9416\n",
      "Iteration: 0 Loss: 0.0972057 acc :0.992\n",
      "Iteration: 20 Loss: 0.113721 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0755879 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0983436 acc :0.988048\n",
      "Iteration: 80 Loss: 0.093178 acc :0.992032\n",
      "Iteration: 100 Loss: 0.087514 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0783544 acc :1.0\n",
      "Iteration: 140 Loss: 0.106933 acc :0.988\n",
      "Iteration: 160 Loss: 0.0786794 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0964343 acc :0.984\n",
      "Iteration: 200 Loss: 0.109976 acc :0.976096\n",
      "Iteration: 220 Loss: 0.0956773 acc :0.988\n",
      "Iteration: 240 Loss: 0.107978 acc :0.984064\n",
      "Iteration: 260 Loss: 0.124059 acc :0.984\n",
      "Iteration: 280 Loss: 0.0930554 acc :0.992032\n",
      "Iteration: 300 Loss: 0.101103 acc :0.992\n",
      "Iteration: 320 Loss: 0.0823388 acc :0.988048\n",
      "Iteration: 340 Loss: 0.137283 acc :0.98\n",
      "Iteration: 360 Loss: 0.100359 acc :0.984064\n",
      "Iteration: 380 Loss: 0.102289 acc :0.992\n",
      "validation Accuracy (13): 0.9462\n",
      "Iteration: 0 Loss: 0.0987521 acc :0.984\n",
      "Iteration: 20 Loss: 0.105096 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0762036 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0908399 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0995782 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0820081 acc :1.0\n",
      "Iteration: 120 Loss: 0.0864519 acc :0.996016\n",
      "Iteration: 140 Loss: 0.116061 acc :0.984\n",
      "Iteration: 160 Loss: 0.076937 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0949249 acc :0.996\n",
      "Iteration: 200 Loss: 0.105879 acc :0.98008\n",
      "Iteration: 220 Loss: 0.0950763 acc :0.988\n",
      "Iteration: 240 Loss: 0.113846 acc :0.996016\n",
      "Iteration: 260 Loss: 0.129151 acc :0.96\n",
      "Iteration: 280 Loss: 0.0969245 acc :0.992032\n",
      "Iteration: 300 Loss: 0.103257 acc :0.984\n",
      "Iteration: 320 Loss: 0.0826916 acc :0.996016\n",
      "Iteration: 340 Loss: 0.138814 acc :0.976\n",
      "Iteration: 360 Loss: 0.104814 acc :0.992032\n",
      "Iteration: 380 Loss: 0.107228 acc :0.992\n",
      "validation Accuracy (14): 0.9434\n",
      "Iteration: 0 Loss: 0.0970098 acc :0.98\n",
      "Iteration: 20 Loss: 0.108192 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0805563 acc :0.996016\n",
      "Iteration: 60 Loss: 0.102151 acc :0.984064\n",
      "Iteration: 80 Loss: 0.0985724 acc :0.988048\n",
      "Iteration: 100 Loss: 0.0811956 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0839754 acc :0.996016\n",
      "Iteration: 140 Loss: 0.112039 acc :0.992\n",
      "Iteration: 160 Loss: 0.0796112 acc :0.996016\n",
      "Iteration: 180 Loss: 0.103076 acc :0.98\n",
      "Iteration: 200 Loss: 0.101855 acc :0.992032\n",
      "Iteration: 220 Loss: 0.0923353 acc :0.992\n",
      "Iteration: 240 Loss: 0.100575 acc :0.992032\n",
      "Iteration: 260 Loss: 0.117651 acc :0.98\n",
      "Iteration: 280 Loss: 0.0920021 acc :0.996016\n",
      "Iteration: 300 Loss: 0.102699 acc :0.98\n",
      "Iteration: 320 Loss: 0.081352 acc :1.0\n",
      "Iteration: 340 Loss: 0.138005 acc :0.976\n",
      "Iteration: 360 Loss: 0.104132 acc :0.992032\n",
      "Iteration: 380 Loss: 0.100181 acc :0.992\n",
      "validation Accuracy (15): 0.9454\n",
      "Iteration: 0 Loss: 0.090848 acc :0.996\n",
      "Iteration: 20 Loss: 0.107141 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0776147 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0876371 acc :0.996016\n",
      "Iteration: 80 Loss: 0.093837 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0825856 acc :1.0\n",
      "Iteration: 120 Loss: 0.074186 acc :1.0\n",
      "Iteration: 140 Loss: 0.11723 acc :0.984\n",
      "Iteration: 160 Loss: 0.0810512 acc :0.996016\n",
      "Iteration: 180 Loss: 0.102949 acc :0.992\n",
      "Iteration: 200 Loss: 0.115707 acc :0.976096\n",
      "Iteration: 220 Loss: 0.0875627 acc :0.988\n",
      "Iteration: 240 Loss: 0.105795 acc :0.98008\n",
      "Iteration: 260 Loss: 0.116461 acc :0.984\n",
      "Iteration: 280 Loss: 0.0937842 acc :1.0\n",
      "Iteration: 300 Loss: 0.0968851 acc :0.988\n",
      "Iteration: 320 Loss: 0.0849442 acc :0.996016\n",
      "Iteration: 340 Loss: 0.140206 acc :0.976\n",
      "Iteration: 360 Loss: 0.0920224 acc :0.992032\n",
      "Iteration: 380 Loss: 0.104673 acc :0.988\n",
      "validation Accuracy (16): 0.9438\n",
      "Iteration: 0 Loss: 0.085647 acc :1.0\n",
      "Iteration: 20 Loss: 0.108801 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0846729 acc :0.992032\n",
      "Iteration: 60 Loss: 0.0928093 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0924651 acc :0.988048\n",
      "Iteration: 100 Loss: 0.0863549 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0843672 acc :0.996016\n",
      "Iteration: 140 Loss: 0.109523 acc :0.984\n",
      "Iteration: 160 Loss: 0.0785657 acc :0.992032\n",
      "Iteration: 180 Loss: 0.0979455 acc :0.988\n",
      "Iteration: 200 Loss: 0.112149 acc :0.98008\n",
      "Iteration: 220 Loss: 0.08801 acc :0.992\n",
      "Iteration: 240 Loss: 0.10597 acc :0.984064\n",
      "Iteration: 260 Loss: 0.121848 acc :0.984\n",
      "Iteration: 280 Loss: 0.0954743 acc :1.0\n",
      "Iteration: 300 Loss: 0.0976705 acc :0.98\n",
      "Iteration: 320 Loss: 0.0855188 acc :0.996016\n",
      "Iteration: 340 Loss: 0.138951 acc :0.976\n",
      "Iteration: 360 Loss: 0.0928106 acc :0.996016\n",
      "Iteration: 380 Loss: 0.10422 acc :0.988\n",
      "validation Accuracy (17): 0.9437\n",
      "Iteration: 0 Loss: 0.0931046 acc :0.992\n",
      "Iteration: 20 Loss: 0.0980762 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0776767 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0900351 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0916431 acc :0.988048\n",
      "Iteration: 100 Loss: 0.0812898 acc :1.0\n",
      "Iteration: 120 Loss: 0.0851514 acc :0.988048\n",
      "Iteration: 140 Loss: 0.105852 acc :0.992\n",
      "Iteration: 160 Loss: 0.0801293 acc :0.992032\n",
      "Iteration: 180 Loss: 0.0922302 acc :0.988\n",
      "Iteration: 200 Loss: 0.115672 acc :0.98008\n",
      "Iteration: 220 Loss: 0.0951849 acc :0.992\n",
      "Iteration: 240 Loss: 0.103447 acc :0.988048\n",
      "Iteration: 260 Loss: 0.117515 acc :0.984\n",
      "Iteration: 280 Loss: 0.0956581 acc :1.0\n",
      "Iteration: 300 Loss: 0.0987727 acc :0.98\n",
      "Iteration: 320 Loss: 0.0812017 acc :0.996016\n",
      "Iteration: 340 Loss: 0.13393 acc :0.98\n",
      "Iteration: 360 Loss: 0.093426 acc :0.992032\n",
      "Iteration: 380 Loss: 0.108257 acc :0.988\n",
      "validation Accuracy (18): 0.9428\n",
      "Iteration: 0 Loss: 0.0920249 acc :0.992\n",
      "Iteration: 20 Loss: 0.101625 acc :0.988048\n",
      "Iteration: 40 Loss: 0.082792 acc :0.992032\n",
      "Iteration: 60 Loss: 0.0980985 acc :0.972112\n",
      "Iteration: 80 Loss: 0.0953033 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0848352 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0843378 acc :0.996016\n",
      "Iteration: 140 Loss: 0.104545 acc :0.992\n",
      "Iteration: 160 Loss: 0.0807928 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0848877 acc :1.0\n",
      "Iteration: 200 Loss: 0.13212 acc :0.976096\n",
      "Iteration: 220 Loss: 0.0899704 acc :0.988\n",
      "Iteration: 240 Loss: 0.106445 acc :0.988048\n",
      "Iteration: 260 Loss: 0.122178 acc :0.976\n",
      "Iteration: 280 Loss: 0.095332 acc :1.0\n",
      "Iteration: 300 Loss: 0.0998489 acc :0.988\n",
      "Iteration: 320 Loss: 0.0804481 acc :1.0\n",
      "Iteration: 340 Loss: 0.126326 acc :0.976\n",
      "Iteration: 360 Loss: 0.0929949 acc :0.992032\n",
      "Iteration: 380 Loss: 0.0999696 acc :0.996\n",
      "validation Accuracy (19): 0.9451\n",
      "Iteration: 0 Loss: 0.0915163 acc :0.996\n",
      "Iteration: 20 Loss: 0.092951 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0760759 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0937483 acc :0.984064\n",
      "Iteration: 80 Loss: 0.0970984 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0801445 acc :1.0\n",
      "Iteration: 120 Loss: 0.0803762 acc :0.996016\n",
      "Iteration: 140 Loss: 0.103896 acc :0.988\n",
      "Iteration: 160 Loss: 0.0767625 acc :0.992032\n",
      "Iteration: 180 Loss: 0.0949207 acc :0.992\n",
      "Iteration: 200 Loss: 0.103232 acc :0.976096\n",
      "Iteration: 220 Loss: 0.0887962 acc :0.992\n",
      "Iteration: 240 Loss: 0.101841 acc :0.988048\n",
      "Iteration: 260 Loss: 0.125229 acc :0.976\n",
      "Iteration: 280 Loss: 0.0933905 acc :0.996016\n",
      "Iteration: 300 Loss: 0.097259 acc :0.98\n",
      "Iteration: 320 Loss: 0.0806839 acc :1.0\n",
      "Iteration: 340 Loss: 0.139164 acc :0.98\n",
      "Iteration: 360 Loss: 0.0960188 acc :0.992032\n",
      "Iteration: 380 Loss: 0.108975 acc :0.984\n",
      "validation Accuracy (20): 0.9434\n",
      "Iteration: 0 Loss: 0.0841206 acc :1.0\n",
      "Iteration: 20 Loss: 0.100685 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0787775 acc :0.992032\n",
      "Iteration: 60 Loss: 0.0914899 acc :0.996016\n",
      "Iteration: 80 Loss: 0.096939 acc :0.988048\n",
      "Iteration: 100 Loss: 0.0721532 acc :1.0\n",
      "Iteration: 120 Loss: 0.0758129 acc :0.996016\n",
      "Iteration: 140 Loss: 0.101824 acc :0.988\n",
      "Iteration: 160 Loss: 0.0747472 acc :0.996016\n",
      "Iteration: 180 Loss: 0.100341 acc :0.988\n",
      "Iteration: 200 Loss: 0.105034 acc :0.988048\n",
      "Iteration: 220 Loss: 0.0910023 acc :0.992\n",
      "Iteration: 240 Loss: 0.100799 acc :0.988048\n",
      "Iteration: 260 Loss: 0.120586 acc :0.976\n",
      "Iteration: 280 Loss: 0.0994818 acc :0.992032\n",
      "Iteration: 300 Loss: 0.0972729 acc :0.988\n",
      "Iteration: 320 Loss: 0.0834319 acc :0.996016\n",
      "Iteration: 340 Loss: 0.145994 acc :0.968\n",
      "Iteration: 360 Loss: 0.0925542 acc :0.996016\n",
      "Iteration: 380 Loss: 0.104724 acc :0.988\n",
      "validation Accuracy (21): 0.947\n",
      "Iteration: 0 Loss: 0.0887612 acc :0.996\n",
      "Iteration: 20 Loss: 0.0985668 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0726473 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0885486 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0992924 acc :0.984064\n",
      "Iteration: 100 Loss: 0.0743919 acc :1.0\n",
      "Iteration: 120 Loss: 0.0744339 acc :1.0\n",
      "Iteration: 140 Loss: 0.0936537 acc :0.992\n",
      "Iteration: 160 Loss: 0.0749973 acc :0.996016\n",
      "Iteration: 180 Loss: 0.103312 acc :0.98\n",
      "Iteration: 200 Loss: 0.103851 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0933535 acc :0.988\n",
      "Iteration: 240 Loss: 0.0980751 acc :0.988048\n",
      "Iteration: 260 Loss: 0.108747 acc :0.98\n",
      "Iteration: 280 Loss: 0.0952566 acc :0.992032\n",
      "Iteration: 300 Loss: 0.0966092 acc :0.984\n",
      "Iteration: 320 Loss: 0.0823172 acc :0.992032\n",
      "Iteration: 340 Loss: 0.129908 acc :0.98\n",
      "Iteration: 360 Loss: 0.100031 acc :0.988048\n",
      "Iteration: 380 Loss: 0.10237 acc :0.992\n",
      "validation Accuracy (22): 0.9452\n",
      "Iteration: 0 Loss: 0.0903829 acc :0.992\n",
      "Iteration: 20 Loss: 0.0991559 acc :0.988048\n",
      "Iteration: 40 Loss: 0.071667 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0996253 acc :0.984064\n",
      "Iteration: 80 Loss: 0.0919223 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0769728 acc :1.0\n",
      "Iteration: 120 Loss: 0.0761369 acc :1.0\n",
      "Iteration: 140 Loss: 0.0964048 acc :0.992\n",
      "Iteration: 160 Loss: 0.0759435 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0954237 acc :0.992\n",
      "Iteration: 200 Loss: 0.103942 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0877399 acc :0.988\n",
      "Iteration: 240 Loss: 0.100537 acc :0.988048\n",
      "Iteration: 260 Loss: 0.1076 acc :0.984\n",
      "Iteration: 280 Loss: 0.0964472 acc :0.992032\n",
      "Iteration: 300 Loss: 0.0933855 acc :0.988\n",
      "Iteration: 320 Loss: 0.0804702 acc :0.996016\n",
      "Iteration: 340 Loss: 0.127581 acc :0.98\n",
      "Iteration: 360 Loss: 0.0930144 acc :0.996016\n",
      "Iteration: 380 Loss: 0.104689 acc :0.992\n",
      "validation Accuracy (23): 0.9445\n",
      "Iteration: 0 Loss: 0.0979074 acc :0.988\n",
      "Iteration: 20 Loss: 0.0959727 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0800879 acc :0.992032\n",
      "Iteration: 60 Loss: 0.0911373 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0960161 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0793939 acc :1.0\n",
      "Iteration: 120 Loss: 0.0785393 acc :0.996016\n",
      "Iteration: 140 Loss: 0.10008 acc :0.988\n",
      "Iteration: 160 Loss: 0.0724039 acc :0.996016\n",
      "Iteration: 180 Loss: 0.103523 acc :0.98\n",
      "Iteration: 200 Loss: 0.104832 acc :0.992032\n",
      "Iteration: 220 Loss: 0.0862816 acc :0.988\n",
      "Iteration: 240 Loss: 0.0978982 acc :0.988048\n",
      "Iteration: 260 Loss: 0.109995 acc :0.984\n",
      "Iteration: 280 Loss: 0.0832716 acc :1.0\n",
      "Iteration: 300 Loss: 0.0858463 acc :0.992\n",
      "Iteration: 320 Loss: 0.075444 acc :0.996016\n",
      "Iteration: 340 Loss: 0.131144 acc :0.976\n",
      "Iteration: 360 Loss: 0.0904457 acc :0.996016\n",
      "Iteration: 380 Loss: 0.110336 acc :0.988\n",
      "validation Accuracy (24): 0.9438\n",
      "Iteration: 0 Loss: 0.0892051 acc :0.992\n",
      "Iteration: 20 Loss: 0.0904431 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0731747 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0859709 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0873146 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0763529 acc :1.0\n",
      "Iteration: 120 Loss: 0.0764401 acc :0.996016\n",
      "Iteration: 140 Loss: 0.107306 acc :0.984\n",
      "Iteration: 160 Loss: 0.075625 acc :1.0\n",
      "Iteration: 180 Loss: 0.097393 acc :0.992\n",
      "Iteration: 200 Loss: 0.104957 acc :0.98008\n",
      "Iteration: 220 Loss: 0.0906665 acc :0.988\n",
      "Iteration: 240 Loss: 0.104608 acc :0.988048\n",
      "Iteration: 260 Loss: 0.116109 acc :0.976\n",
      "Iteration: 280 Loss: 0.0903935 acc :1.0\n",
      "Iteration: 300 Loss: 0.0973786 acc :0.984\n",
      "Iteration: 320 Loss: 0.0797988 acc :0.992032\n",
      "Iteration: 340 Loss: 0.128495 acc :0.98\n",
      "Iteration: 360 Loss: 0.0905902 acc :0.992032\n",
      "Iteration: 380 Loss: 0.107132 acc :0.988\n",
      "validation Accuracy (25): 0.9445\n",
      "Iteration: 0 Loss: 0.0964866 acc :0.988\n",
      "Iteration: 20 Loss: 0.0967781 acc :0.992032\n",
      "Iteration: 40 Loss: 0.070935 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0853773 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0862007 acc :1.0\n",
      "Iteration: 100 Loss: 0.0809127 acc :1.0\n",
      "Iteration: 120 Loss: 0.0815419 acc :0.996016\n",
      "Iteration: 140 Loss: 0.0982267 acc :0.984\n",
      "Iteration: 160 Loss: 0.0757284 acc :1.0\n",
      "Iteration: 180 Loss: 0.0976711 acc :0.992\n",
      "Iteration: 200 Loss: 0.107262 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0913017 acc :0.988\n",
      "Iteration: 240 Loss: 0.105471 acc :0.992032\n",
      "Iteration: 260 Loss: 0.111043 acc :0.984\n",
      "Iteration: 280 Loss: 0.0916956 acc :1.0\n",
      "Iteration: 300 Loss: 0.100346 acc :0.988\n",
      "Iteration: 320 Loss: 0.0859101 acc :0.992032\n",
      "Iteration: 340 Loss: 0.131491 acc :0.984\n",
      "Iteration: 360 Loss: 0.0975002 acc :0.988048\n",
      "Iteration: 380 Loss: 0.110521 acc :0.98\n",
      "validation Accuracy (26): 0.9443\n",
      "Iteration: 0 Loss: 0.0911972 acc :0.992\n",
      "Iteration: 20 Loss: 0.100812 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0744808 acc :0.992032\n",
      "Iteration: 60 Loss: 0.0816127 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0880584 acc :0.992032\n",
      "Iteration: 100 Loss: 0.081485 acc :1.0\n",
      "Iteration: 120 Loss: 0.0795041 acc :0.992032\n",
      "Iteration: 140 Loss: 0.095544 acc :0.984\n",
      "Iteration: 160 Loss: 0.0749313 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0994857 acc :0.984\n",
      "Iteration: 200 Loss: 0.103819 acc :0.988048\n",
      "Iteration: 220 Loss: 0.0925525 acc :0.992\n",
      "Iteration: 240 Loss: 0.101929 acc :0.996016\n",
      "Iteration: 260 Loss: 0.115812 acc :0.972\n",
      "Iteration: 280 Loss: 0.0861567 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0960835 acc :0.984\n",
      "Iteration: 320 Loss: 0.0791675 acc :0.996016\n",
      "Iteration: 340 Loss: 0.135061 acc :0.984\n",
      "Iteration: 360 Loss: 0.0904695 acc :0.988048\n",
      "Iteration: 380 Loss: 0.111751 acc :0.984\n",
      "validation Accuracy (27): 0.9478\n",
      "Iteration: 0 Loss: 0.0852512 acc :1.0\n",
      "Iteration: 20 Loss: 0.0945305 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0707769 acc :0.996016\n",
      "Iteration: 60 Loss: 0.082077 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0923379 acc :0.988048\n",
      "Iteration: 100 Loss: 0.0742223 acc :1.0\n",
      "Iteration: 120 Loss: 0.0811254 acc :0.996016\n",
      "Iteration: 140 Loss: 0.102943 acc :0.984\n",
      "Iteration: 160 Loss: 0.0772941 acc :0.996016\n",
      "Iteration: 180 Loss: 0.102482 acc :0.98\n",
      "Iteration: 200 Loss: 0.107296 acc :0.988048\n",
      "Iteration: 220 Loss: 0.085714 acc :0.988\n",
      "Iteration: 240 Loss: 0.100395 acc :0.992032\n",
      "Iteration: 260 Loss: 0.121075 acc :0.968\n",
      "Iteration: 280 Loss: 0.0921582 acc :0.996016\n",
      "Iteration: 300 Loss: 0.109232 acc :0.984\n",
      "Iteration: 320 Loss: 0.0830448 acc :0.992032\n",
      "Iteration: 340 Loss: 0.137559 acc :0.976\n",
      "Iteration: 360 Loss: 0.0943962 acc :0.992032\n",
      "Iteration: 380 Loss: 0.111235 acc :0.988\n",
      "validation Accuracy (28): 0.9451\n",
      "Iteration: 0 Loss: 0.0909272 acc :0.996\n",
      "Iteration: 20 Loss: 0.0942937 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0717042 acc :1.0\n",
      "Iteration: 60 Loss: 0.0826297 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0936917 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0821278 acc :0.996016\n",
      "Iteration: 120 Loss: 0.082649 acc :0.996016\n",
      "Iteration: 140 Loss: 0.100954 acc :0.988\n",
      "Iteration: 160 Loss: 0.0727628 acc :1.0\n",
      "Iteration: 180 Loss: 0.0983034 acc :0.984\n",
      "Iteration: 200 Loss: 0.102513 acc :0.988048\n",
      "Iteration: 220 Loss: 0.084108 acc :0.992\n",
      "Iteration: 240 Loss: 0.101934 acc :0.984064\n",
      "Iteration: 260 Loss: 0.116432 acc :0.976\n",
      "Iteration: 280 Loss: 0.09057 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0997935 acc :0.984\n",
      "Iteration: 320 Loss: 0.0857282 acc :0.992032\n",
      "Iteration: 340 Loss: 0.135051 acc :0.972\n",
      "Iteration: 360 Loss: 0.0914899 acc :1.0\n",
      "Iteration: 380 Loss: 0.111234 acc :0.988\n",
      "validation Accuracy (29): 0.9461\n",
      "Iteration: 0 Loss: 0.0895613 acc :0.992\n",
      "Iteration: 20 Loss: 0.0972236 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0740257 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0780013 acc :1.0\n",
      "Iteration: 80 Loss: 0.0824833 acc :1.0\n",
      "Iteration: 100 Loss: 0.0788691 acc :1.0\n",
      "Iteration: 120 Loss: 0.0811643 acc :1.0\n",
      "Iteration: 140 Loss: 0.105663 acc :0.988\n",
      "Iteration: 160 Loss: 0.0747831 acc :0.996016\n",
      "Iteration: 180 Loss: 0.100848 acc :0.984\n",
      "Iteration: 200 Loss: 0.107101 acc :0.988048\n",
      "Iteration: 220 Loss: 0.0923225 acc :0.984\n",
      "Iteration: 240 Loss: 0.100364 acc :0.984064\n",
      "Iteration: 260 Loss: 0.111097 acc :0.976\n",
      "Iteration: 280 Loss: 0.082738 acc :1.0\n",
      "Iteration: 300 Loss: 0.110411 acc :0.984\n",
      "Iteration: 320 Loss: 0.0772294 acc :0.996016\n",
      "Iteration: 340 Loss: 0.134082 acc :0.98\n",
      "Iteration: 360 Loss: 0.0920129 acc :0.992032\n",
      "Iteration: 380 Loss: 0.114468 acc :0.984\n",
      "validation Accuracy (30): 0.9449\n",
      "Iteration: 0 Loss: 0.0899037 acc :0.996\n",
      "Iteration: 20 Loss: 0.0989446 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0727809 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0841837 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0882455 acc :1.0\n",
      "Iteration: 100 Loss: 0.0809502 acc :1.0\n",
      "Iteration: 120 Loss: 0.0811662 acc :1.0\n",
      "Iteration: 140 Loss: 0.106324 acc :0.98\n",
      "Iteration: 160 Loss: 0.0745013 acc :1.0\n",
      "Iteration: 180 Loss: 0.0920801 acc :0.992\n",
      "Iteration: 200 Loss: 0.0929016 acc :0.988048\n",
      "Iteration: 220 Loss: 0.0929455 acc :0.988\n",
      "Iteration: 240 Loss: 0.100013 acc :0.988048\n",
      "Iteration: 260 Loss: 0.101151 acc :0.992\n",
      "Iteration: 280 Loss: 0.091677 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0973322 acc :0.988\n",
      "Iteration: 320 Loss: 0.0762083 acc :1.0\n",
      "Iteration: 340 Loss: 0.135789 acc :0.972\n",
      "Iteration: 360 Loss: 0.0877254 acc :0.996016\n",
      "Iteration: 380 Loss: 0.107738 acc :0.988\n",
      "validation Accuracy (31): 0.9457\n",
      "Iteration: 0 Loss: 0.0956303 acc :0.992\n",
      "Iteration: 20 Loss: 0.0949912 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0751864 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0853186 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0932231 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0829225 acc :0.996016\n",
      "Iteration: 120 Loss: 0.078977 acc :0.996016\n",
      "Iteration: 140 Loss: 0.099932 acc :0.988\n",
      "Iteration: 160 Loss: 0.0752641 acc :1.0\n",
      "Iteration: 180 Loss: 0.0916431 acc :0.988\n",
      "Iteration: 200 Loss: 0.10266 acc :0.992032\n",
      "Iteration: 220 Loss: 0.0892284 acc :0.988\n",
      "Iteration: 240 Loss: 0.0990661 acc :0.988048\n",
      "Iteration: 260 Loss: 0.101835 acc :0.984\n",
      "Iteration: 280 Loss: 0.0877132 acc :0.996016\n",
      "Iteration: 300 Loss: 0.098442 acc :0.98\n",
      "Iteration: 320 Loss: 0.0801969 acc :1.0\n",
      "Iteration: 340 Loss: 0.135465 acc :0.98\n",
      "Iteration: 360 Loss: 0.0908982 acc :0.996016\n",
      "Iteration: 380 Loss: 0.0986972 acc :0.984\n",
      "validation Accuracy (32): 0.9433\n",
      "Iteration: 0 Loss: 0.0875804 acc :0.992\n",
      "Iteration: 20 Loss: 0.0951103 acc :0.992032\n",
      "Iteration: 40 Loss: 0.073115 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0793074 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0811914 acc :1.0\n",
      "Iteration: 100 Loss: 0.0854331 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0797012 acc :1.0\n",
      "Iteration: 140 Loss: 0.105359 acc :0.984\n",
      "Iteration: 160 Loss: 0.0717454 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0995432 acc :0.988\n",
      "Iteration: 200 Loss: 0.10306 acc :0.984064\n",
      "Iteration: 220 Loss: 0.087252 acc :0.988\n",
      "Iteration: 240 Loss: 0.104881 acc :0.988048\n",
      "Iteration: 260 Loss: 0.0995818 acc :0.992\n",
      "Iteration: 280 Loss: 0.0881 acc :0.996016\n",
      "Iteration: 300 Loss: 0.102159 acc :0.988\n",
      "Iteration: 320 Loss: 0.0773717 acc :0.996016\n",
      "Iteration: 340 Loss: 0.144707 acc :0.976\n",
      "Iteration: 360 Loss: 0.0886328 acc :0.996016\n",
      "Iteration: 380 Loss: 0.101591 acc :0.988\n",
      "validation Accuracy (33): 0.9475\n",
      "Iteration: 0 Loss: 0.088633 acc :0.992\n",
      "Iteration: 20 Loss: 0.0996214 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0740186 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0995672 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0881778 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0777806 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0814265 acc :1.0\n",
      "Iteration: 140 Loss: 0.107108 acc :0.984\n",
      "Iteration: 160 Loss: 0.0714099 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0894541 acc :0.992\n",
      "Iteration: 200 Loss: 0.095591 acc :0.992032\n",
      "Iteration: 220 Loss: 0.0863409 acc :0.992\n",
      "Iteration: 240 Loss: 0.101305 acc :0.98008\n",
      "Iteration: 260 Loss: 0.102479 acc :0.992\n",
      "Iteration: 280 Loss: 0.087258 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0953329 acc :0.988\n",
      "Iteration: 320 Loss: 0.0806895 acc :0.992032\n",
      "Iteration: 340 Loss: 0.14109 acc :0.98\n",
      "Iteration: 360 Loss: 0.0858994 acc :1.0\n",
      "Iteration: 380 Loss: 0.0989061 acc :0.988\n",
      "validation Accuracy (34): 0.9462\n",
      "Iteration: 0 Loss: 0.0959253 acc :0.988\n",
      "Iteration: 20 Loss: 0.0986209 acc :0.996016\n",
      "Iteration: 40 Loss: 0.0710217 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0926052 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0905512 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0784707 acc :1.0\n",
      "Iteration: 120 Loss: 0.0764377 acc :0.996016\n",
      "Iteration: 140 Loss: 0.108601 acc :0.988\n",
      "Iteration: 160 Loss: 0.0749918 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0893978 acc :1.0\n",
      "Iteration: 200 Loss: 0.0936437 acc :0.988048\n",
      "Iteration: 220 Loss: 0.0920654 acc :0.988\n",
      "Iteration: 240 Loss: 0.107455 acc :0.984064\n",
      "Iteration: 260 Loss: 0.0976006 acc :0.992\n",
      "Iteration: 280 Loss: 0.0923204 acc :0.992032\n",
      "Iteration: 300 Loss: 0.10863 acc :0.98\n",
      "Iteration: 320 Loss: 0.0755478 acc :0.996016\n",
      "Iteration: 340 Loss: 0.131275 acc :0.976\n",
      "Iteration: 360 Loss: 0.0854594 acc :1.0\n",
      "Iteration: 380 Loss: 0.0915673 acc :0.992\n",
      "validation Accuracy (35): 0.9445\n",
      "Iteration: 0 Loss: 0.0933914 acc :0.996\n",
      "Iteration: 20 Loss: 0.0958573 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0755709 acc :0.988048\n",
      "Iteration: 60 Loss: 0.0887214 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0879703 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0748606 acc :1.0\n",
      "Iteration: 120 Loss: 0.0766935 acc :1.0\n",
      "Iteration: 140 Loss: 0.102197 acc :0.988\n",
      "Iteration: 160 Loss: 0.0755048 acc :0.996016\n",
      "Iteration: 180 Loss: 0.089569 acc :0.992\n",
      "Iteration: 200 Loss: 0.0955948 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0875802 acc :0.996\n",
      "Iteration: 240 Loss: 0.0978224 acc :0.992032\n",
      "Iteration: 260 Loss: 0.103838 acc :0.984\n",
      "Iteration: 280 Loss: 0.0916176 acc :1.0\n",
      "Iteration: 300 Loss: 0.0992816 acc :0.984\n",
      "Iteration: 320 Loss: 0.076619 acc :0.996016\n",
      "Iteration: 340 Loss: 0.139814 acc :0.98\n",
      "Iteration: 360 Loss: 0.0821045 acc :1.0\n",
      "Iteration: 380 Loss: 0.102396 acc :0.992\n",
      "validation Accuracy (36): 0.9466\n",
      "Iteration: 0 Loss: 0.0989852 acc :0.984\n",
      "Iteration: 20 Loss: 0.0926724 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0710391 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0828565 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0906695 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0762242 acc :1.0\n",
      "Iteration: 120 Loss: 0.0754833 acc :0.996016\n",
      "Iteration: 140 Loss: 0.113254 acc :0.984\n",
      "Iteration: 160 Loss: 0.0714667 acc :1.0\n",
      "Iteration: 180 Loss: 0.0940686 acc :0.988\n",
      "Iteration: 200 Loss: 0.0889329 acc :0.992032\n",
      "Iteration: 220 Loss: 0.0889049 acc :0.988\n",
      "Iteration: 240 Loss: 0.101379 acc :0.984064\n",
      "Iteration: 260 Loss: 0.114294 acc :0.972\n",
      "Iteration: 280 Loss: 0.0959586 acc :0.992032\n",
      "Iteration: 300 Loss: 0.0976631 acc :0.984\n",
      "Iteration: 320 Loss: 0.076862 acc :1.0\n",
      "Iteration: 340 Loss: 0.130154 acc :0.976\n",
      "Iteration: 360 Loss: 0.0869102 acc :1.0\n",
      "Iteration: 380 Loss: 0.102232 acc :0.992\n",
      "validation Accuracy (37): 0.9453\n",
      "Iteration: 0 Loss: 0.0967625 acc :0.988\n",
      "Iteration: 20 Loss: 0.101475 acc :0.984064\n",
      "Iteration: 40 Loss: 0.0724218 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0870937 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0914819 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0786932 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0748545 acc :1.0\n",
      "Iteration: 140 Loss: 0.110445 acc :0.984\n",
      "Iteration: 160 Loss: 0.0713222 acc :1.0\n",
      "Iteration: 180 Loss: 0.094904 acc :0.984\n",
      "Iteration: 200 Loss: 0.101234 acc :0.996016\n",
      "Iteration: 220 Loss: 0.090355 acc :0.988\n",
      "Iteration: 240 Loss: 0.0956438 acc :0.988048\n",
      "Iteration: 260 Loss: 0.112508 acc :0.992\n",
      "Iteration: 280 Loss: 0.0897168 acc :1.0\n",
      "Iteration: 300 Loss: 0.094953 acc :0.988\n",
      "Iteration: 320 Loss: 0.0776131 acc :1.0\n",
      "Iteration: 340 Loss: 0.119627 acc :0.984\n",
      "Iteration: 360 Loss: 0.0904469 acc :1.0\n",
      "Iteration: 380 Loss: 0.103324 acc :0.988\n",
      "validation Accuracy (38): 0.946\n",
      "Iteration: 0 Loss: 0.0943123 acc :0.992\n",
      "Iteration: 20 Loss: 0.0942513 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0731253 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0855077 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0923757 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0759372 acc :1.0\n",
      "Iteration: 120 Loss: 0.0791619 acc :0.992032\n",
      "Iteration: 140 Loss: 0.104696 acc :0.984\n",
      "Iteration: 160 Loss: 0.0696134 acc :1.0\n",
      "Iteration: 180 Loss: 0.0902558 acc :0.992\n",
      "Iteration: 200 Loss: 0.101202 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0847911 acc :0.996\n",
      "Iteration: 240 Loss: 0.0969039 acc :0.984064\n",
      "Iteration: 260 Loss: 0.103145 acc :0.988\n",
      "Iteration: 280 Loss: 0.0900378 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0955873 acc :0.98\n",
      "Iteration: 320 Loss: 0.081845 acc :0.996016\n",
      "Iteration: 340 Loss: 0.128762 acc :0.98\n",
      "Iteration: 360 Loss: 0.0897631 acc :0.992032\n",
      "Iteration: 380 Loss: 0.0939363 acc :0.992\n",
      "validation Accuracy (39): 0.9449\n",
      "Iteration: 0 Loss: 0.0882569 acc :0.992\n",
      "Iteration: 20 Loss: 0.0940153 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0705554 acc :1.0\n",
      "Iteration: 60 Loss: 0.0862431 acc :0.984064\n",
      "Iteration: 80 Loss: 0.0860221 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0792865 acc :1.0\n",
      "Iteration: 120 Loss: 0.0758548 acc :1.0\n",
      "Iteration: 140 Loss: 0.105179 acc :0.988\n",
      "Iteration: 160 Loss: 0.0733044 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0946152 acc :0.988\n",
      "Iteration: 200 Loss: 0.0940889 acc :0.988048\n",
      "Iteration: 220 Loss: 0.0852171 acc :0.996\n",
      "Iteration: 240 Loss: 0.100617 acc :0.984064\n",
      "Iteration: 260 Loss: 0.10641 acc :0.988\n",
      "Iteration: 280 Loss: 0.0856154 acc :1.0\n",
      "Iteration: 300 Loss: 0.0913495 acc :0.988\n",
      "Iteration: 320 Loss: 0.0770493 acc :1.0\n",
      "Iteration: 340 Loss: 0.12799 acc :0.98\n",
      "Iteration: 360 Loss: 0.0843989 acc :1.0\n",
      "Iteration: 380 Loss: 0.0963596 acc :0.992\n",
      "validation Accuracy (40): 0.9438\n",
      "Iteration: 0 Loss: 0.0801788 acc :0.996\n",
      "Iteration: 20 Loss: 0.0902656 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0709052 acc :1.0\n",
      "Iteration: 60 Loss: 0.0854534 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0826206 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0759832 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0771424 acc :1.0\n",
      "Iteration: 140 Loss: 0.111118 acc :0.976\n",
      "Iteration: 160 Loss: 0.0717633 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0910621 acc :0.996\n",
      "Iteration: 200 Loss: 0.0920836 acc :0.984064\n",
      "Iteration: 220 Loss: 0.0888809 acc :0.992\n",
      "Iteration: 240 Loss: 0.0944821 acc :0.988048\n",
      "Iteration: 260 Loss: 0.107115 acc :0.988\n",
      "Iteration: 280 Loss: 0.0879157 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0957174 acc :0.988\n",
      "Iteration: 320 Loss: 0.0809665 acc :0.996016\n",
      "Iteration: 340 Loss: 0.129599 acc :0.98\n",
      "Iteration: 360 Loss: 0.0847699 acc :1.0\n",
      "Iteration: 380 Loss: 0.0991751 acc :0.984\n",
      "validation Accuracy (41): 0.9448\n",
      "Iteration: 0 Loss: 0.0856846 acc :0.996\n",
      "Iteration: 20 Loss: 0.0923033 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0744093 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0911225 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0902539 acc :0.992032\n",
      "Iteration: 100 Loss: 0.077153 acc :1.0\n",
      "Iteration: 120 Loss: 0.0778204 acc :0.996016\n",
      "Iteration: 140 Loss: 0.104004 acc :0.98\n",
      "Iteration: 160 Loss: 0.0761959 acc :0.996016\n",
      "Iteration: 180 Loss: 0.096073 acc :0.988\n",
      "Iteration: 200 Loss: 0.0963916 acc :0.992032\n",
      "Iteration: 220 Loss: 0.0911938 acc :0.984\n",
      "Iteration: 240 Loss: 0.0919357 acc :0.988048\n",
      "Iteration: 260 Loss: 0.105463 acc :0.988\n",
      "Iteration: 280 Loss: 0.0862794 acc :1.0\n",
      "Iteration: 300 Loss: 0.0860855 acc :0.992\n",
      "Iteration: 320 Loss: 0.0769776 acc :0.996016\n",
      "Iteration: 340 Loss: 0.131698 acc :0.98\n",
      "Iteration: 360 Loss: 0.0839495 acc :1.0\n",
      "Iteration: 380 Loss: 0.0975735 acc :0.992\n",
      "validation Accuracy (42): 0.943\n",
      "Iteration: 0 Loss: 0.0812115 acc :0.996\n",
      "Iteration: 20 Loss: 0.0933368 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0735024 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0869996 acc :0.988048\n",
      "Iteration: 80 Loss: 0.0905477 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0750859 acc :1.0\n",
      "Iteration: 120 Loss: 0.0799347 acc :0.996016\n",
      "Iteration: 140 Loss: 0.104626 acc :0.988\n",
      "Iteration: 160 Loss: 0.0723568 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0929501 acc :0.988\n",
      "Iteration: 200 Loss: 0.0831436 acc :1.0\n",
      "Iteration: 220 Loss: 0.0884232 acc :0.988\n",
      "Iteration: 240 Loss: 0.0933095 acc :0.988048\n",
      "Iteration: 260 Loss: 0.104399 acc :0.988\n",
      "Iteration: 280 Loss: 0.087892 acc :1.0\n",
      "Iteration: 300 Loss: 0.0955857 acc :0.976\n",
      "Iteration: 320 Loss: 0.0757288 acc :1.0\n",
      "Iteration: 340 Loss: 0.120962 acc :0.98\n",
      "Iteration: 360 Loss: 0.0833983 acc :1.0\n",
      "Iteration: 380 Loss: 0.0959713 acc :0.996\n",
      "validation Accuracy (43): 0.9447\n",
      "Iteration: 0 Loss: 0.0871762 acc :0.992\n",
      "Iteration: 20 Loss: 0.101649 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0702533 acc :1.0\n",
      "Iteration: 60 Loss: 0.0832038 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0883019 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0770144 acc :1.0\n",
      "Iteration: 120 Loss: 0.0804308 acc :0.996016\n",
      "Iteration: 140 Loss: 0.103155 acc :0.984\n",
      "Iteration: 160 Loss: 0.0692906 acc :1.0\n",
      "Iteration: 180 Loss: 0.0930782 acc :0.992\n",
      "Iteration: 200 Loss: 0.0842353 acc :0.996016\n",
      "Iteration: 220 Loss: 0.0874655 acc :0.996\n",
      "Iteration: 240 Loss: 0.0956824 acc :0.988048\n",
      "Iteration: 260 Loss: 0.102342 acc :0.992\n",
      "Iteration: 280 Loss: 0.0908851 acc :0.992032\n",
      "Iteration: 300 Loss: 0.0898187 acc :0.992\n",
      "Iteration: 320 Loss: 0.0734644 acc :0.996016\n",
      "Iteration: 340 Loss: 0.134589 acc :0.984\n",
      "Iteration: 360 Loss: 0.0928248 acc :1.0\n",
      "Iteration: 380 Loss: 0.101694 acc :0.984\n",
      "validation Accuracy (44): 0.9454\n",
      "Iteration: 0 Loss: 0.0885279 acc :0.988\n",
      "Iteration: 20 Loss: 0.0919991 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0731789 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0854118 acc :0.992032\n",
      "Iteration: 80 Loss: 0.0904473 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0787175 acc :1.0\n",
      "Iteration: 120 Loss: 0.0779541 acc :0.996016\n",
      "Iteration: 140 Loss: 0.109346 acc :0.98\n",
      "Iteration: 160 Loss: 0.0688487 acc :1.0\n",
      "Iteration: 180 Loss: 0.0965425 acc :0.992\n",
      "Iteration: 200 Loss: 0.0940147 acc :0.996016\n",
      "Iteration: 220 Loss: 0.0860203 acc :0.996\n",
      "Iteration: 240 Loss: 0.0979225 acc :0.992032\n",
      "Iteration: 260 Loss: 0.102981 acc :0.992\n",
      "Iteration: 280 Loss: 0.0875175 acc :0.996016\n",
      "Iteration: 300 Loss: 0.096252 acc :0.988\n",
      "Iteration: 320 Loss: 0.0785263 acc :0.992032\n",
      "Iteration: 340 Loss: 0.124633 acc :0.98\n",
      "Iteration: 360 Loss: 0.085026 acc :1.0\n",
      "Iteration: 380 Loss: 0.0965341 acc :0.996\n",
      "validation Accuracy (45): 0.9452\n",
      "Iteration: 0 Loss: 0.0873903 acc :0.992\n",
      "Iteration: 20 Loss: 0.100489 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0737451 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0786444 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0903941 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0744103 acc :1.0\n",
      "Iteration: 120 Loss: 0.0774888 acc :1.0\n",
      "Iteration: 140 Loss: 0.108559 acc :0.984\n",
      "Iteration: 160 Loss: 0.071325 acc :1.0\n",
      "Iteration: 180 Loss: 0.0901873 acc :0.992\n",
      "Iteration: 200 Loss: 0.089516 acc :0.992032\n",
      "Iteration: 220 Loss: 0.0784743 acc :0.988\n",
      "Iteration: 240 Loss: 0.108307 acc :0.984064\n",
      "Iteration: 260 Loss: 0.100373 acc :0.992\n",
      "Iteration: 280 Loss: 0.0927576 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0897049 acc :0.988\n",
      "Iteration: 320 Loss: 0.0711625 acc :1.0\n",
      "Iteration: 340 Loss: 0.128499 acc :0.98\n",
      "Iteration: 360 Loss: 0.0892017 acc :0.992032\n",
      "Iteration: 380 Loss: 0.0975625 acc :0.988\n",
      "validation Accuracy (46): 0.9441\n",
      "Iteration: 0 Loss: 0.0891529 acc :0.988\n",
      "Iteration: 20 Loss: 0.0909517 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0703323 acc :1.0\n",
      "Iteration: 60 Loss: 0.0777835 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0848722 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0785529 acc :0.996016\n",
      "Iteration: 120 Loss: 0.0803626 acc :0.996016\n",
      "Iteration: 140 Loss: 0.106502 acc :0.984\n",
      "Iteration: 160 Loss: 0.0716431 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0867351 acc :0.996\n",
      "Iteration: 200 Loss: 0.0851971 acc :0.996016\n",
      "Iteration: 220 Loss: 0.0828273 acc :0.992\n",
      "Iteration: 240 Loss: 0.100872 acc :0.992032\n",
      "Iteration: 260 Loss: 0.0987426 acc :1.0\n",
      "Iteration: 280 Loss: 0.08758 acc :0.996016\n",
      "Iteration: 300 Loss: 0.0960218 acc :0.988\n",
      "Iteration: 320 Loss: 0.0759666 acc :0.996016\n",
      "Iteration: 340 Loss: 0.142478 acc :0.976\n",
      "Iteration: 360 Loss: 0.0913528 acc :0.992032\n",
      "Iteration: 380 Loss: 0.0964522 acc :0.988\n",
      "validation Accuracy (47): 0.9453\n",
      "Iteration: 0 Loss: 0.0820748 acc :0.992\n",
      "Iteration: 20 Loss: 0.0929862 acc :0.992032\n",
      "Iteration: 40 Loss: 0.0757838 acc :0.992032\n",
      "Iteration: 60 Loss: 0.0815556 acc :0.996016\n",
      "Iteration: 80 Loss: 0.0861497 acc :0.996016\n",
      "Iteration: 100 Loss: 0.0716902 acc :1.0\n",
      "Iteration: 120 Loss: 0.0798009 acc :0.992032\n",
      "Iteration: 140 Loss: 0.108635 acc :0.98\n",
      "Iteration: 160 Loss: 0.0680037 acc :1.0\n",
      "Iteration: 180 Loss: 0.0894008 acc :0.992\n",
      "Iteration: 200 Loss: 0.0856662 acc :0.992032\n",
      "Iteration: 220 Loss: 0.088432 acc :0.992\n",
      "Iteration: 240 Loss: 0.0996471 acc :0.984064\n",
      "Iteration: 260 Loss: 0.102244 acc :0.996\n",
      "Iteration: 280 Loss: 0.0944558 acc :1.0\n",
      "Iteration: 300 Loss: 0.0875787 acc :0.984\n",
      "Iteration: 320 Loss: 0.0723156 acc :1.0\n",
      "Iteration: 340 Loss: 0.125962 acc :0.98\n",
      "Iteration: 360 Loss: 0.0915528 acc :0.996016\n",
      "Iteration: 380 Loss: 0.0888323 acc :0.992\n",
      "validation Accuracy (48): 0.9449\n",
      "Iteration: 0 Loss: 0.087771 acc :0.988\n",
      "Iteration: 20 Loss: 0.0955849 acc :0.988048\n",
      "Iteration: 40 Loss: 0.0721362 acc :0.996016\n",
      "Iteration: 60 Loss: 0.0833455 acc :1.0\n",
      "Iteration: 80 Loss: 0.0861908 acc :0.992032\n",
      "Iteration: 100 Loss: 0.0780769 acc :0.996016\n",
      "Iteration: 120 Loss: 0.07425 acc :1.0\n",
      "Iteration: 140 Loss: 0.105968 acc :0.984\n",
      "Iteration: 160 Loss: 0.0692698 acc :0.996016\n",
      "Iteration: 180 Loss: 0.0913778 acc :0.992\n",
      "Iteration: 200 Loss: 0.093292 acc :0.988048\n",
      "Iteration: 220 Loss: 0.0872329 acc :0.992\n",
      "Iteration: 240 Loss: 0.109614 acc :0.984064\n",
      "Iteration: 260 Loss: 0.0987809 acc :0.996\n",
      "Iteration: 280 Loss: 0.0952593 acc :0.996016\n",
      "Iteration: 300 Loss: 0.089042 acc :0.988\n",
      "Iteration: 320 Loss: 0.071149 acc :1.0\n",
      "Iteration: 340 Loss: 0.127213 acc :0.98\n",
      "Iteration: 360 Loss: 0.0879706 acc :0.992032\n",
      "Iteration: 380 Loss: 0.0947189 acc :0.988\n",
      "validation Accuracy (49): 0.9448\n"
     ]
    }
   ],
   "source": [
    "Y_train = dense_to_one_hot(y_train, n_classes=10)\n",
    "Y_valid = dense_to_one_hot(y_valid, n_classes=10)\n",
    "Y_test = dense_to_one_hot(y_test, n_classes=10)\n",
    "# %% We'll now train in minibatches and report accuracy, loss:\n",
    "iter_per_epoch = 400\n",
    "#n_epochs = 200\n",
    "n_epochs = 50\n",
    "\n",
    "train_size = 100000\n",
    "\n",
    "indices = np.linspace(0, 100000 - 1, iter_per_epoch)\n",
    "indices = indices.astype('int')\n",
    "\n",
    "for epoch_i in range(n_epochs):\n",
    "    for iter_i in range(iter_per_epoch - 1):\n",
    "        batch_xs = X_train[indices[iter_i]:indices[iter_i+1]]\n",
    "        batch_ys = Y_train[indices[iter_i]:indices[iter_i+1]]\n",
    "\n",
    "        if iter_i % 20 == 0:\n",
    "            loss,accuracy_ = sess.run([cross_entropy,accuracy],\n",
    "                            feed_dict={\n",
    "                                x: batch_xs,\n",
    "                                y: batch_ys,\n",
    "                                keep_prob: 1.0,\n",
    "                                regular_lambda:0.0001\n",
    "                            })\n",
    "            print('Iteration: ' + str(iter_i) + ' Loss: ' + str(loss) +' acc :' +str(accuracy_))\n",
    "\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            x: batch_xs, y: batch_ys, keep_prob: 0.6,learning_rate:0.002, regular_lambda:0.00025})\n",
    "\n",
    "\n",
    "    print('validation Accuracy (%d): ' % epoch_i + str(sess.run(accuracy,\n",
    "                                                     feed_dict={\n",
    "                                                         x: X_valid,\n",
    "                                                         y: Y_valid,\n",
    "                                                         keep_prob: 1.0,\n",
    "                                                     })))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "dbe4aa8f-1542-458f-a4ca-388b7812834c"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45699802  0.07855655  0.00392494  0.01981884  0.45308241 -0.2113339 ]\n"
     ]
    }
   ],
   "source": [
    "# lets take a see at theta\n",
    "theta = sess.run(h_fc_loc2, feed_dict={\n",
    "       x: batch_xs, keep_prob: 1.0})\n",
    "print(theta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "427651a6-bdbe-4396-819c-9865db625798"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 99  1  0  1  0  1  1  0  0]\n",
      " [ 1  0 96  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 97  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 95  0  1  0  1  0]\n",
      " [ 1  0  0  0  0 92  1  0  0  1]\n",
      " [ 1  0  0  0  0  1 94  0  0  2]\n",
      " [ 0  0  0  0  0  2  1 97  2  0]\n",
      " [ 0  0  0  0  0  1  0  0 94  0]\n",
      " [ 0  0  0  0  3  0  0  0  2 91]]\n"
     ]
    }
   ],
   "source": [
    "# take look at confusion table\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ROI,theta,prediction = sess.run([h_trans,h_fc_loc2,tf_predictions], feed_dict={\n",
    "       x: X_test, keep_prob: 1.0})\n",
    "\n",
    "\n",
    "y_pred = prediction.tolist()\n",
    "y_true = y_test\n",
    "\n",
    "w = confusion_matrix(y_true, y_pred, labels=range(10)).T/np.sum(confusion_matrix(y_true, y_pred, labels=range(10)), axis=1).astype(float)*100\n",
    "print w.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c406645b-ac7c-4aad-b488-6f150682fbe9"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 40, 40, 1)\n",
      "(10, 6)\n"
     ]
    }
   ],
   "source": [
    "ROI,theta,prediction = sess.run([h_trans,h_fc_loc2,tf_predictions], feed_dict={\n",
    "       x: batch_xs[0:10], keep_prob: 1.0})\n",
    "\n",
    "print ROI.shape\n",
    "print theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "412c45ab-648f-484d-8331-09f1617d0473"
    }
   },
   "outputs": [],
   "source": [
    "def getboundary(theta):\n",
    "    four_angles=np.array([[1,1,1],[1,-1,1],[-1,-1,1],[-1,1,1]])\n",
    "    theta=theta.reshape([2,3])\n",
    "    WH=np.array([40,40])\n",
    "    return (((theta.dot(four_angles.T)+1)/2).T*WH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7cb97b0a-91ed-43d4-9035-9c1a282d1850"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU4IUIOK0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3004eddf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "count=1\n",
    "for i in xrange(0,5):\n",
    "    plt.subplot(5, 2, count)\n",
    "    first_train_img = np.reshape(batch_xs[i], (40, 40)).copy()\n",
    "    first_train_img = cv2.cvtColor(first_train_img,cv2.COLOR_GRAY2RGB)\n",
    "    fourangle=getboundary(theta[i])\n",
    "    fourangle=fourangle.astype(int)\n",
    "    #cv2.rectangle(first_train_img, tuple(twoangle[0].tolist()), tuple(twoangle[1].tolist()), (0, 1,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[0].tolist()),tuple(fourangle[1].tolist()),(1,0,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[1].tolist()),tuple(fourangle[2].tolist()),(0,1,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[2].tolist()),tuple(fourangle[3].tolist()),(0,0,1),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[3].tolist()),tuple(fourangle[0].tolist()),(0,1,0),2)\n",
    "    plt.imshow(first_train_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    count+=1\n",
    "    plt.subplot(5, 2, count)\n",
    "    first_train_img = np.reshape(ROI[i], (40, 40))\n",
    "    plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    count+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9738ec2e-a8da-4274-bc39-201a44aa0d49"
    }
   },
   "source": [
    "# [sec3] give a continus test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "9cd4a84d-4422-4d37-88e2-d491f6ff1d9e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3005179c90>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3004eceed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_idx=13\n",
    "print y_test[test_idx]\n",
    "det=getrotation_img(X_test[test_idx, :],0)\n",
    "plt.imshow(det, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "43c0ee2c-3374-45c6-aa28-2244fc1b5f5a"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "# create 720 rotation images\n",
    "print y_test[test_idx]\n",
    "for i in xrange(720):\n",
    "    if i==0:\n",
    "        X_test_temp=np.reshape(getrotation_img(X_test[test_idx, :],i), (-1, 1600))\n",
    "    else:\n",
    "        temp=np.reshape(getrotation_img(X_test[test_idx, :],i), (-1, 1600))\n",
    "        X_test_temp=np.concatenate((X_test_temp, temp), axis=0)\n",
    "\n",
    "# forward to test\n",
    "ROI,theta,prediction = sess.run([h_trans,h_fc_loc2,tf_predictions], feed_dict={\n",
    "       x: X_test_temp, keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "fa5d359c-0751-403d-a96a-9026aaf077c0"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99444444444444446"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prediction==y_test[test_idx]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take a look at images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "59ed0f87-b99e-45f1-9a14-95439ae0c80c"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAADPCAYAAAD1eWSNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f300de91750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count=1\n",
    "for i in [15,30,90,180]:\n",
    "    plt.subplot(5, 2, count)\n",
    "    first_train_img = np.reshape(X_test_temp[i], (40, 40)).copy()\n",
    "    first_train_img = cv2.cvtColor(first_train_img,cv2.COLOR_GRAY2RGB)\n",
    "    fourangle=getboundary(theta[i])\n",
    "    fourangle=fourangle.astype(int)\n",
    "    #cv2.rectangle(first_train_img, tuple(twoangle[0].tolist()), tuple(twoangle[1].tolist()), (0, 1,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[0].tolist()),tuple(fourangle[1].tolist()),(1,0,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[1].tolist()),tuple(fourangle[2].tolist()),(0,1,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[2].tolist()),tuple(fourangle[3].tolist()),(0,0,1),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[3].tolist()),tuple(fourangle[0].tolist()),(0,1,0),2)\n",
    "    plt.imshow(first_train_img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    count+=1\n",
    "    plt.subplot(5, 2, count)\n",
    "    first_train_img = np.reshape(ROI[i], (40, 40))\n",
    "    plt.imshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    count+=1\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write the image out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e176e34c-fb3c-4a5e-b08e-ea998a5623c6"
    }
   },
   "outputs": [],
   "source": [
    "# add retangle to image and write it out\n",
    "for i in xrange(720):\n",
    "    first_train_img = np.reshape(X_test_temp[i], (40, 40)).copy()\n",
    "    first_train_img = cv2.cvtColor(first_train_img,cv2.COLOR_GRAY2RGB)\n",
    "    fourangle=getboundary(theta[i])\n",
    "    fourangle=fourangle.astype(int)\n",
    "    #cv2.rectangle(first_train_img, tuple(twoangle[0].tolist()), tuple(twoangle[1].tolist()), (0, 1,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[0].tolist()),tuple(fourangle[1].tolist()),(1,0,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[1].tolist()),tuple(fourangle[2].tolist()),(0,1,0),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[2].tolist()),tuple(fourangle[3].tolist()),(0,0,1),2)\n",
    "    cv2.line(first_train_img,tuple(fourangle[3].tolist()),tuple(fourangle[0].tolist()),(0,1,0),2)\n",
    "    cv2.imwrite('trial/'+str(i).zfill(4)+'.jpg',first_train_img*255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with the help with imagemagick (install it with apt-get) \n",
    "\n",
    "### make the pictures to gif\n",
    "(shell) convert -delay 2 -loop 0 *.jpg myimage.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](trial/myimage.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "673bf288-626a-4710-aa5a-40a8329aa863": {
     "id": "673bf288-626a-4710-aa5a-40a8329aa863",
     "layout": "grid",
     "prev": null,
     "regions": {
      "1a2b288d-2f20-4416-916d-6833f9492cea": {
       "attrs": {
        "height": 0.6666666666666666,
        "pad": 0.01,
        "width": 0.8333333333333334,
        "x": 0.08333333333333333,
        "y": 0.25
       },
       "content": {
        "cell": "2bfd530f-5521-4368-a9c0-c0466b9415a9",
        "part": "source"
       },
       "id": "1a2b288d-2f20-4416-916d-6833f9492cea"
      },
      "de1e6d70-59c0-4d22-af18-1b484416a4dc": {
       "attrs": {
        "height": 0.0826960563802669,
        "pad": 0.01,
        "width": 0.75,
        "x": 0.08333333333333333,
        "y": 0.08333333333333333
       },
       "content": {
        "cell": "4afcf73d-dced-4549-a33d-ec46c749e8cd",
        "part": "whole"
       },
       "id": "de1e6d70-59c0-4d22-af18-1b484416a4dc"
      }
     },
     "theme": null
    },
    "87db4509-a670-44d1-908a-7c7aa894108c": {
     "id": "87db4509-a670-44d1-908a-7c7aa894108c",
     "prev": "673bf288-626a-4710-aa5a-40a8329aa863",
     "regions": {
      "c47b806b-d35f-4fd8-a364-5057822c026d": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "aa206c74-bc21-40a9-9c42-294fcea4d184",
        "part": "source"
       },
       "id": "c47b806b-d35f-4fd8-a364-5057822c026d"
      }
     }
    }
   },
   "themes": {
    "default": "2fe5f2cc-5154-4648-af10-074f703ccef2",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
